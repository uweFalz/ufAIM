\documentclass{report}   				% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                	% See geometry.pdf to learn the layout options. There are lots.
% \geometry{a4paper}                   	% ... or a4paper or a5paper or ... 
% \geometry{landscape}                	% Activate for rotated page geometry
\usepackage{pdflscape}
% \usepackage[parfill]{parskip}
\usepackage{graphicx}
\usepackage[ngerman,english]{babel}
\usepackage{makeidx}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{sample.bib}

\newcommand{\myIndex}[1]{#1\index{#1}}

\usepackage[]{amsmath, amssymb, amsthm, amscd}

\usepackage{hyperref}	% optional

\usepackage{enumitem}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{summary}[theorem]{Summary}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{algorithm}[theorem]{Algorithm}

\numberwithin{theorem}{subsection}	% important bit
\numberwithin{equation}{section}	% important bit

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\hh}{\mathbb{H}}

\newcommand{\x}{\hat{x}}

\newcommand{\idx}{k}
\newcommand{\idy}{k}
\newcommand{\idz}{\ell}

\newcommand{\A}{\mathcal{A}}
\newcommand{\I}{\mathcal{I}}
\newcommand{\J}{\mathcal{J}}
\newcommand{\Lagrangian}{\mathcal{L}}
\newcommand{\Nu}{\mathcal{N}}

\newcommand{\diff}{\: \mathrm{d}}

\makeindex

\title{AIM - BIMalignment revised}
% \subtitle{A WikiPedia session}
\author{uf}
\date{\today}							% Activate to display a given date or no date

\begin{document}
\maketitle

\tableofcontents

\chapter*{Intro}

BIM \ldots alignment \ldots

\chapter{Basics}

\section{Characteristic parameters}

Have a look at \cite{grafitoi}:
In order to analyze the various types of transition curves it is also necessary to determine other parameters that characterize the vehicle displacement along the curve:

Rate of change of non-compensated lateral acceleration parallel to the running plane. Lateral jerk ($\tfrac{m}{s^3}$):
\begin{equation}
v = \frac{d a_q}{d t} = \frac{V}{3,6} \cdot \frac{d h (s)}{d s} 
\end{equation}

Rate of change of the lateral jerk ($\tfrac{m}{s^4}$):
\begin{equation}
a = \frac{d^2 a_q}{d t^2} = \left( \frac{V}{3,6} \right)^2 \cdot \frac{d^2 h (s)}{d s^2}
\end{equation}

The third time derivative of the non-compensated lateral acceleration parallel to the running plane ($\tfrac{m}{s^5}$):
\begin{equation}
\dot{a} = \frac{d^3 a_q}{d t^3} = \left( \frac{V}{3,6} \right)^3 \cdot \frac{d^3 h (s)}{d s^3}
\end{equation}

The angular roll velocity ($\tfrac{\text{rad}}{s}$):
\begin{equation}
\omega = \frac{d \psi}{d t} = \frac{V}{3,6} \cdot \frac{d \psi}{d s} 
\end{equation}

The angular roll acceleration is equal to the second time derivative of the cant angle ($\tfrac{\text{rad}}{s^2}$):
\begin{equation}
a = \frac{d^2 \psi}{d t^2} = \left( \frac{V}{3,6} \right)^2 \cdot \frac{d^2 \psi}{d s^2} 
\end{equation}

The angular jerk about roll axis is equal to the third time derivative of the cant angle ($\tfrac{\text{rad}}{s^3}$):
\begin{equation}
\dot{a} = \frac{d^3 \psi}{d t^3} = \left( \frac{V}{3,6} \right)^3 \cdot \frac{d^3 \psi}{d s^3} 
\end{equation}

\section{Differentialgeometrie / Theoretische Physik}

\subsection{Kurven}

refer to Wikipedia!

In der Mathematik ist eine Kurve (von lateinisch curvus „gebogen, gekrümmt“) ein eindimensionales Objekt. Im Gegensatz etwa zu einer Geraden muss eine Kurve grundsätzlich keinen geraden, sondern kann vielmehr jeden beliebigen Verlauf annehmen.

Eindimensional bedeutet dabei informell, dass man sich auf der Kurve nur in eine Richtung (bzw. in die Gegenrichtung) bewegen kann. Ob die Kurve in der zweidimensionalen Ebene liegt (ebene Kurve), in einem höherdimensionalen Raum (siehe Raumkurve), oder gar in einer Mannigfaltigkeit (beispielsweise in einer \textsc{Lorentz}schen Mannigfaltigkeit) ist in diesem begrifflichen Zusammenhang unerheblich.

Je nach Teilgebiet der Mathematik gibt es unterschiedliche Präzisierungen dieser Beschreibung.

\paragraph{Parameterdarstellungen}

Eine Kurve kann als das Bild (Wertebereich) eines Weges definiert werden. Ein Weg ist (abweichend von der Umgangssprache) eine stetige Abbildung von einem Intervall in den betrachteten Raum, also z.B. in die euklidische Ebene $\mathbb {R} ^{2}$. Ein Weg, dessen Bild eine gegebene Kurve ist, heißt auch Parameterdarstellung dieser Kurve. Wege werden deshalb manchmal auch als parametrisierte Kurven bezeichnet.

Gelegentlich, insbesondere bei historischen Bezeichnungen, wird zwischen Weg und Kurve nicht unterschieden. So ist die interessante Struktur bei der \textsc{Hilbert}-Kurve der Weg; das Bild dieses Weges ist das Einheitsquadrat, besitzt also keinerlei fraktale Struktur mehr.

\paragraph{Parametertransformation}

Eine Parametertransformation $\phi$ ist eine umkehrbar stetige Abbildung (Homöomorphismus), der zwei Wege (d. h. parametrisierte Kurven) $c,c'$ ineinander überführt gemäß $c' = c \circ \phi$.

Für zwei Parameterdarstellungen $c \colon I \to C, c' \colon J \to C$ derselben Kurve $C$ ist ein Parameterwechsel daher durch eine Parametertransformation $\phi \colon J \to I$ gegeben, so dass $c' = c \circ \phi$ – und damit umgekehrt auch $c = c' \circ \phi ^{-1}$.

Statt Kurven mit den Bildern von Wegen zu identifizieren, könnte man sie auch (im Sinn der Kategorientheorie) äquivalent auch als die Äquivalenzklassen von Wegen mit gleichem Bild beschreiben, die durch Parametertransformationen (Homöomorphismen) ineinander übergeführt werden können. Diese Gleichwertigkeit macht man sich zunutze, um spezielle Klassen von Kurven zu definieren.

\paragraph{Gerichtete Kurven}

Durch die Parameterdarstellung erhält die Kurve einen „Richtungssinn“ in der Richtung des wachsenden Parameters.

Eine „gerichtete“ (oder „orientierte“) Kurve ist eine Äquivalenzklasse von Wegen (parametrisierten Kurven), die sich durch streng (strikt) monotone steigende Parametertransformationen ineinander überführen lassen.

In Anpassung des Sprachgebrauchs an den vorliegenden Verwendungszweck wird allgemein definiert:

Die „Spur“ einer (parametrisierten, gerichteten oder allgemeinen) Kurve ist die eindeutige Menge der Bildpunkte (einer beliebigen Parameterdarstellung derselben).

\paragraph{Glatte Kurven}

In diesem Fall verlangt man zusätzlich $k$-fache stetige Differenzierbarkeit ($k=1, 2, \ldots, \infty$) für den Weg bzw. die Parameterdarstellungen einer (gerichteten) Kurve. Die entsprechenden Kurvenklassen werden mit $C^{k}$ bezeichnet.

\paragraph{Gleichungsdarstellungen}

Eine Kurve kann auch durch eine oder mehrere Gleichungen in den Koordinaten beschrieben werden. Beispiele dafür sind wieder die Bilder der beiden durch die obigen Parameterdarstellungen gegebenen Kurven:

Die Gleichung $x^{2}+y^{2}=1$ beschreibt den Einheitskreis in der Ebene. Die Gleichung $y^{2}=x^{2}(x+1)$ beschreibt die oben in Parameterdarstellung angegebene Kurve mit Doppelpunkt. Ist die Gleichung wie hier durch ein Polynom gegeben, nennt man die Kurve algebraisch.

\paragraph{Funktionsgraphen}

Funktionsgraphen sind ein Spezialfall beider oben angegebenen Formen: Der Graph einer Funktion $f \colon D \to \mathbb {R} ,\quad x \mapsto f(x)$ kann entweder als Parameterdarstellung $D \to \mathbb{R}^{2}, \quad t \mapsto (t, f(t))$ oder als Gleichung $\Gamma_{f} = \{(x,y)\in \mathbb{R} ^{2} \mid y=f(x)\}$ angegeben werden.

\paragraph{Differenzierbare Kurven, Krümmung}

Sei $[a,b] \subset \mathbb {R}$ ein Intervall und $c \colon [a,b] \to \mathbb {R} ^{n}$ eine reguläre Kurve, d. h. $| c'(x) | \neq 0$ für alle $x \in (a,b)$. Die Länge der Kurve ist $l = \int _{a}^{b} | c'(t) | \,dt$

Die Funktion $x \mapsto \int _{a}^{x} | c'(t) | \,dt $ ist ein Diffeomorphismus $[a,b] \to [0,l]$, und die Verkettung von $c$ mit dem inversen Diffeomorphismus liefert eine neue Kurve ${\tilde {c}} \colon [0,l] \to \mathbb {R} ^{n}$ mit $ |{\tilde {c}}'(x)|=1$ für alle $x \in (0,l)$. Man sagt: $ {\tilde {c}}$ ist nach der Bogenlänge parametrisiert.

$ [a,b]\subset \mathbb {R} $ ein Intervall und $c \colon [a,b] \to \mathbb {R} ^{n}$ eine nach der Bogenlänge parametrisierte Kurve. Die Krümmung von $c$ an der Stelle $s$ ist definiert als $\kappa (s) = |c''(s)|$. Für ebene Kurven kann man die Krümmung noch mit einem Vorzeichen versehen: Ist $J$ die Drehung um 90°, dann ist $\kappa (s)$ festgelegt durch $c''(s) = \kappa (s) \cdot Jc'(s)$. Positive Krümmung entspricht Linkskurven, negative Rechtskurven.

\paragraph{Geschlossene Kurven}

Eine ebene Kurve $c \colon [0,1] \to \mathbb {R} ^{2}$ heißt geschlossen, wenn $c(0) = c(1)$, und einfach geschlossen, wenn zusätzlich $c$ auf $[0,1)$ injektiv ist. Der \textsc{Jordan}sche Kurvensatz besagt, dass eine einfach geschlossene Kurve die Ebene in einen beschränkten und einen unbeschränkten Teil zerlegt. Ist $c$ eine geschlossene Kurve mit $c (t) \neq (0,0)$ für alle $t \in [0,1]$, kann man der Kurve eine Umlaufzahl zuordnen, die angibt, wie oft die Kurve um den Nullpunkt herumläuft.

Glatten geschlossenen Kurven kann man eine weitere Zahl zuordnen, die Tangentenumlaufzahl, die für eine nach der Bogenläge parametrisierte Kurve $c \colon [0,l] \to \mathbb{R} ^{2}$ durch ${\frac {1}{2 \pi }} \int _{0}^{l}\kappa (t)\,dt$ gegeben ist. Der Umlaufsatz von \textsc{Heinz Hopf} besagt, dass eine einfache geschlossene Kurve Tangentenumlaufzahl 1 oder -1 hat.

Sei allgemein $X$ ein topologischer Raum. Statt von geschlossenen Wegen $c \colon [0,1] \to X$ mit $c(0)=c(1)$ spricht man auch von Schleifen mit Basispunkt $c(0)$. Weil der Quotientenraum $[0,1]/\{0,1\}$ homöomorph zum Einheitskreis $S^{1}$ ist, identifiziert man Schleifen mit stetigen Abbildungen $S^{1} \to X$. Zwei Schleifen $c_{1},c_{2}$ mit Basispunkt $x$ heißen homotop, wenn man sie unter Beibehaltung des Basispunkts stetig ineinander deformieren kann, d. h. wenn es eine stetige Abbildung $H \colon [0,1]^{2} \to X$ mit $H(s,0)=c_{1}(s)$, $H(s,1)=c_{2}(s)$ für alle $s$ und $H(0,t)=H(1,t)=x$ für alle $t$ gilt. Die Äquivalenzklassen homotoper Schleifen bilden eine Gruppe, die Fundamentalgruppe von $X$. Ist $X = \mathbb{R}^{2}-\{0\}$, dann ist die Fundamentalgruppe über die Windungszahl isomorph zu $\mathbb{Z}$.

\paragraph{Raumkurven}

Sei $[a,b] \subset \mathbb{R}$ ein Intervall und $c \colon [a,b] \to \mathbb{R} ^{3}$ eine nach der Bogenlänge parametrisierte Kurve. Die folgenden Bezeichnungen sind Standard: 
$$
\begin{aligned}
t(s) & = c'(s) \\
n(s) & = \frac{t'(s)}{| t'(s) |} \\
b(s) & = t(s) \times n(s)
\end{aligned}
$$
(definiert, wann immer $t'(s)\neq 0$). $t(s)$ ist der Tangentialvektor, $n(s)$ der Normalenvektor und $b(s)$ der Binormalenvektor, das Tripel $(t,n,b)$ heißt begleitendes Dreibein. Die Krümmung ist $\kappa (s)=|t'(s)|=|c''(s)|$, die Windung $\tau (s)$ definiert durch $b'(s) = -\tau (s) n(s)$. Es gelten die frenetschen Formeln:
$$
\begin{matrix}
t'&=&& \kappa n \\
n'&=&-\kappa t&+&\tau b \\
b'&=&&-\tau n
\end{matrix}
$$
Der Hauptsatz der lokalen Kurventheorie besagt, dass man eine Kurve aus Krümmung und Windung rekonstruieren kann: Sind glatte Funktionen $\kappa ,\tau \colon [0,l] \to \mathbb{R}$ mit $\kappa (s)>0$ für alle $s \in [0,l]$ (der Wert 0 ist für $\kappa$ also nicht erlaubt), so gibt es bis auf Bewegungen genau eine entsprechende Kurve.

Die von je zwei der drei Vektoren $t$, $n$ oder $b$ aufgespannten Ebenen durch den Kurvenpunkt tragen besondere Namen:

\begin{itemize}
\item Die Oskulations­ebene oder Schmiegebene wird von $t$ und $n$ aufgespannt.
\item Die Normalebene wird von $n$ und $b$ aufgespannt.
\item Die rektifizierende Ebene oder Streckebene wird von $t$ und $b$ aufgespannt.
\end{itemize}

\paragraph{Kurven als eigenständige Objekte}

Kurven ohne umgebenden Raum sind in der Differentialgeometrie relativ uninteressant, weil jede eindimensionale Mannigfaltigkeit diffeomorph zur reellen Geraden $\mathbb{R}$ oder zur Einheitskreislinie $S^1$ ist. Auch Eigenschaften wie die Krümmung einer Kurve sind intrinsisch nicht feststellbar.

In der algebraischen Geometrie und damit zusammenhängend in der komplexen Analysis versteht man unter „Kurven“ in der Regel eindimensionale komplexe Mannigfaltigkeiten, oft auch als \textsc{Riemann}sche Flächen bezeichnet. Diese Kurven sind eigenständige Studienobjekte, das prominenteste Beispiel sind die elliptischen Kurven.

\subsection{Algebraische Kurve}

Eine algebraische Kurve ist eine eindimensionale algebraische Varietät, kann also durch eine Polynomgleichung beschrieben werden. Ein wichtiger Spezialfall sind die ebenen algebraischen Kurven, also algebraische Kurven, die in der affinen oder projektiven Ebene verlaufen.

Geschichtlich beginnt die Beschäftigung mit algebraischen Kurven schon in der Antike mit der Untersuchung von Geraden und Kegelschnitten. Im 17. Jahrhundert wurden sie im Rahmen der analytischen Geometrie Gegenstand der Analysis und \textsc{Isaac Newton} behandelte systematisch Kubiken. Die Beschäftigung mit ihnen erreichte im 19. Jahrhundert durch die Behandlung im Rahmen der projektiven Geometrie einen Höhepunkt (unter anderem \textsc{August Ferdinand Möbius}, \textsc{Julius Plücker}). Dabei wird der Punkt im Unendlichen systematisch mit berücksichtigt. Die natürliche Betrachtungsweise ist nach dem Fundamentalsatz der Algebra über den komplexen Zahlen, und die klassische Theorie wurde durch die von \textsc{Bernhard Riemann} entdeckte Verbindung zu \textsc{Riemann}schen Flächen – die im Komplexen Kurven sind – auf eine neue Grundlage gestellt. In der Zahlentheorie (arithmetische Geometrie) werden auch Kurven über anderen Körpern als den reellen und komplexen Zahlen und über Ringen betrachtet.

Algebraische Kurven gehören zu den einfachsten Objekten der algebraischen Geometrie, in der sie mit rein algebraischen Methoden behandelt werden und nicht mit Methoden der Analysis. Höherdimensionale Varietäten der algebraischen Geometrie sind zum Beispiel algebraische Flächen. Man kann algebraische Kurven aber auch im Rahmen der komplexen Analysis untersuchen.

Im Folgenden werden die verwendeten Begriffe am einfachsten Fall ebener algebraischer Kurven erläutert. Man kann algebraische Kurven etwa als Schnittkurve algebraischer Flächen auch in mehr als zwei Dimensionen definieren. Ihre Klassifikation in drei Dimensionen nach Grad $d$ und Geschlecht $g$ war Gegenstand von zwei großen Arbeiten zum \textsc{Steiner}preis in den 1880er Jahren von \textsc{Max Noether} und \textsc{Georges Henri Halphen}, deren Beweise und Arbeit aber noch unvollständig war. Gegenstand der Klassifikation ist festzustellen, welche Paare $(d,\ g)$ existieren. Algebraische Kurven können immer in den dreidimensionalen projektiven Raum eingebettet werden, so dass die Betrachtung von zwei und drei Raumdimensionen reicht.

\paragraph{Definition und wichtige Eigenschaften}

Eine ebene algebraische Kurve über einem Körper $K$ wird durch ein nichtkonstantes Polynom in zwei Variablen $x$ und $y$ definiert, dessen Koeffizienten aus $K$ stammen. Dabei werden zwei Polynome miteinander identifiziert, wenn das eine durch Multiplikation mit einer von Null verschiedenen Zahl aus $K$ aus dem anderen hervorgeht. Der Grad des Polynoms wird als Grad der Kurve bezeichnet.

Dieser Definition liegt folgende Motivation zu Grunde: Ist $f$ ein solches Polynom, so kann man die Nullstellenmenge $V(f) = \{ (x,y) \in K^{2} | f(x,y) = 0 \}$
in der Ebene $K^{2}$ betrachten. Diese Menge stellt häufig ein Objekt dar, das man auch anschaulich als Kurve bezeichnen würde, so ist beispielsweise $\{ (x,y) \in \mathbb {R} ^{2} | x^{2}+y^{2}-1=0 \}$ ein Kreis. Auch bei der Definition von $V(f)$ spielt ein konstanter Faktor keine Rolle.

Ist der Körper $K$ algebraisch abgeschlossen, so kann man nach dem hilbertschen Nullstellensatz aus der Menge $V(f)$ das Polynom $f$ wiedergewinnen, falls dieses in lauter verschiedene irreduzible Faktoren zerfällt. In diesem Fall muss also nicht streng zwischen dem definierenden Polynom und dessen Nullstellenmenge unterschieden werden.

Ist der Körper $K$ dagegen nicht algebraisch abgeschlossen, so stellt $V(f)$ nicht immer eine Kurve in der Ebene dar. So werden durch $\{(x,y) \in \mathbb {R} ^{2} | x^{2}+y^{2}+1=0 \}$ und $\{ (x,y)\in \mathbb {R}^{2} | x^{2}+y^{2}=0 \}$ im Reellen die leere Menge beziehungsweise ein Punkt definiert, beides keine eindimensionalen Objekte. Erst im Komplexen erzeugen diese Polynome Kurven: ein Kreis und ein sich schneidendes Geradenpaar.

Man sagt daher, eine Kurve habe eine Eigenschaft geometrisch, falls die Menge $V(f)$ diese Eigenschaft über dem algebraischen Abschluss von $K$ besitzt.

Abstrakter kann man eine algebraische Kurve auch als ein eindimensionales separiertes algebraisches Schema über einem Körper definieren. Häufig werden noch weitere Voraussetzungen wie geometrische Reduziertheit oder Irreduzibilität in die Definition mit aufgenommen.

\paragraph{Irreduzibilität}

Ist das definierende Polynom reduzibel, falls es also in zwei nichttriviale Faktoren zerlegt werden kann, so kann auch die Kurve in zwei unabhängige Komponenten zerlegt werden. Zum Beispiel ist das Polynom $f(x,y) = xy$ reduzibel, da es in die Faktoren $x$ und $y$ zerlegt werden kann. Die durch $f$ definierte Kurve besteht daher aus zwei Geraden.

Bei einem irreduziblen Polynom kann die Kurve nicht zerlegt werden, welche dann ebenfalls irreduzibel genannt wird.

\paragraph{Singularitäten}

Im Normalfall lässt sich in jedem Punkt der algebraischen Kurve genau eine Tangente an die Kurve zeichnen. In diesem Fall nennt man den Punkt glatt oder nichtsingulär. Es kann aber auch der Fall auftreten, dass die Kurve in einem oder mehreren Punkten einen Selbstschnitt oder eine Spitze besitzt. Im ersten Fall besitzt die Kurve in diesem Punkt zwei oder mehr Tangenten, im zweiten fallen diese Tangenten zu einer mehrfachen Tangente zusammen.

Beispiele für solche singulären Punkte finden sich bei der \textsc{Neil}schen Parabel mit der Gleichung $y^{2} = x^{3}$, diese hat eine Spitze im Nullpunkt. Einen Doppelpunkt, also einen Punkt, der zwei Mal in verschiedenen Richtungen durchlaufen wird, findet man beim kartesischen Blatt, das durch $x^{3}+y^{3}-3xy = 0$ gegeben ist.

\paragraph{Projektive Kurven}

Häufig ist es von Vorteil, algebraische Kurven nicht im Affinen, sondern in der projektiven Ebene zu betrachten. Diese kann durch sogenannte homogene Koordinaten $[x:y:z]$ beschrieben werden, wobei $x$, $y$ und $z$ nicht gleichzeitig $0$ werden dürfen und zwei Punkte als gleich aufgefasst werden, wenn sie durch Multiplikation mit einer von 0 verschiedenen Zahl auseinander hervorgehen. Für $\lambda \neq 0$ gilt also $[x:y:z] = [\lambda \cdot x:\lambda \cdot y:\lambda \cdot z]$. Um im Projektiven algebraische Kurven zu definieren, benötigt man also Polynome in drei Variablen $x$, $y$ und $z$. Würde man hier beliebige Polynome verwenden, so ergäben sich große Probleme auf Grund der Tatsache, dass die Darstellung der Punkte nicht eindeutig ist: So sind die Punkte $\left[1:1:1\right]$ und $\left[2:2:2\right]$ gleich, aber das Polynom $f (x, y, z) = x^{2} - y$ verschwindet bei der ersten Darstellung, nicht aber bei der zweiten.

Dieses Problem tritt nicht auf, wenn man sich auf homogene Polynome beschränkt: Zwar können sich auch hier die Werte, die das Polynom bei verschiedenen Darstellungen annimmt, unterscheiden, aber die Eigenschaft, ob das Polynom eine Nullstelle hat, ist von der Wahl der Darstellung des Punktes unabhängig.

Um zu einer affinen Kurve die zugehörige projektive Kurve zu finden, homogenisiert man das definierende Polynom: In jedem Term fügt man eine so große $z$-Potenz ein, dass sich ein homogenes Polynom ergibt: Aus der Gleichung $x^{2}-y+1 = 0$ wird also $x^{2}-yz+z^{2} = 0$.

Der umgekehrte Vorgang wird als Dehomogenisieren bezeichnet. Hier setzt man in das homogene Polynom für $z$ (oder eine Variable, falls man nach einer anderen Variablen dehomogenisieren möchte) den Wert 1 ein.

\paragraph{Schnitte zweier Kurven}

Betrachtet man beispielsweise eine Gerade und eine Parabel, so erwartet man im Allgemeinen zwei gemeinsame Punkte. Durch verschiedene Umstände können auch weniger gemeinsame Punkte auftreten, diese Fälle kann man jedoch alle durch spezielle Voraussetzungen oder Definitionen umgehen:

\begin{itemize}
\item Die Gerade und die Parabel können gar keinen Schnittpunkt besitzen, dies umgeht man, indem man voraussetzt, dass der zu Grunde liegende Körper algebraisch abgeschlossen ist.
\item Die Gerade kann durch den Scheitel der Parabel senkrecht nach oben verlaufen und somit nur einen Punkt mit ihr gemeinsam haben. Dies tritt nicht auf, wenn man sich in der projektiven Ebene befindet, hier haben Gerade und Parabel in diesem Fall einen weiteren Schnittpunkt im Unendlichen.
\item Die Gerade kann eine Tangente an die Parabel sein. Auch in diesem Fall existiert nur ein gemeinsamer Punkt. Mit einer geeigneten Definition von Schnittmultiplizität kann dieser Schnittpunkt jedoch doppelt gezählt werden.
\end{itemize}
Unter den obigen Voraussetzungen gilt der Satz von \textsc{Bézout}: Die Anzahl der gemeinsamen Punkte zweier projektiver ebener algebraischer Kurven von Grad $n$ und $m$ ohne gemeinsame Komponenten beträgt $n m$.

\paragraph{Beispiele für algebraische Kurven}

\subparagraph{Kurven nach Grad geordnet}

\begin{itemize}
\item Die ebenen algebraischen Kurven von Grad 1 sind genau die Geraden. Die Gleichungen  $x=0$ und $y=0$ beispielsweise beschreiben die Koordinatenachsen, die Gleichung $x=y$ oder äquivalent $x-y=0$ die erste Winkelhalbierende.
\item Die ebenen algebraischen Kurven von Grad 2 (Quadriken) sind genau die Kegelschnitte, darunter der durch $x^{2}+y^{2}=1$ beschriebene Einheitskreis und die Normalparabel mit der Formel $y=x^{2}$. Die reduziblen Kurven sind dabei die entarteten Kegelschnitte.
\item Bei Grad 3 (Kubiken) treten zum ersten Mal irreduzible Kurven mit Singularitäten auf, zum Beispiel die \textsc{Nei}lsche Parabel mit der Gleichung $y^{3}=x^{2}$ und das kartesische Blatt, das durch $x^{3} + y^{3} - 3xy = 0$ gegeben ist. Die elliptischen Kurven sind ebenfalls wichtige Beispiele ebener algebraischer Kurven von Grad 3.
\item Eine Spirische Kurve ist eine algebraische Kurve vom Grad 4 (Quartik). Sonderfälle davon sind die \textsc{Cassini}sche Kurve, Lemniskate von \textsc{Bernoulli} und Lemniskate von \textsc{Booth}.
\item Kurven vom Grad 5 werden als Quintiken bezeichnet, Kurven vom Grad 6 als Sextiken.
\end{itemize}

\subparagraph{Kurven nach Geschlecht geordnet}

\begin{itemize}
\item Kurven vom Geschlecht 0 sind rationale Kurven.
\item Kurven vom Geschlecht 1 sind elliptische Kurven.
\item Zu den Kurven vom Geschlecht mindestens 2 gehören hyperelliptische Kurven, die \textsc{Klein}sche Quartik $x^{3}y+y^{3}z+z^{3}x = 0$ und die \textsc{Fermat}-Kurve $x^{n}+y^{n}-z^{n} = 0$.
\end{itemize}

\paragraph{Duale Kurve}

Eine Kurve kann statt durch ihre Punkte auch durch ihre Tangenten beschrieben werden. Ein in diesem Zusammenhang wichtiges Problem ist die Frage, wie viele Tangenten sich „in der Regel“ von einem nicht auf der Kurve liegenden Punkt aus an eine Kurve $n$-ter Ordnung legen lassen. Diese Anzahl heißt die Klasse der Kurve. Für eine solche Kurve ohne singuläre Punkte (wie etwa Doppelpunkte oder Spitzen) ist diese Klasse gleich $n (n-1)$. Jeder Doppelpunkt verkleinert die Klasse um 2 und jede Spitze um 3. Das ist eine Hauptaussage der \textsc{Plücker}schen Formeln, die sich außerdem noch mit der Anzahl der Wendepunkte und Doppeltangenten befassen. Hierfür muss der Grundkörper algebraisch abgeschlossen sein.

So ist zum Beispiel eine singularitätenfreie Kurve dritter Ordnung von 6. Klasse, besitzt sie einen Doppelpunkt, ist sie von vierter, und wenn sie eine Spitze hat, von dritter Klasse.

Im homogenen Fall haben Geraden, also auch Tangenten, eine Gleichung der Form $ax+by+cz = 0$, wobei $a$, $b$ und $c$ nicht alle verschwinden dürfen und mit einer beliebigen von 0 verschiedenen Zahl multipliziert werden dürfen. Damit kann man dieser Geraden den Punkt $[a:b:c]$ zuordnen. Aus der Menge der Tangenten an eine gegebene Kurve erhält man somit eine Punktemenge in der projektiven Ebene. Es stellt sich heraus, dass diese Menge selbst wieder eine algebraische Kurve ist, die sogenannte duale Kurve.

Dual zueinander sind folgende Begriffe:
\begin{itemize}
\item Kurvenpunkt und Kurventangente
\item Doppelpunkt und Doppeltangente
\item Wendepunkt und Spitze
\item Ordnung und Klasse
\end{itemize}
Die duale Kurve der dualen Kurve ist wieder die ursprüngliche Kurve.

\ldots

\section{Kinematik}

refer to Wikipedia!

\subsection{Bewegungszustand}

Als Bewegungszustand bezeichnet man in der Mechanik die momentane Bewegung eines Körpers. Diese kann in einer Translations- und/oder Rotationsbewegung bestehen.

Hinsichtlich der Translationsbewegung wird der Bewegungszustand eines Körpers gekennzeichnet durch die Geschwindigkeit seines Massenmittelpunkts mit ihren momentanen Werten für Betrag und Richtung, also in vektorieller Form. Wird der Körper schneller oder langsamer, oder ändert er auch nur seine Bewegungsrichtung, ändert sich sein Bewegungszustand. Ein quantitatives Maß für den translatorischen Bewegungszustand ist der Impuls.

Rotiert der Körper um seinen Massenmittelpunkt, gehört auch diese Rotationsbewegung zu seinem Bewegungszustand. Ein Maß für diesen Teil des Bewegungszustandes ist der Drehimpuls.

Die gleichförmige Bewegung ist ein Beispiel für eine Bewegung, bei der der Bewegungszustand unverändert bleibt. Dagegen wird bei einer gleichförmigen Kreisbewegung eines Körpers der Bewegungszustand nicht beibehalten, denn hier ändert sich fortwährend die Richtung der Geschwindigkeit.

Der Trägheitssatz oder das erste \textsc{Newton}sche Gesetz der Mechanik besagt, dass jeder Körper, der nicht von äußeren Kräften beeinflusst wird, in seinem Bewegungszustand verharrt. Mit anderen Worten ist das Bestreben eines Körpers, seinen Bewegungszustand beizubehalten, Ausdruck seiner Trägheit. Insbesondere bewegt sich bei einem Körper ohne äußere Kräfte der Massenmittelpunkt mit gleichbleibender Geschwindigkeit geradlinig weiter. Im Fall der Rotation um den Massenmittelpunkt bleibt dann der Drehimpuls nach Betrag und Richtung konstant, jedoch nicht unbedingt die Drehachse und Rotationsgeschwindigkeit.

Im scheinbaren Gegensatz zum Trägheitssatz ist es Alltagserfahrung, dass ein sich bewegender Körper gerade dann langsamer wird, wenn keine Kraft feststellbar ist, die ihn antreibt. Das erklärt sich dadurch, dass bei jeder Bewegung Bremskräfte wie der Luftwiderstand und sonstige Reibungskräfte vorhanden sind. Diese sind für die Abbremsung des Körpers, also die Änderung seines Bewegungszustandes, ursächlich. Allgemein besagt das zweite \textsc{Newton}sche Gesetz der Mechanik, wie sich der Bewegungszustand ändert, wenn eine resultierende äußere Kraft auf den Körper wirkt.

\subsection{Geschwindigkeit}

Die Geschwindigkeit ist neben dem Ort und der Beschleunigung einer der grundlegenden Begriffe der Kinematik, eines Teilgebiets der Mechanik. Die Geschwindigkeit beschreibt, wie schnell und in welcher Richtung ein Körper oder ein Phänomen (beispielsweise ein Wellenberg) im Lauf der Zeit seinen Ort verändert. Eine Geschwindigkeit wird durch ihren Betrag und die Bewegungsrichtung angegeben; es handelt sich also um eine vektorielle Größe. Als Formelzeichen ist $\vec {v}$ üblich nach dem lateinischen bzw. englischen Wort für Geschwindigkeit (lateinisch velocitas, englisch velocity).

Oft wird mit dem Wort Geschwindigkeit nur ihr Betrag gemeint (Formelzeichen $v$), der anschaulich gesprochen das momentane Tempo (englisch speed) der Bewegung wiedergibt, wie es beispielsweise im Auto vom Tachometer angezeigt wird. $v$ gibt an, welche Wegstrecke ein Körper innerhalb einer bestimmten Zeitspanne zurücklegt, wenn die Geschwindigkeit entsprechend lange konstant bleibt; es handelt sich um eine skalare Größe. Die international verwendete Einheit ist Meter pro Sekunde (m/s), gebräuchlich sind auch Kilometer pro Stunde (km/h) und – vor allem in der See- und Luftfahrt – Knoten (kn).

Die höchstmögliche Geschwindigkeit, mit der sich die Wirkung einer bestimmten Ursache räumlich ausbreiten kann, ist die Lichtgeschwindigkeit $c$. Diese Obergrenze gilt also auch für jedwede Informationsübertragung. Körper, die eine Masse besitzen, können sich nur mit geringeren Geschwindigkeiten als $c$ bewegen.

Eine Geschwindigkeitsangabe ist immer relativ zu einem Bezugssystem zu verstehen. Ruht ein Körper in einem Bezugssystem, so hat er in einem anderen Bezugssystem, welches sich gegenüber dem ersten mit der Geschwindigkeit $\vec {v}$ bewegt, die entgegengesetzt gleich große Geschwindigkeit $-\vec {v}$.

\paragraph{Definition}

Bewegt sich ein Objekt entlang einer Bahnkurve, wobei es sich zum Zeitpunkt $t$ im Punkt $A$ und zu einem späteren Zeitpunkt $t + \Delta t$ im Punkt $B$ befindet, so ergibt sich seine Geschwindigkeit $\vec {v} (t)$ zum Zeitpunkt $t$ (bzw. im Punkt $A$) näherungsweise aus der Ortsänderung $\Delta \vec{r}$ und der dafür benötigten Zeitspanne $\Delta t$ gemäß
$$\vec{v} (t) \approx \frac {\Delta {\vec {r}}}{\Delta t}.$$

Dabei ist $\Delta {\vec {r}}={\vec {r}}(t+\Delta t)-{\vec {r}}(t)={\vec {r}}_{B}-{\vec {r}}_{A}$ der Verbindungsvektor von Punkt $A$ zu Punkt $B$. Geometrisch entspricht er der Sehne des Kurvenabschnitts zwischen den beiden Punkten. Außerdem gibt er näherungsweise die Richtung der Geschwindigkeit an. Aus der Näherung erhält man die exakte Definition für die Momentangeschwindigkeit zum Zeitpunkt $t$ (bzw. am Punkt $A$), wenn man das Zeitintervall $\Delta t$ gegen null gehen lässt. Dabei rückt (aufgrund der Stetigkeit der Bewegung) der Punkt $B$ beliebig nah an den Punkt $A$ heran, so dass auch $\Delta {\vec {r}}$ gegen null geht; der Quotient ${\tfrac {\Delta {\vec {r}}}{\Delta t}}$ hingegen strebt einem Grenzwert zu, der gerade der Momentangeschwindigkeit entspricht:
$${\vec {v}}(t)=\lim _{\Delta t\rightarrow 0}{\frac {{\vec {r}}(t+\Delta t)-{\vec {r}}(t)}{\Delta t}}.$$

Hierfür schreibt man auch
$$
\vec{v} (t) = \frac{\mathrm{d} \vec{r} }{\mathrm{d} t} \quad \text{oder} \quad \vec{v} (t) = \dot{\vec{r}},$$
da es sich um eine Zeitableitung handelt.

Da die Sehne $\Delta {\vec {r}}$ beim Grenzübergang die Richtung der Tangente an die Bahnkurve annimmt, ist dies auch die Richtung der Momentangeschwindigkeit.

Der Betrag der Momentangeschwindigkeit (das „Tempo“ oder die Bahngeschwindigkeit) ist durch den Betrag des Geschwindigkeitsvektors
$$v=\left|{\vec {v}}\right|=\left|\lim _{\Delta t\rightarrow 0}{\frac {\Delta {\vec {r}}}{\Delta t}}\right|=\left|{\frac {\mathrm {d} {\vec {r}}}{\mathrm {d} t}}\right|=\left|{\dot {\vec {r}}}\right|$$
gegeben, wobei $\left|{\vec {r}}\right| = r$ der Betrag des Ortsvektors ${\vec {r}}$ ist. Die Bahngeschwindigkeit ist nicht dasselbe wie $\left|{\dot {r}}\right|$, wie man beispielsweise an der Kreisbewegung mit $r={\text{konst.}},\ v\neq 0,\ {\dot {r}}=0$ sehen kann.

Den Betrag der Momentangeschwindigkeit kann man auch erhalten, wenn man statt der dreidimensionalen Bahnkurve nur die Weglänge (Symbol $s$) entlang der Bahnkurve berücksichtigt. Man bildet hierfür den Grenzwert des Quotienten aus zurückgelegter Weglänge $\Delta s$ und benötigter Zeit $\Delta t$:
$$v=\lim _{\Delta t\rightarrow 0}{\frac {\Delta s}{\Delta t}}={\frac {\mathrm {d} s}{\mathrm {d} t}}={\dot {s}}$$

\paragraph{Anfangsgeschwindigkeit}

Wenn die Geschwindigkeit eines Körpers oder Massenpunkts zu Beginn eines bestimmten Bewegungsabschnittes interessiert, wird sie auch als Anfangsgeschwindigkeit (Formelzeichen meist $v_{0}$) bezeichnet.

Die Anfangsgeschwindigkeit ist eine der Anfangsbedingungen beim Lösen der Bewegungsgleichungen in der klassischen Mechanik, zum Beispiel für numerische Simulationen in der Himmelsmechanik. Sie ist ein wichtiger Parameter z. B. für die Flugbahn beim senkrechten und schrägen Wurf sowie für die Reichweite von Schusswaffen oder Raketen.

\paragraph{Endgeschwindigkeit}

Die Endgeschwindigkeit (auch: Grenzgeschwindigkeit) ist die Geschwindigkeit, die ein Objekt am Ende seiner Beschleunigung erreicht hat.

Ein Objekt erreicht seine Endgeschwindigkeit, wenn die bremsenden Kräften, beim freien Fall insbesondere der mit der Fallgeschwindigkeit wachsende Luftwiderstand, durch Zu- oder Abnahme der Geschwindigkeit so stark geworden sind, dass sich ein Kräftegleichgewicht aller beteiligten Kräfte ausbildet. Die Beschleunigung bei Erreichen der Endgeschwindigkeit ist daher null.

Der Begriff wird auch in der Technik verwendet. Im Automobilsektor spricht man zum Beispiel von Endgeschwindigkeit oder Maximalgeschwindigkeit, wenn sich das Fahrzeug begrenzt durch Motorleistung und äußere Umstände nicht weiter beschleunigen lässt.

\paragraph{Einfache Sonderfälle}

\subparagraph{Geradlinig gleichförmige Bewegung}

Von geradlinig gleichförmiger Bewegung spricht man, wenn die Geschwindigkeit ${\vec {v}}$ des Objekts immer die gleiche ist (d. h. gleich in Betrag und Richtung), was gleichbedeutend mit der Beschleunigung ${\vec {a}}(t)={\vec {0}}$ ist. In diesem Fall bewegt sich das Objekt auf einer Geraden, entlang derer man üblicherweise das Koordinatensystem ausrichtet, so dass die Geschwindigkeit eine skalare Größe $v$ ist. Dann gilt:
$$v={\frac {s}{t}}.$$

Hierbei ist $s$ der in der Zeitspanne $t$ zurückgelegte Weg.

\subparagraph{Gleichmäßig beschleunigte Bewegung}

Bei einer gleichmäßig beschleunigten Bewegung hat die Beschleunigung $\vec {a}$ stets den gleichen Betrag und die gleiche Richtung. Ist die Bewegungsrichtung parallel zu $\vec {a}$, so bewegt sich das Objekt auf einer Geraden. Praktischerweise richtet man das Koordinatensystem in Richtung der Bewegung aus und schreibt Beschleunigung und Geschwindigkeit als Skalar. Dann gilt
$$v(t) = a\cdot t+v_{0}.$$

Hierbei steht ${v}_{0}$ für die Anfangsgeschwindigkeit.

\subparagraph{Kreisbewegung}

Die Geschwindigkeit einer Kreisbewegung bezeichnet man als Umfangsgeschwindigkeit oder allgemein als Bahngeschwindigkeit:
$${\vec {v}}={\vec {\omega }}\times {\vec {r}}$$

Hierbei steht $\omega$ für die Winkelgeschwindigkeit und $r$ für den Radius der Kreisbewegung.

Bei einer gleichförmigen Kreisbewegung ist der Betrag der Umfangsgeschwindigkeit konstant und kann als Quotient aus der auf der Kreisbahn zurückgelegten Streckenlänge und der dafür benötigten Zeit $T$ ausgedrückt werden:
$$v={\frac {2\cdot \pi \cdot r}{T}}$$

\paragraph{Beziehungen zu anderen physikalischen Größen}

\subparagraph{Beziehung zum Ort}

Bewegt sich ein Massepunkt im Raum (dreidimensionale Bewegung), so kann man aus dem zeitlichen Verlauf des Geschwindigkeitsvektors $\vec {v}$ auf die Verschiebung des Massepunkts schließen, indem man $\vec {v}$ über die Zeit integriert:
$${\vec {r}}_{2}-{\vec {r}}_{1}=\int _{t_{1}}^{t_{2}}{\vec {v}}(t)\,\mathrm {d} t,$$
wobei ${\vec {r}}_{2} = {\vec {r}}(t_{2})$ und ${\vec {r}}_{1}={\vec {r}}(t_{1})$. Hieraus erhält man die Position des Massepunktes zum Endzeitpunkt als
$${\vec {r}}_{2}={\vec {r}}_{1}+\int _{t_{1}}^{t_{2}}{\vec {v}}(t)\,\mathrm {d} t.$$

Bewegt sich der Massepunkt auf einer Geraden (geradlinige bzw. eindimensionale Bewegung), so richtet man das Koordinatensystem üblicherweise entlang dieser Geraden aus. Die Position des Teilchens wird dann allein durch die Koordinate $x = x (t)$ beschrieben. Die oben stehende Formel vereinfacht sich in diesem Fall zu
$$x_{2}-x_{1}=\int _{t_{1}}^{t_{2}}v(t)\,\mathrm {d} t.$$
Dies ist die kinematische Version des Hauptsatzes der Differential- und Integralrechnung.

\subparagraph{Beziehung zur Wegstrecke}

Die zurückgelegte Strecke $s$ erhält man durch Integration des Geschwindigkeitsbetrags $|\vec {v}|$ über die Zeit:
$$s=\int _{t_{1}}^{t_{2}}|{\vec {v}}(t)|\,\mathrm {d} t.$$
Im einfachsten Fall, nämlich bei konstanter Geschwindigkeit, wird daraus $s = v \cdot (t_{2} - t_{1})$.

\subparagraph{Beziehung zu Beschleunigung und Ruck}

Die erste Zeitableitung der Geschwindigkeit ist die Beschleunigung: ${\vec {a}} (t) = {\dot {\vec {v}}} (t) = {\ddot {\vec {r}}} (t)$.

Umgekehrt gewinnt man die Geschwindigkeit aus der Beschleunigung durch Integration:
$${\vec {v}}(t)={\vec {v}}_{0}+\int _{0}^{t}{\vec {a}}(\tau )\,\mathrm {d} \tau.$$
Findet die Bewegung auf einer Geraden statt, so richtet man das Koordinatensystem praktischerweise in Richtung der Bewegung aus, und erhält die skalare Gleichung
$$v(t)=v_{0}+\int _{0}^{t}a(\tau )\,\mathrm {d} \tau.$$

Die zweite Zeitableitung der Geschwindigkeit ergibt den Ruck einer Bewegung: ${\vec {j}} (t) = {\ddot {\vec {v}}} (t) = {\dot {\vec {a}}} (t)$. Umgekehrt gewinnt man die Geschwindigkeit aus dem Ruck durch zweifache Integration.

\subparagraph{Beziehung zu Impuls und kinetischer Energie}

Der Impuls – also anschaulich gesprochen der „Schwung“ – eines Körpers der Masse $m$ berechnet sich nach $\vec {p} = m \cdot \vec {v}$, während die kinetische Energie durch $E_{\mathrm{kin}} = {\tfrac {1}{2}} mv^{2} = {\tfrac {p^{2}}{2m}}$ gegeben ist. Streng genommen gelten die letzten beiden Gleichungen nur näherungsweise für den sogenannten nichtrelativistischen Fall, also für Geschwindigkeiten, die viel kleiner als die Lichtgeschwindigkeit sind.

\paragraph{Geschwindigkeiten und Bezugssystem}
 
Je nach verwendetem Bezugssystem bzw. Koordinatensystem haben sich verschiedene Bezeichnungen eingebürgert:

Im homogenen Schwerefeld wird oft ein kartesisches Koordinatensystem verwendet. Geschwindigkeiten, die parallel zur Fallbeschleunigung ${\vec {g}}$ gerichtet sind, werden meist als Vertikalgeschwindigkeiten, solche, die orthogonal zu dieser Richtung sind, als Horizontalgeschwindigkeiten bezeichnet.

Bei Polarkoordinaten ist die Radialgeschwindigkeit ${\vec {v}}_{\mathrm {r} }$ die Komponente des Geschwindigkeitsvektors in Richtung des Ortsvektors, also längs der Verbindungslinie zwischen dem bewegten Objekt und dem Koordinatenursprung. Die Komponente senkrecht dazu heißt Umfangsgeschwindigkeit ${\vec {v}}_{\perp}$. Somit ergibt sich: ${\vec {v}}={\vec {v}}_{\perp }+{\vec {v}}_{\mathrm {r} }$. Das Vektorprodukt aus der Winkelgeschwindigkeit und dem Ortsvektor ergibt die Umfangsgeschwindigkeit: ${\vec {v}}_{\perp }={\vec {\omega }}\times {\vec {r}}$.

Bei Bewegungen auf einer Kreisbahn um den Koordinatenursprung, aber auch nur in diesem Fall, ist die Radialgeschwindigkeit null und die Umfangsgeschwindigkeit gleich der Tangentialgeschwindigkeit, also der Bahngeschwindigkeit längs der Tangente an die Bahnkurve.

Aus der Änderung des Abstands zum Koordinatenursprung (Radius) folgt die Radialgeschwindigkeit: ${\vec {v}}_{\mathrm {r} }={\dot {r}}\,{\frac {\vec {r}}{|{\vec {r}}|}}$.

Setzt man voraus, dass es ein allgemein gültiges Bezugssystem gibt, so nennt man die Geschwindigkeiten, die in diesem System gemessen werden, Absolutgeschwindigkeiten. Geschwindigkeiten, die sich auf einen Punkt beziehen, der sich selbst in diesem System bewegt, heißen Relativgeschwindigkeiten.

Das Relativitätsprinzip besagt jedoch, dass es keinen physikalischen Grund gibt, warum man ein bestimmtes Bezugssystem herausgreifen und gegenüber anderen Systemen bevorzugen sollte. Sämtliche physikalischen Gesetze, die in einem Inertialsystem gelten, gelten auch in jedem anderen. Welche Bewegungen man als „absolut“ ansieht, ist also vollkommen willkürlich. Deswegen wird der Begriff der Absolutgeschwindigkeit spätestens seit der speziellen Relativitätstheorie vermieden. Stattdessen sind alle Geschwindigkeiten Relativgeschwindigkeiten. Aus diesem Relativitätsprinzip folgt, zusammen mit der Invarianz der Lichtgeschwindigkeit, dass Geschwindigkeiten nicht – wie im obigen Beispiel stillschweigend angenommen – einfach addiert werden dürfen. Stattdessen gilt das relativistische Additionstheorem für Geschwindigkeiten. Dies macht sich jedoch erst bei sehr hohen Geschwindigkeiten bemerkbar.

\paragraph{Geschwindigkeit zahlreicher Teilchen}

Betrachtet man ein System aus vielen Teilchen, so ist es meist nicht mehr sinnvoll oder überhaupt möglich, für jedes einzelne Teilchen eine bestimmte Geschwindigkeit anzugeben. Stattdessen arbeitet man mit der Geschwindigkeitsverteilung, die angibt, wie häufig ein bestimmter Bereich von Geschwindigkeiten in dem Teilchenensemble auftritt. In einem idealen Gas gilt beispielsweise die Maxwell-Boltzmann-Verteilung (siehe nebenstehende Abbildung): Die meisten Teilchen haben eine Geschwindigkeit in der Nähe der wahrscheinlichsten Geschwindigkeit, die durch das Maximum der Maxwell-Boltzmann-Verteilung angezeigt wird. Sehr kleine und sehr große Geschwindigkeiten kommen auch vor, werden aber nur von ganz wenigen Teilchen angenommen. Die Lage des Maximums ist temperaturabhängig. Je heißer das Gas ist, desto höher ist die wahrscheinlichste Geschwindigkeit. Mehr Teilchen erreichen dann hohe Geschwindigkeiten. Dies zeigt, dass die Temperatur ein Maß für die mittlere kinetische Energie der Teilchen ist. Doch sind auch bei niedrigen Temperaturen sehr hohe Geschwindigkeiten nicht vollständig ausgeschlossen. Mit der Geschwindigkeitsverteilung lassen sich viele physikalische Transportphänomene erklären, wie z. B. die Diffusion in Gasen.

\paragraph{Strömungsgeschwindigkeit eines Fluids}

Die mittlere Strömungsgeschwindigkeit eines Gases oder einer Flüssigkeit $v_{\mathrm {A} }$ ergibt sich aus der Volumenstromstärke $Q={\tfrac {\mathrm {d} V}{\mathrm {d} t}}$ durch den Strömungsquerschnitt $A$:
$$v_{\mathrm {A} }={\frac {Q}{A}}$$
Allerdings können sich die lokalen Strömungsgeschwindigkeiten sehr stark voneinander unterscheiden. Beispielsweise ist die Geschwindigkeit in der Mitte eines idealen Rohres am größten und fällt durch die Reibung zur Wandung hin bis auf Null ab. Man muss daher die Strömung eines Mediums als Vektorfeld auffassen. Wenn die Geschwindigkeitsvektoren zeitlich konstant sind, spricht man von einer stationären Strömung. Verhalten sich die Geschwindigkeiten im Gegensatz dazu chaotisch, so handelt es sich um eine turbulente Strömung. Bei der Charakterisierung des Strömungsverhaltens hilft die Reynoldszahl, die die Strömungsgeschwindigkeit in Relation zu der Abmessungen des angeströmten Körpers und zur Viskosität des Fluids setzt.

Mathematisch wird das Verhalten der Geschwindigkeiten durch die Navier-Stokes-Gleichungen modelliert, die als Differenzialgleichungen die Geschwindigkeitsvektoren mit inneren und äußeren Kräften in Beziehung setzen. Damit haben sie für die Bewegung eines Fluids eine ähnliche Bedeutung wie die Grundgleichung der Mechanik für Massenpunkte und starre Körper.

\paragraph{Geschwindigkeit von Wellen}

Die komplexe Bewegung von Wellen macht es nötig, verschiedene Geschwindigkeitsbegriffe zu verwenden. (Insbesondere kann mit dem Wort Ausbreitungsgeschwindigkeit verschiedenes gemeint sein.)

Die Auslenkungsgeschwindigkeit mechanischer Wellen wird als Schnelle bezeichnet. Das bekannteste Beispiel ist die Schwingungsgeschwindigkeit der Luftteilchen in einer Schallwelle.

Die Geschwindigkeit, mit der sich ein Punkt bestimmter Phase vorwärts bewegt, heißt Phasengeschwindigkeit. Es gilt: $v_{\mathrm {p} }={\frac {\lambda }{T}}={\frac {\omega }{k}}$. Hierbei sind $\lambda$ die Wellenlänge, $T$ die Periodendauer, $\omega$ die Kreisfrequenz und $k$ die Kreiswellenzahl. Die Geschwindigkeit, mit der sich die Wellenkämme im Meer fortbewegen, ist ein typisches Beispiel für eine Phasengeschwindigkeit.

Die Geschwindigkeit, mit der sich ein ganzes Wellenpaket bewegt, wird Gruppengeschwindigkeit genannt: $v_{\mathrm{g}} = {\frac {\partial \mathbf {\omega } }{\partial \mathbf {k} }}$.

Phasen- und Gruppengeschwindigkeit stimmen nur in seltenen Fällen überein (z. B. Ausbreitung von Licht im Vakuum). In der Regel unterscheiden sie sich. Ein anschauliches extremes Beispiel ist die Fortbewegung von Schlangen: Fasst man die Schlange als eine Welle auf, so ist die Geschwindigkeit ihres Vorankommens eine Gruppengeschwindigkeit. Die Phasengeschwindigkeit ist beim Schlängeln jedoch Null, denn die Stellen, an denen sich der Körper der Schlange nach rechts oder links krümmt, sind durch den Untergrund vorgegeben und bewegen sich nicht über den Boden.

In aller Regel ist die Phasengeschwindigkeit einer physikalischen Welle von der Frequenz bzw. der Kreiswellenzahl abhängig. Diesen Effekt bezeichnet man als Dispersion. Er ist unter anderem dafür verantwortlich, dass Licht verschiedener Wellenlänge von einem Prisma unterschiedlich stark gebrochen wird.

\paragraph{Relativitätstheorie}

Aus den Gesetzen der klassischen Physik folgt für Geschwindigkeiten unter anderem:
\begin{itemize}
\item Die Messwerte für Längen und Zeiten sind unabhängig vom Bewegungszustand (und damit der Geschwindigkeit) des Beobachters. Insbesondere stimmen alle Beobachter darin überein, ob zwei Ereignisse gleichzeitig stattfinden oder nicht.
\item Bei einem Wechsel des Bezugssystems gilt die Galilei-Transformation. Dies bedeutet, dass Geschwindigkeiten von Bewegungen, die sich überlagern, vektoriell addiert werden dürfen.
\item Es gibt keine theoretische Obergrenze für die Geschwindigkeit von Bewegungen.
\item Zwar wird es von den Gesetzen der klassischen Physik nicht verlangt, aber es wurde vor Einstein allgemein angenommen, dass es für alle Geschwindigkeiten ein universelles Bezugssystem, den „Äther“, gebe. Wenn dem so wäre, müsste die Ausbreitungsgeschwindigkeit von elektromagnetischen Wellen vom Bewegungszustand des Empfängers abhängen.
\end{itemize}
Letztere Abhängigkeit ließ sich mit dem Michelson-Morley-Experiment nicht nachweisen. Einstein postulierte, dass das Relativitätsprinzip, das bereits aus der klassischen Mechanik bekannt war, auch auf alle anderen Phänomene der Physik, insbesondere die Ausbreitung des Lichts, angewendet werden müsse und dass die Lichtgeschwindigkeit unabhängig vom Bewegungszustand des Senders sei. Daraus folgerte er, dass die oben genannten Aussagen der klassischen Mechanik modifiziert werden müssen.[3] Im Detail heißt dies:
\begin{itemize}
\item Die Messwerte für Längen und Zeiten sind abhängig vom Bewegungszustand (und damit der Geschwindigkeit) des Beobachters (siehe Zeitdilatation und Längenkontraktion). Auch die Gleichzeitigkeit ist relativ.
\item Bei einem Wechsel des Bezugssystems gilt die Lorentz-Transformation. Dies bedeutet, dass Geschwindigkeiten von Bewegungen, die sich überlagern, nicht einfach vektoriell addiert werden dürfen.
\item Bewegungen von Körpern können nur mit Geschwindigkeiten erfolgen, die geringer als die Lichtgeschwindigkeit sind. Auch Informationen können nicht schneller als das Licht übertragen werden.
\item Es gibt keinen „Äther“.
\end{itemize}
Die Effekte, die sich aus der speziellen Relativitätstheorie ergeben, machen sich jedoch erst bei sehr hohen Geschwindigkeiten bemerkbar. Der Lorentz-Faktor, der für Zeitdilatation und Längenkontraktion maßgeblich ist, ergibt erst für Geschwindigkeiten von $v > 4{,}2 \cdot 10^{7}\,\mathrm {\tfrac {m}{s}}$ eine Abweichung von mehr als einem Prozent. Folglich stellt die klassische Mechanik selbst für die schnellsten bisher gebauten Raumfahrzeuge eine äußerst präzise Näherung dar.

\subsection{Beschleunigung}

Die Beschleunigung ist eine physikalische Größe, die die Änderung des Bewegungszustands eines Körpers angibt. Je nach Richtung der Beschleunigung wird ein beschleunigter Körper schneller oder langsamer oder es ändert sich seine Bewegungsrichtung. Die Beschleunigung ist eine zentrale Größe in der Kinematik.

Die Beschleunigung ist die momentane zeitliche Änderungsrate der Geschwindigkeit, also ${\vec {a}}={\frac {{\text{d}}{\vec {v}}}{{\text{d}}t}}$. Sie ist damit eine vektorielle Größe.

Für Insassen von Fahrzeugen sind Beschleunigungen durch die damit verbundenen Trägheitskräfte erfahrbar.

\paragraph{Einführung}

Nach dem ersten Newtonschen Gesetz bewegen sich alle Körper in Inertialsystemen mit konstanter Geschwindigkeit auf geradlinigen Bahnen, wenn keine Kräfte auf sie wirken. Man sagt: Ihr Bewegungszustand ist konstant. Falls doch eine Kraft auf einen Körper einwirkt, ändert sich sein Bewegungszustand.

In der Umgangssprache bezeichnet Beschleunigung oft nur eine Steigerung des „Tempos“, also des Betrags der Geschwindigkeit. Im physikalischen Sinn ist aber jede Änderung einer Bewegung eine Beschleunigung, z. B. auch eine Abnahme des Geschwindigkeitsbetrages – wie ein Bremsvorgang – oder eine reine Richtungsänderung bei gleichbleibendem Geschwindigkeitsbetrag – wie bei einer Kurvenfahrt mit einem Auto.

Zunächst betrachten wir nur Bewegungen entlang einer Geraden, also eindimensionale Bewegungen. Zu zwei Zeitpunkten hat der Körper die Geschwindigkeiten $v_{1}$ und $v_{2}$. Seine Geschwindigkeit hat sich also in der Zeitspanne dazwischen $\Delta t=t_{2}-t_{1}$ geändert. Die Geschwindigkeitsänderung beträgt $\Delta v=v_{2}-v_{1}$. Man definiert nun die mittlere Beschleunigung als die mittlere Änderungsrate der Geschwindigkeit. Die Beschleunigung $a$ gibt also an, wie schnell diese Geschwindigkeitsänderung erfolgt. Es gilt somit:
$${\overline {a}}={\frac {\Delta v}{\Delta t}}$$
Wenn die Beschleunigung dasselbe Vorzeichen hat wie die Geschwindigkeit, dann nimmt der Betrag der Geschwindigkeit zu. Wenn sich beide Vorzeichen unterscheiden, nimmt der Betrag der Geschwindigkeit ab (die Richtung der Geschwindigkeit kann sich auch umkehren). Ähnlich wie bei der Durchschnittsgeschwindigkeit lässt sich mit obiger Gleichung nur die durchschnittliche Beschleunigung berechnen. Nur wenn die Geschwindigkeit sich linear mit der Zeit ändert, also im Falle einer konstanten Beschleunigung, entspricht dies auch zu jedem Zeitpunkt der momentanen Beschleunigung. Um auch in anderen Fällen zur momentanen Beschleunigung zu gelangen, muss man den Grenzwert für sehr kleine Zeitintervalle bilden und gelangt so zur zeitlichen Ableitung der Geschwindigkeit:
$$a(t)=\lim _{\Delta t \rightarrow 0}{\frac {\Delta v}{\Delta t}}={\frac {\mathrm {d} v}{\mathrm {d} t}}={\dot {v}}(t)$$

\paragraph{Gleichmäßig beschleunigte Bewegung}

Von einer gleichmäßig beschleunigten Bewegung spricht man, wenn die Beschleunigung konstant ist. Dann gilt für die Geschwindigkeit
$$v(t)=at+v_{0}$$
und für die zurückgelegte Strecke
$$s(t)={\frac {1}{2}}at^{2}+v_{0}t+s_{0}$$
mit dem Startpunkt $s_{0}$ und der Anfangsgeschwindigkeit $v_{0}$.

\paragraph{Allgemeine Definition}

Im Allgemeinen erfolgt die Bewegung nicht zwangsläufig geradlinig, sondern im zwei- oder dreidimensionalen Fall. Bei einer konstanten Beschleunigung, muss die Differenz der Geschwindigkeiten $\Delta {\vec {v}}={\vec {v}}(t_{2})-{\vec {v}}(t_{1})$ vektoriell bestimmt werden, wie in der Abbildung veranschaulicht. Wenn sich die Beschleunigung während der betrachteten Zeitspanne ändert, erhält man mit obiger Rechnung die mittlere Beschleunigung, auch Durchschnittsbeschleunigung genannt.
$$a={\frac {\Delta {\vec {v}}}{\Delta t}}.$$

Um die Beschleunigung für einen bestimmten Zeitpunkt statt für ein Zeitintervall zu berechnen, muss man – wie oben beschrieben – vom Differenzenquotienten zum Differentialquotienten übergehen. Die Beschleunigung ist dann die erste Ableitung der Geschwindigkeit nach der Zeit:
$${\vec {a}}(t)={\frac {\mathrm {d} {\vec {v}}(t)}{\mathrm {d} t}}={\dot {\vec {v}}}(t).$$

Da die Geschwindigkeit die Ableitung des Ortes nach der Zeit ist, kann man die Beschleunigung auch als zweite Ableitung des Ortsvektors ${\vec {r}}$ nach der Zeit darstellen:
$$\vec {a} (t) = {\frac {\mathrm {d} ^{2}{\vec {r}}(t)}{\mathrm {d} t^{2}}} = {\ddot {\vec {r}}}(t).$$

Wenn die Vektoren der Geschwindigkeit und der Beschleunigung in die gleiche Richtung zeigen, bedeutet die Beschleunigung nur eine Zunahme des Geschwindigkeitsbetrags. Entsprechend nimmt der Geschwindigkeitsbetrag ab, wenn die beiden Vektoren antiparallel sind. In beiden Fällen ändert sich aber die Richtung des Geschwindigkeitsvektors nicht. Es handelt sich also um eine geradlinig beschleunigte Bewegung.

Sofern jedoch die Beschleunigung in einem gewissen Winkel zur Bewegungsrichtung steht, ändert sich auch die Richtung der Geschwindigkeit. Die Bewegung beschreibt also eine gekrümmte Bahn. Wenn Beschleunigung und Geschwindigkeit orthogonal zueinander stehen, besitzt die Beschleunigung überhaupt keine Komponente in Richtung der Geschwindigkeit mehr. In diesem Fall ändert sich nur deren Richtung, aber nicht ihr Betrag. Die Bahnkurve ist dann – zumindest momentan – eine Kreisbahn.

\paragraph{Gekrümmte Wege}

\subparagraph{Spezialfall: Kreisbewegung}

Bei der gleichförmigen Kreisbewegung ist der Beschleunigungsvektor in jedem Moment orthogonal zur Bewegungsrichtung. Man spricht von der Zentripetalbeschleunigung $a_{Z}$. Sie ergibt sich aus dem Abstand $r$ des Massepunktes zur Drehachse und seiner Tangentialgeschwindigkeit $v$ oder der Winkelgeschwindigkeit $\omega$:
$$a_{Z}={\frac {v^{2}}{r}}=\omega ^{2}r.$$

Ein typisches Anwendungsbeispiel ist hierbei die Flugbahn von Satelliten in einem niedrigen, kreisförmigen Orbit, wo die Fallbeschleunigung, die stets zum Erdmittelpunkt gerichtet ist, als Zentripetalbeschleunigung fungiert.

Bezüglich eines mitrotierenden (und daher beschleunigten) Bezugssystems wird ein Objekt vom Mittelpunkt weg nach außen beschleunigt, dann wird die Bezeichnung Zentrifugalbeschleunigung verwendet. Eine Zentrifuge nutzt diesen Effekt, um Dinge einer konstanten Beschleunigung auszusetzen. Der Krümmungsradius entspricht dabei, da es sich um eine Kreisbewegung handelt, dem Abstand $r$ des Zentrifugiergutes zur Drehachse. Der Betrag der Zentrifugalbeschleunigung berechnet sich nach derselben Formel wie die Zentripetalbeschleunigung.

\subparagraph{Allgemeiner Fall}

Die Beschleunigung eines Körpers, der sich entlang eines Weges (einer Raumkurve) bewegt, lässt sich mit den Frenetschen Formeln berechnen. Dies ermöglicht eine additive Zerlegung der Beschleunigung in eine Beschleunigung in Bewegungsrichtung (Tangentialbeschleunigung) und eine Beschleunigung senkrecht zur Bewegungsrichtung (Normalbeschleunigung oder Radialbeschleunigung).

Der Vektor der Geschwindigkeit ${\vec {v}}$ kann als Produkt aus seinem Betrag $v$ und dem Tangenteneinheitsvektor ${\hat{t}}$ dargestellt werden:
$${\vec {v}}=v\,{\hat {t}}$$

Der Tangenteneinheitsvektor ist ein Vektor der Länge 1, der an jedem Punkt des Weges die Richtung der Bewegung anzeigt. Die Ableitung dieses Ausdrucks mithilfe der Produktregel liefert die Beschleunigung:
$${\vec {a}}={\frac {\mathrm {d} {\vec {v}}}{\mathrm {d} t}}=\left({\frac {\mathrm {d} v}{\mathrm {d} t}}\right){\hat {t}}+v\left({\frac {\mathrm {d} {\hat {t}}}{\mathrm {d} t}}\right)$$

Die zeitliche Ableitung des Tangenteneinheitsvektors kann über die Bogenlänge $s$ berechnet werden:
$${\frac {\mathrm {d} {\hat {t}}}{\mathrm {d} t}}=\underbrace {\frac {\mathrm {d} {\hat {t}}}{\mathrm {d} s}} _{{\hat {n}}/\rho }\underbrace {\frac {\mathrm {d} s}{\mathrm {d} t}} _{v}={\frac {v}{\rho }}{\hat {n}}$$

Dabei führt man den Krümmungsradius $\rho$ und den Normaleneinheitsvektor ${\hat{n}}$ ein. Der Krümmungsradius ist ein Maß für die Stärke der Krümmung und der Normaleneinheitsvektor zeigt senkrecht zur Bahnkurve in Richtung des Krümmungsmittelpunkts. Man definiert die Tangentialbeschleunigung $a_{t}$ und Radialbeschleunigung $a_{n}$ so:
$$a_{t}={\dot {v}}$$
$$a_{n}={\frac {v^{2}}{\rho }}$$

Die Beschleunigung lässt sich damit in zwei Komponenten zerlegen:
$${\vec {a}}=a_{t}{\hat {t}}+a_{n}{\hat {n}}$$

Ist die Tangentialbeschleunigung null, so ändert der Körper nur seine Bewegungsrichtung. Der Betrag der Geschwindigkeit bleibt dabei erhalten. Um den Betrag der Geschwindigkeit zu ändern, muss also eine Kraft wirken, die eine Komponente in Richtung des Tangentialvektors besitzt.

\subparagraph{Ruck}

Die zeitliche Ableitung der Beschleunigung (also die dritte Ableitung des Ortsvektors nach der Zeit) wird Ruck ${\vec {\jmath }}$ genannt:
$${\vec {\jmath }}(t)={\dot {\vec {a}}}(t)={\frac {\mathrm {d} ^{3}{\vec {r}}(t)}{\mathrm {d} t^{3}}}$$

\paragraph{Zusammenhang zwischen Beschleunigung und Kraft}

Der Zusammenhang zwischen Beschleunigungen und Kräften wird durch die Newtonschen Gesetze beschrieben:

\begin{itemize}
\item In einem Inertialsystem erfahren kräftefreie Körper keine Beschleunigung.
\item Falls Kräfte angreifen, ist die Beschleunigung proportional zum Betrag der resultierenden Kraft und erfolgt in deren Richtung: ${\vec {F}}=m{\vec {a}}$.
\end{itemize}

Wenn die resultierende Kraft proportional zur Masse eines Körpers ist – wie das beispielsweise für die Gewichtskraft der Fall ist – ist die Beschleunigung von der Masse des Körpers unabhängig. Das ist der Grund, warum die Fallbeschleunigung beim freien Fall unabhängig von der Masse ist: Alle Körper fallen unabhängig von ihrer Masse gleich schnell, auf der Erde mit rund 9,81 m/s².

In der speziellen Relativitätstheorie gilt die Newton’sche Beziehung nicht exakt; die Beschleunigung ist nicht genau parallel zur Kraft (siehe Beschleunigung (spezielle Relativitätstheorie)).

\subparagraph{Trägheitskräfte}

Soll die Bewegung in einem beschleunigten Bezugssystem beschrieben werden, so sind zusätzlich Trägheitskräfte zu berücksichtigen. Damit ist folgendes gemeint:

Ein Körper, der in einem Inertialsystem ruht, erfährt in einem Bezugssystem, das gegenüber dem Inertialsystem mit ${\vec {a}}$ beschleunigt, eine Beschleunigung von ${\vec {a}}^{\ast }=-{\vec {a}}$. Ein mitbewegter Beobachter macht dafür eine Kraft ${\vec {F}}^{\ast }=m{\vec {a}}^{\ast }$ verantwortlich, für die es in seinem Bezugssystem keine erkennbare Ursache gibt. Dies ist die Trägheitskraft. Beispiel: Ein Ball, der auf dem Boden einer U-Bahn liegt, rollt plötzlich nach hinten, wenn die Bahn anfährt. Ein naiver Fahrgast könnte vermuten, dass der Ball von einer mysteriösen Kraft beschleunigt wird. Ein am Bahnsteig stehender Beobachter würde hingegen sagen, dass die U-Bahn beschleunigt und der Ball aufgrund seiner Trägheit zunächst zurückbleibt.

\paragraph{Beschleunigung in der speziellen Relativitätstheorie}

Ebenso wie in der klassischen Mechanik können Beschleunigungen auch in der speziellen Relativitätstheorie (SRT) als Ableitung der Geschwindigkeit nach der Zeit dargestellt werden. Da der Zeitbegriff aufgrund der Lorentz-Transformation und Zeitdilatation in der SRT jedoch komplexer ausfällt, führt dies auch zu komplexeren Formulierungen der Beschleunigung und ihres Zusammenhangs mit der Kraft. Insbesondere ergibt sich, dass kein massebehafteter Körper auf Lichtgeschwindigkeit beschleunigt werden kann.

\paragraph{Äquivalenzprinzip und allgemeine Relativitätstheorie}

Das Äquivalenzprinzip besagt, dass in einem frei fallenden Bezugssystem lokal keine Gravitationsfelder existieren. Es geht auf die Überlegungen von Galileo Galilei und Isaac Newton zurück, die erkannt haben, dass alle Körper unabhängig von ihrer Masse von der Gravitation gleich beschleunigt werden. Ein Beobachter in einem (kleinen) Labor kann nicht feststellen, ob sich sein Labor in der Schwerelosigkeit oder im freien Fall befindet. Er kann innerhalb seines Labors auch nicht feststellen, ob sein Labor gleichförmig beschleunigt bewegt wird oder ob es sich in einem äußeren homogenen Gravitationsfeld befindet.

Mit der allgemeinen Relativitätstheorie lässt sich ein Gravitationsfeld durch die Metrik der Raumzeit, also die Maßvorschrift in einem vierdimensionalen Raum aus Orts- und Zeitkoordinaten ausdrücken. Ein Inertialsystem hat eine flache Metrik. Nichtbeschleunigte Beobachter bewegen sich immer auf dem kürzesten Weg (einer Geodäte) durch die Raumzeit. In einem flachen Raum, also einem Inertialsystem, ist dies eine gerade Weltlinie. Gravitation bewirkt eine Raumkrümmung. Das bedeutet, dass die Metrik des Raumes nicht mehr flach ist. Dies führt dazu, dass die Bewegung, die in der vierdimensionalen Raumzeit einer Geodäte folgt, im dreidimensionalen Anschauungsraum vom außenstehenden Beobachter meist als beschleunigte Bewegung längs einer gekrümmten Kurve wahrgenommen wird.

\ldots

\subsection{Ruck}

Ruck ist ein Begriff aus der Kinematik. Er ist die momentane zeitliche Änderungsrate der Beschleunigung eines Körpers.[1] Die SI-Einheit des Rucks ist $\mathrm {m} /\mathrm {s} ^{3}$. Als Formelzeichen wird üblicherweise $j$ gewählt in Anlehnung an die englischen Bezeichnungen jerk oder jolt. In deutscher Literatur ist auch $r$ oder $h$ im Gebrauch.

\paragraph{Definition}

Formal ist der Ruck die Ableitung der Beschleunigung nach der Zeit, also die zweite zeitliche Ableitung der Geschwindigkeit und die dritte zeitliche Ableitung des Wegs:
$$j(t)={\dot {a}}(t)={\ddot {v}}(t)={\overset {...}{x}}(t)$$
wobei $t$ die Zeit, $a$ die Beschleunigung, $v$ die Geschwindigkeit und $x$ der Ort sind.

Wird von einem körperfesten Koordinatensystem ausgegangen, so kann der Ruck für jede Koordinatenrichtung getrennt bestimmt werden, z. B. als Längsruck oder Querruck, oder allgemein vektoriell als Ableitung der Beschleunigung bezüglich dieses Bezugssystems. Insbesondere stellt diese Definition sicher, dass eine gleichförmige Kreisbewegung ruckfrei ist, was dem allgemeinen Sprachgebrauch sowie der Anwendung in der Technik entspricht. Bei Stoßvorgängen ist der Ruck nicht definiert.

Obwohl die physikalische Größe ‚Ruck‘ bei jeder Beschleunigungsänderung definiert ist, wird der Begriff umgangssprachlich in der Regel nur bei kurzen „ruckartigen“ Beschleunigungsänderungen verwendet (siehe Weblinks). Diese treten z. B. beim Anfahren mit einem nicht vorgespannten Abschleppseil auf. „Ruckartig“ bedeutet hier, dass der Gradient des kinematischen Rucks einen hohen Betrag hat.

\paragraph{Praxis / Anwendungen}

\ldots

\subparagraph{Landfahrzeuge}

Bei Fahrzeugen ist der Grund für Rucke häufig ein Lastwechsel (z. B. beim Teillastruckeln). Unterschieden werden:
\begin{itemize}
\item der Längsruck, die zeitliche Änderung der Längsbeschleunigung
\item der Querruck, die zeitliche Änderung der Querbeschleunigung.
\end{itemize}

Anschaulich bedeutet dies, dass der Längsruck bei einem Fahrzeug durch plötzliches Anfahren oder Bremsen verursacht wird, der Querruck dagegen durch plötzliche Änderung des Lenkradwinkels bei einem fahrenden Automobil.

Bei elektronischen Lenksystemen können durch die Zusatzfunktionen auch Querrucke ohne Betätigung des Lenkrads auftreten. Diese müssen aus Sicherheitsgründen auf 5 m/s3 begrenzt sein (ECE R79).

Die Bezeichnungen längs und quer deuten schon an, dass diese Beschleunigungen Komponenten in einem fahrzeugfesten Bezugssystem sind. Ändern sich die Komponenten nicht, so ist der Ruck Null. Bei stationärer Kreisfahrt zeigt der Beschleunigungsvektor immer zum Kreismittelpunkt (Zentripetalkraft), von außen betrachtet ändert er sich also; im fahrzeugfesten Koordinatensystem dagegen bleibt derselbe Beschleunigungsvektor konstant.

\subparagraph{Längsruck}

Je schneller eine Bremsung eingeleitet oder beendet wird, desto höher ist der Ruck. Eine abrupt eingeleitete Bremsung (Notbremsung) ist mit einem hohen Ruck verbunden. Wenn sich der Insasse nicht schnell genug darauf eingestellt hat und sich nicht abstützt, wird er bei Vorwärtsfahrt nach vorne geworfen (im Auto vom Gurt abgefangen), bei Rückwärtsfahrt in den Sitz gedrückt. Da die Betätigung der Bremse selbst bei einer Notbremsung noch eine gewisse Zeit beansprucht, bleibt der Ruck ein endlicher Wert.

Bleibt die Bremse bis zum Stillstand mit ihrer maximalen Kraft wirksam, so tritt am Ende des Bremsweges ein theoretisch unendlich hoher Ruck (Schlussruck) auf, weil die Verzögerung (= negative Beschleunigung) plötzlich, also in der Zeitdauer null, endet. Dadurch wird der Insasse durch seine eigene Muskelkraft (Abstützkraft) oder, wenn er sich völlig passiv verhalten hat, durch die vom Gurt ausgeübte Kraft in den Sessel geschleudert und von der Federkraft des Sessels dann zurückgeschleudert. Für diese Bewegungen vergeht allerdings Zeit. Dadurch wird der Schlussruck endlich, also gemildert. Außerdem entspannen sich elastische Elemente am Fahrzeug (Reifen, Fahrzeug-Federung, Eisenbahn-Puffer u. a.), was ebenfalls eine kurze Zeit dauert. Das Fahrzeug fährt dabei scheinbar ein kleines Stück zurück.

Im Normalbetrieb löst der routinierte Fahrer die Bremse langsam vor Erreichen des Stillstandes und dehnt damit die Abnahme der Verzögerung zeitlich aus, so dass der Schlussruck auf ein Minimum herabgesetzt wird.

Fahrzeuge mit Elektroantrieb entwickeln bei einfachen (stufigen) Steuerungskonzepten des Motorstromes einen starken Längsruck bei jeder Beschleunigungsänderung.
Der Fahrkomfort beim Anfahren, Beschleunigen und rekuperativen Bremsen wird durch sanft reagierende Fahrdynamik verbessert, jedoch kann ein sogenannter Warnruck bei autonomen Fahrzeugen genutzt werden, die Aufmerksamkeit zur Überwachung herzustellen.[6]

\subparagraph{Querruck}

Der Querruck $k$ als Spezialfall des Rucks ist die Änderung der Zentripetalbeschleunigung $a_{r}$ in Abhängigkeit von der Zeit $t$:
$$k={\frac {\mathrm {d} a_{r}(t)}{\mathrm {d} t}}$$

Die Zentripetalbeschleunigung eines Fahrzeugs ist abhängig von seiner Geschwindigkeit $v$ sowie der Krümmung $\kappa ={\tfrac {1}{r}}$ der Bahn, wobei $r$ der Radius des Krümmungskreises ist:
$$a_{r}={\frac {v^{2}}{r}}=v^{2}\,\kappa$$

$$\Rightarrow k = v^{2} \, \dot{\kappa} \quad \text{für} \quad v = \mathrm{konst.} $$

Die Krümmung ist bei den verwendeten Trassierungselementen als Funktion der Wegstrecke $s$ gegeben: $\kappa =\kappa (s)$

Mit ${\dot {\kappa }} = {\frac {\mathrm {d} \kappa }{\mathrm {d} t}} = {\frac {\mathrm {d} s}{\mathrm {d} t}}\cdot {\frac {\mathrm {d} \kappa (s)}{\mathrm {d} s}} = v\cdot {\frac {\mathrm {d} \kappa (s)}{\mathrm {d} s}}$ ergibt sich für den Querruck somit:
$$k=v^{3}\,{\frac {\mathrm {d} \kappa (s)}{\mathrm {d} s}}.$$

Ein Querruck tritt also beispielsweise auf, wenn sich der Radius einer Kreisbewegung ändert. Wenn in einer Trasse, z. B. einem Bahngleis, ein Kreisbogen unmittelbar auf eine Gerade folgt, so ändert sich an dieser Stelle die Zentripetalbeschleunigung bei schienengebundenen Fahrzeugen sprungartig. Das heißt, die Zeit für diese Änderung ist fast null, und der Querruck wird extrem groß. Verwendet man als Verbindungselement zwischen Gerade und Kreisbogen eine Klothoide, so ändert sich die Zentripetalbeschleunigung linear während der Zeit, die zum Durchfahren der Klothoide benötigt wird. Daher wird der Querruck entsprechend geringer.

In Abschnitten, in denen das Fahrzeug sich auf einer Geraden oder mit konstanter Geschwindigkeit auf einer Kreisbahn bewegt, ändert sich die Zentripetalbeschleunigung nicht. Der Querruck ist somit null.

\subparagraph{Trassenbau}

Bei der Planung von Trassen ist je nach der Bemessungsgeschwindigkeit und dem Fahrkomfort, den man für eine Strecke erreichen will, darauf zu achten, dass der Querruck einen Grenzwert von 0,4 bis 0,6 m/s³ nicht übersteigt. Bei Schienenfahrzeugen wird durch die Wahl der Trassierungselemente eine möglichst ruckarme Fahrt beim Übergang in Kurven sichergestellt. Auch bei Achterbahnen wird durch entsprechende Übergänge die Belastung auf den menschlichen Körper reduziert. Im Extremfall, etwa bei Hochgeschwindigkeitszügen, kann durch Verwendung anderer Übergangsbögen als der Klothoide erreicht werden, dass der Querruck am Anfang des Übergangsbogens nicht sprunghaft, sondern allmählich einsetzt.

Der Querruck bei Lenkmanövern von Straßenfahrzeugen ist wegen der erforderlichen Lenkraddrehung generell begrenzt. Der sanfte Verlauf des Querruckes beim autonomen Fahren ist Forschungsgegenstand, um die Vorhersehbarkeit und den Komfort eines Lenkmanövers zu verbessern, der Ruck würde aufgrund rein mathematischer Algorithmen ansonsten plötzlich und überraschend einsetzen.

\paragraph{Ruckänderung}

Die Ruckänderung $s$ (engl. jounce, snap), manchmal Knall genannt, ist ein Begriff aus der analytischen Modellierung der Fahrdynamik von Schienenfahrzeugen und die erste Ableitung des Rucks nach der Zeit:
$$s(t) = \frac{\mathrm{d} j}{\mathrm{d} t}$$

wobei $t$ die Zeit und $j$ der Ruck ist. Die SI-Einheit der Ruckänderung ist dementsprechend $\frac{\mathrm{m}}{\mathrm{s}^{4}}$.

Die Ruckänderung spielt in diesen Modellen vor allem eine theoretische Rolle, in dem zumindest bei einem stückweise stetigen Differenzieren oder Integrieren die Ruckänderung jeweils als gleich Null vorausgesetzt wird und auf diese Weise eine Lösung der zugehörigen Gleichungssysteme möglich wird.

\ldots

\section{Optimierungstheorie}

\subsection{Grundlagen der Optimierungstheorie}

Optimierungsaufgaben treten in den Wirtschaftswissenschaften (Operations Research), in der Technik und in den Naturwissenschaften in vielfältiger Art und Weise auf.

\subsubsection*{Glossary}

\begin{table}[htp]
\begin{center}
\begin{tabular}{|c|c|}
\hline
$\R$, $\N$, $\C$ & wie üblich \\ \hline
$\idx$, $\idy$, $\idz$ & Iterations-Indizes \\ \hline
$f$, $g$, $h$ & Zielfkt., Fkt.en der Ungleichungs\-restr., Fkt.en der Gleichheits\-restr. \\ \hline
$m$, $p$ & Anzahl Un- resp. Gleichheits\-restr. \\ \hline
$\I$, $\J$; $\A$ & Index\-mengen; active set \\ \hline
$\Lagrangian$; $\mu$, $\nu$ & Lagrange-Funktion; -multiplikatoren \\ \hline
\end{tabular}
\end{center}
\caption{default}
\end{table}

\ldots

\subsubsection{Aufgabenstellung}

Für gegebene (und hinreichend oft differenzierbare) Funktionen
\begin{eqnarray*}
f & : & \R^n \to \R \\
g = (g_1, \ldots, g_m)^T & : & \R^n \to \R^m \\
h = (h_1, \ldots, h_p)^T & : & \R^n \to \R^p 
\end{eqnarray*}
betrachten wir das restringierte Standard-Optimierungsproblem:
\begin{problem}
\emph{(Standard-Optimierungsproblem)} Finde $x \in \R^n$, so dass $f (x)$ minimal wird unter den Nebenbedingungen
\begin{eqnarray*}
g_i (x) & \leq & 0,\quad i = 1, \ldots, m \\
h_j (x) & = & 0,\quad j = 1, \ldots , p
\end{eqnarray*}
In Kurzform schreiben wir auch:
\begin{eqnarray*}
f (x) & \to & \min \\
g (x) & \leq & 0 \\
h (x) & = & 0
\end{eqnarray*}
\qed
\end{problem}
Mit
\begin{equation}
\label{eqn:1.1}
\Sigma := \{ x \in \R^n \;:\; g_i (x) \leq 0, \; i=1, \ldots, m, \; h_j (x) = 0, \; j=1, \ldots, p \}
\end{equation}
bezeichnen wir die \emph{zulässige Menge} (oder den \emph{zulässigen Bereich}) des Standard-Optimierungsproblems. Die Menge $\Sigma$ in (\ref{eqn:1.1}) ist eine abgeschlossene Menge, falls die Funktionen $g_i$ und $h_j$ stetig sind.

Ein Punkt $x \in \R^n$ heißt
\begin{itemize}
\item \emph{zulässig}\index{zulässig}, falls $x \in \Sigma$ gilt, und
\item \emph{unzulässig}, falls $x \notin \Sigma$ gilt.
\end{itemize}
Für zulässige Punkte $x \in \Sigma$ bezeichnen wir mit
$$\A (x) := \{ i \in \{ 1, \ldots, m \} \;:\; g_i (x) = 0 \}$$
die \emph{Indexmenge der (in $x$) aktiven Ungleichungs\-restriktionen} und nennen die Restriktion $g_i (x) \leq 0$
\begin{itemize}
\item \emph{aktiv in $x$}\index{aktiv}, wenn $g_i (x) = 0$ gilt, und
\item \emph{inaktiv in $x$}, wenn $g_i (x) < 0$ gilt.
\end{itemize}
Das Standard-Optimierungs\-problem enthält die folgenden Problemklassen als Spezialfälle:
\begin{itemize}
\item \emph{Unrestringiertes Optimierungsproblem:}
$$\min_{x \in \R^n} f (x)$$
Hierin treten keine Ungleichungs- und Gleichungs\-restriktionen auf.
\item \emph{Konvexes Optimierungsproblem:}
$$\min_{\substack{g (x) \leq 0 \\ Ax = b}} f(x)$$
Spezialfall, wobei $f$ und $g$ konvexe Funktionen, $A \in \R^{m \times n}$ eine Matrix und $b \in \R^m$ ein Vektor sind.
\item \emph{Lineares Optimierungsproblem (in primaler Normalform):} 
$$\min_{\substack{Ax = b \\ x \geq 0}} c^T x$$
Spezialfall mit $g (x) = -x$, $h (x) = Ax-b$, wobei $c \in \R^n$, $b \in \R^m$ Vektoren und $A \in \R^{m \times n}$ eine Matrix sind. Das lineare Optimierungsproblem ist ein konvexes Optimierungsproblem.
\item \emph{Linear-quadratisches Optimierungsproblem:}
$$\min_{\substack{Ax = b \\ x \geq 0}} \dfrac{1}{2} x^T Q x + c^T x$$
Spezialfall mit $g (x) = -x$, $h (x) = Ax-b$, wobei $c \in \R^n$, $b \in \R^m$ Vektoren und $Q \in \R^{n \times n}$ und $A \in \R^{m \times n}$ Matrizen sind. Falls $Q$ symmetrisch und positiv semi-definit ist, liegt ein konvexes Optimierungsproblem vor.
\end{itemize}

\subsubsection{Notwendige Bedingungen für restringierte Optimierungsprobleme}

Die folgenden \textsc{Karush-Kuhn-Tucker} (KKT) Bedingungen sind die Basis für viele theoretische Untersuchungen und numerische Algorithmen.

Die \emph{Lagrange-Funktion} für das Standard-Optimierungsproblem ist definiert als
\begin{eqnarray*}
\Lagrangian (x, \mu, \nu) & := & f (x) + \mu^T g (x) + \nu^T h (x) \\
& = & f (x) + \sum_{i=1}^m \mu_i g_i (x) + \sum_{j=1}^p \nu_j h_j (x)
\end{eqnarray*}
wobei $\mu = (\mu_1, \ldots, \mu_m)^T \in \R^m$ und $\nu = (\nu_1, \ldots, \nu_p)^T \in \R^p$ als \emph{Lagrange-Multiplikatoren} bezeichnet werden. Es gilt:
\begin{theorem}\label{theo:1.2.1}\emph{(Notwendige Bedingungen erster Ordnung, KKT-Bedingungen)}\\
Voraussetzungen:
\begin{itemize}
\item $\x$ ist ein lokales Minimum des Standard-Optimierungsproblems.
\item Die Funktionen $f$, $g_i$, $i=1, \ldots, m$, und $h_j$, $j=1, \ldots, p$ sind stetig differenzierbar.
\item Es gilt die Linear Independence Constraint Qualification (LICQ) in $\x$, d.h. die Vektoren
$$\nabla g_i (\x), i \in \A (\x) \text{ und } \nabla h_j (\x), j=1, \ldots, p$$
sind linear unabhängig.
\end{itemize}
Dann existieren eindeutig bestimmte Multiplikatoren $\mu = (\mu_1, \ldots , \mu_m)^T \in \R^m$ und $\nu = (\nu_1, \ldots, \nu_p)^T \in \R^p$, so dass die folgenden Bedingungen gelten:
\begin{description}
\item[(a) \emph{Stationarität der Lagrange-Funktion:}]
\begin{equation}
\label{eqn:1.2}
\nabla_x \Lagrangian (\x, \mu, \nu) = 0
\end{equation}
bzw.
\begin{equation}
\label{eqn:1.3}
\nabla f (\x) + \sum_{i=1}^m \mu_i \cdot \nabla g_i (\x) + \sum_{j=1}^p \nu_j \cdot \nabla h_j (\x) = 0.
\end{equation}
\item[(c) \emph{Komplementaritätsbedingungen:}] Für $i=1, \ldots, m$ gilt:
\begin{eqnarray}
\label{eqn:1.4}
\mu_i \cdot \geq 0 & \text{und} & \mu_i g_i (\x) = 0
\end{eqnarray}
\item[(d) \emph{Zulässigkeit:}] 
\begin{eqnarray}
\label{eqn:1.5}
g (\x) \leq 0 & \text{und} & h (\x) = 0
\end{eqnarray}
\end{description}
\qed
\end{theorem}

Jeden Punkt $(\x, \mu, \nu)$, der die Bedingungen (\ref{eqn:1.2})--(\ref{eqn:1.5}) erfüllt, nennen wir \emph{KKT-Punkt} oder \emph{stationären Punkt}. Beachte, dass KKT-Punkte lediglich Kandidaten für optimale Lösungen liefern.

Aus den KKT-Bedingungen ergeben sich folgende Spezialfälle:
\begin{itemize}
\item Für das \emph{unrestringierte Optimierungsproblem}
$$\min_{x \in \R^n} f(x)$$
erhält man die notwendige Bedingung
$$\nabla f (\x) = 0$$
\item Für das \emph{lineare Optimierungsproblem (in primaler Normalform)} 
$$\min_{\substack{x \geq 0 \\ Ax=b}} c^T x$$
erhält man mit der Lagrange-Funktion $\Lagrangian (x, \mu, \nu) = c^T x + \mu^T (-x) + \nu^T (b-Ax)$ die notwendigen Bedingungen
\begin{eqnarray*}
c - \mu - A^T \nu = 0, & \mu \geq 0, & \mu^T (-\x) = 0
\end{eqnarray*}
bzw.
\begin{eqnarray*}
A^T \nu \leq c, && \x^T (c - A^T \nu) = 0
\end{eqnarray*}
\item Für das \emph{linear-quadratische Optimierungsproblem}
$$\min_{\substack{x \geq 0 \\ A x = b}} \dfrac{1}{2} x^T Q x + c^T x$$
erhält man mit der Lagrange-Funktion $\Lagrangian (x, \mu, \nu) = \dfrac{1}{2} x^T Q x + c^T x + \mu^T (-x) + \nu^T (b-Ax)$ die notwendigen Bedingungen
\begin{eqnarray*}
Q \x + c - \mu - A^T \nu = 0, & \mu \geq 0, & \mu^T (-\x) = 0
\end{eqnarray*}
\item Für das \emph{gleichungsrestringierte Optimierungsproblem}
$$\min_{h (x) = 0} f (x)$$
erhält man mit der Lagrange-Funktion $\Lagrangian (x, \nu) = f (x) + \nu^T h (x)$ die notwendigen Bedingungen
$$
\begin{pmatrix}
\nabla_x \Lagrangian (\x, \nu) \\ h (\x)
\end{pmatrix}
=
\begin{pmatrix}
0 \\ 0
\end{pmatrix}
$$
Dies ist i.A. ein nichtlineares Gleichungssystem in den Unbekannten $x$ und $\nu$ und kann mit dem \textsc{Newton}-Verfahren gelöst werden (siehe \textsc{Lagrange-Newton}-Verfahren). 
\end{itemize}

Für eine notwendige Bedingung zweiter Ordnung in einem KKT-Punkt $(\x, \hat{\mu}, \hat{\nu})$ benötigen wir den \emph{kritischen Kegel}
\begin{eqnarray*}
T_K (x) := \{ d \in \R^n & : & \nabla g_i (x)^T d \leq 0,\; i \in \A (x),\; \hat{\mu}_i = 0, \\
&& \nabla g_i (x)^T d = 0,\; i \in \A (x) ,\; \hat{\mu}_i > 0, \\
&& \nabla h_j (x)^T d = 0,\; j = 1, \ldots, p \}
\end{eqnarray*}
Der kritische Kegel enthält tangentiale Richtungen $d$ an den zulässigen Bereich für die die Richtungsableitung $\nabla f (\x)^T d$ gleich Null ist. Für diese kritischen Richtungen müssen Bedingungen zweiter Ordnung herangezogen werden.

Es gilt:
\begin{theorem}\emph{(Notwendige Bedingungen zweiter Ordnung)}
\\ Voraussetzungen:
\begin{itemize}
\item $f$, $g_i$, $i = 1, \ldots, m$, und $h_j$, $j = 1, \ldots, p$ sind zweimal stetig differenzierbar. 
\item $(\x, \mu, \nu)$ ist ein KKT-Punkt.
\item $\x$ ist ein lokales Minimum des Standard-Optimierungsproblems.
\item Es gilt die LICQ in $\x$. 
\end{itemize}
Dann gilt
\begin{eqnarray*}
d^T \nabla_{xx}^2 \Lagrangian (\x, \mu, \nu) d \geq 0 && \forall d \in T_K (\x)
\end{eqnarray*}
(Die Hessematrix der Lagrange-Funktion ist positiv semi-definit auf dem kritischen Kegel). \qed
\end{theorem}
Treten keine Restriktionen $g (x) \leq 0$ und $h (x) = 0$ auf (unbeschränkter Fall), so ist der kritische Kegel durch $T_K (\x) = \R^n$ gegeben und die notwendige Bedingung zweiter Ordnung reduziert sich auf die Bedingung
$$H_f (\x) \text{ ist positiv semidefinit,}$$
wobei $H_f (\x)$ die Hessematrix\index{Hessematrix} der Zielfunktion $f$ in $\x$ bezeichnet.

\subsubsection{Hinreichende Bedingungen für restringierte Optimierungsprobleme}

Die hinreichenden Bedingungen zweiter Ordnung sind sehr nah an den notwendigen Bedingungen zweiter Ordnung.

\begin{theorem}\emph{(Hinreichende Bedingung zweiter Ordnung)}
\\ Voraussetzungen:
\begin{itemize}
\item $f$, $g_i$, $i = 1, \ldots, m$ und $h_j$, $j = 1, \ldots, p$ sind zweimal stetig differenzierbar. 
\item $(\x, \mu, \nu)$ ist KKT-Punkt des Standard-Optimierungsproblems.
\item Es gilt
\begin{eqnarray}
\label{eqn:1.6}
d^T \nabla_{xx}^2 \Lagrangian (\x, \mu, \nu) d > 0 && \forall d \in T_K (\x), d \not= 0
\end{eqnarray}
(Die Hessematrix der Lagrange-Funktion ist positiv-definit auf dem kritischen Kegel).
\end{itemize}
Dann existiert eine Umgebung $U$ von $\x$ und ein $\alpha > 0$ mit
\begin{eqnarray*}
f (x) \geq f (\x) + \alpha \cdot \| x - \x \|^2 && \forall x \in \Sigma \cap U
\end{eqnarray*}
(insbesondere ist $\x$ also lokales Minimum und $f$ wächst lokal mindestens quadratisch). \qed
\end{theorem}
Treten keine Restriktionen $g (x) \leq 0$ und $h (x) = 0$ auf (unbeschränkter Fall), so ist der kritische Kegel durch $T_K (\x) = \R^n$ gegeben und die hinreichende Bedingung zweiter Ordnung reduziert sich auf die Bedingung (\ref{eqn:1.6})
$$H_f (\x) \text{ ist positiv definit,}$$
wobei $\x$ ein stationärer Punkt von $f$ sei.

\subsubsection{Verfahren für unrestringierte Optimierungsprobleme}

Für die Minimierung der Funktion $f : \R^n \to \R$ haben wir iterative Verfahren kennengelernt, die ausgehend von einer Startschätzung $x^{[0]}$ Näherungslösungen
\begin{eqnarray*}
x^{[\idx+1]} := x^{[\idx]} + \alpha_\idx \cdot d^{[\idx]} && \text{für } \idx = 0, 1, 2, \ldots 
\end{eqnarray*}
berechnen. Hierin ist $d^{[\idx]}$ eine Suchrichtung und $\alpha_\idx > 0$ eine Schrittweite.

Zur Bestimmung der Suchrichtung gibt es u.a. die folgenden Ansätze:
\begin{itemize}
\item Beim \emph{Gradientenverfahren} wird stets die Richtung des steilsten Abstiegs gewählt, also
$$d^{[\idx]} := -\nabla f (x^{[\idx]})$$
Diese Richtung ist außer in einem stationären Punkt stets eine Abstiegsrichtung. 
\item Beim \emph{Newton-Verfahren} wird die Richtung
$$d^{[\idx]} := -H_f (x^{[\idx]})^{-1} \nabla f (x^{[\idx]})$$
gewählt. Ist die Hessematrix $H_f (x^{[\idx]})$ positiv definit, so ist die Newton-Richtung außer in einem stationären Punkt eine Abstiegsrichtung.
\item Beim \emph{Quasi-Newton-Verfahren} wird die Richtung
$$d^{[\idx]} := -H_\idx^{-1} \nabla f (x^{[\idx]})$$
gewählt, wobei die Matrix $H_\idx$ stets symmetrisch und positiv definit gewählt wird und durch eine sogenannte Update-Formel in jedem Iterationsschritt aufdatiert wird. Diese Quasi-Newton-Richtung ist außer in einem stationären Punkt stets eine Abstiegsrichtung.
\item \emph{Trust-Region-Verfahren:} Die Suchrichtung ist durch Lösen des Trust-Region-Hilfs\-problems
$$\min_{\| d \| \leq \Delta_\idx} \dfrac{1}{2} d^T H_\idx d + \nabla f (x^{[i]})^T d$$
gegeben, wobei der Trust-Region-Radius $\Delta_\idx > 0$ und die Matrix $H_\idx$ in jedem Schritt angepasst werden. Als Schrittweite wird beim Trust-Region-Verfahren stets $\alpha_\idx = 1$ gewählt, da die Schrittlänge durch den Trust-Region-Radius $\Delta_\idx$ gesteuert wird.
\end{itemize}
Beim Trust-Region-Verfahren arbeitet man mit der Schrittweite $\alpha_\idx = 1$ und verzichtet auf die nachfolgende Liniensuche, da sie durch die Steuerung des Trust-Region-Radius $\Delta_\idx$ überflüssig ist. Für alle anderen Verfahren kann die Schrittweite $\alpha_\idx > 0$ mithilfe einer eindimensionalen Liniensuche für die Funktion
$$\varphi (\alpha) := f (x^{[\idx]} + \alpha \cdot d^{[\idx]})$$
berechnet werden. Voraussetzung ist aber, dass $d^{[\idx]}$ eine Abstiegsrichtung ist. Üblicherweise verwendet man dann das Armijo-Verfahren oder darauf aufbauende Verfahren, z.B. die Wolfe-Powell-Regeln.

\begin{algorithm}\emph{(Armijo-Regel)}
\begin{enumerate}[label=(\roman*)]
\item Wähle $\beta \in (0, 1)$, $\sigma \in (0, 1)$ und setze $\alpha := 1$.
\item Falls die Bedingung
$$\varphi (\alpha) \leq \varphi (0) + \sigma \cdot \alpha \cdot \varphi' (0)$$
erfüllt ist, setze $\alpha_\idx := \alpha$ und beende das Verfahren. Andernfalls gehe zu (iii).
\item Setze $\alpha := \beta \cdot \alpha$ und gehe zu (ii).
\end{enumerate} \qed
\end{algorithm}

\subsubsection{Überblick}

Zur numerischen Lösung des Standard-Optimierungsproblems gibt es im Wesentlichen die folgenden Herangehensweisen:
\begin{enumerate}[label=(\alph*)]
\item \emph{Penalty- und Multiplikator-Verfahren:} Diese Verfahren basieren auf der Ankopplung der Nebenbedingungen an die Zielfunktion mithilfe eines gewichteten Strafterms (Penalty-Term), der unzulässige Punkte bestraft. Dadurch werden die Nebenbedingungen eliminiert und man kann Verfahren der unrestringierten Optimierung (Gradientenverfahren, Newtonverfahren, Quasi-Newton-Verfahren) anwenden. Zielfunktion und Strafterm müssen jedoch geeignet gewichtet werden, damit man letztendlich eine zulässige Lösung bekommt.
\item \emph{Sequentielle quadratische Programmierung (SQP):} SQP-Verfahren basieren auf der lokalen Approximation des Standard-Optimierungsproblems durch ein linear-quadratisches Optimierungsproblem, dessen Lösung die Suchrichtung in einem iterativen Verfahren liefert. SQP-Verfahren erweitern das Lagrange-Newton-Verfahren auf Probleme mit Ungleichungsrestriktionen.
\item \emph{Innere-Punkte-Verfahren (IP):} Innere-Punkte-Verfahren verwenden sogenannte Bar\-rie\-re-Funktionen, um Ungleichungsnebenbedingungen zu eliminieren und diese ähnlich wie bei Penalty-Verfahren mithilfe eines gewichteten Stratfterms an die Zielfunktion zu koppeln. Im Gegensatz zu Penalty- und Multiplikator-Verfahren wird dabei nicht nur das Verlassen des zulässigen Bereichs bestraft, sondern es wird bereits die Annäherung an den Rand des zulässigen Bereichs bestraft (den Rand des zulässigen Bereichs kann man sich als unüberwindliche Barriere vorstellen).
\item \emph{Verfahren für Komplementaritätsprobleme:} Diese Verfahren, zu denen semiglatte Newtonverfahren oder Variationsmethoden gehören, versuchen, die KKT- Bedingungen direkt zu lösen. Dazu werden die Komplementaritätsprobleme entweder als Variationsungleichung umgeschrieben und mit geeigneten Verfahren gelöst, oder sie werden mithilfe von speziellen Funktionen als Gleichung reformuliert. Letzteres führt auf ein nichtdifferenzierbares Gleichungssystem, auf das Varianten des Newtonverfahrens angewendet werden können.
\end{enumerate}

Jede dieser Verfahrensklassen verwendet zusätzlich Strategien, um Konvergenz von beliebigen Startschätzungen zu erreichen (Globalisierungsstrategien). Die üblichen Strategien sind
\begin{itemize}
\item eindimensionale Liniensuche (z.B. \textsc{Armijo}-Verfahren)
\item Trust-Region-Verfahren (Approximation auf einem Vertrauensbereich)
\item Filterverfahren (versuchen, nicht-dominierte Iterierte zu erzeugen, wobei Zielfunktionswert und Verletzung der Restriktionen als zwei Kriterien mitgeführt werden)
\end{itemize}

\subsection{Penalty- und Multiplikator-Verfahren}

Penalty- und Multiplikatorverfahren sind beliebte Verfahren, die auf der Ankopplung der Nebenbedingungen an die Zielfunktion mithilfe eines gewichteten Strafterms (Penalty-Term) basieren. Der Strafterm bestraft unzulässige Punkte. Der Vorteil der Verfahren ist, dass durch die Ankopplung der Nebenbedingungen an die Zielfunktion Nebenbedingungen eliminiert werden, so dass Verfahren der unrestringierten Optimierung angewendet werden können.

Das Konzept der Penalty-Verfahren für die allgemeine Aufgabenstellung 
\begin{eqnarray*}
\text{(P)} && \min_{x \in \Sigma} f (x)
\end{eqnarray*}
funktioniert wie folgt. Man benötigt eine Funktion $r : \R^n \to [0, \infty)$ mit der Eigenschaft 
$$
r (x) 
\begin{cases}
= 0, & \text{falls } x \in \Sigma \\
> 0, & \text{falls } x \notin \Sigma.
\end{cases}
$$
Dann minimiert man für eine geeignet gewählte Folge von Gewichtungsparametern $\{ \eta_\idx \}_{k \in \N}$ mit $\eta_\idx > 0$ die unrestringierte Penalty-Funktion
\begin{equation}
\label{eqn:2.1}
P (x; \eta_\idx) := f (x) + \eta_\idx \cdot r (x)
\end{equation}
Für jedes $\eta_\idx > 0$ erhält man eine Lösung $x^{[\idx]} := x (\eta_\idx)$ und es stellt sich die Frage, wie die Gewichtungsparameter $\eta_\idx$, $k \in \N$, gewählt werden müssen, damit die Folge $\{ x^{[\idx]} \}_{k \in \N}$ gegen ein Minimum von $(P)$ konvergiert.
Die Funktion $r$ kann auf verschiedene Arten definiert werden, wobei differenzierbare Varianten ideal sind, um die uns bekannten Verfahren der unrestringierten Verfahren anwenden zu können. Wird $r$ als stetige, aber nicht stetig differenzierbare Funktion gewählt, so gestaltet sich die Lösung des unrestringierten Penalty-Problems schwieriger.

\subsubsection{Penalty-Verfahren}

Dazu betrachten wir zunächst das folgende gleichungsrestringierte Optimierungsproblem mit stetigen (!) Funktionen $f : \R^n \to R$ und $h_j : \R^n \to \R$, $j = 1, \ldots, p$.
\begin{problem}\label{prob:2.1.2}\emph{(Restringiertes Optimierungsproblem)}
$$\min_{x \in \Sigma} f (x)$$
mit
$$\Sigma = \{ x \in \R^n \;|\; h_j (x) = 0,\; j = 1, \ldots, p \}.$$
\qed
\end{problem}

Die Idee des Penalty-Verfahrens besteht darin, die Lösung $\x$ des Ausgangsproblems iterativ durch die Lösungen von unrestringierten Hilfsproblemen zu approximieren. Diese Hilfsprobleme bestehen in der Minimierung der Penalty-Funktion
$$P (x; \eta) := f (x) + \dfrac{\eta}{2} \sum_{j=1}^p (h_j (x))^2$$
für geeignete Werte von $\eta > 0$. Durch die Ankopplung der Nebenbedingungen wird ein Verlassen des zulässigen Bereichs $\Sigma$ 'bestraft'. Die Konstante $\eta$ stellt einen Gewichtungsfaktor dar, mit dessen Hilfe die 'Stärke der Bestrafung' gesteuert werden kann. Das Penalty-Verfahren ist durch folgenden Algorithmus gegeben.

\begin{algorithm}\label{algo:2.1.3}\emph{(Penalty-Verfahren)}
\begin{enumerate}[label=(\roman*)]
\item Wähle $\eta_0 > 0$ und setze $k=0$. 
\item Bestimme $x^{[\idx]}$ als Lösung von
$$\min_{x \in \R^n} P (x; \eta_\idx)$$
\item Ist $h (x^{[\idx]}) \approx 0$, {\tt{STOP}}.
\item Bestimme $\eta_{\idx+1} > \eta_k$, setze $\idx := \idx + 1$ und gehe zu (ii).
\end{enumerate} \qed
\end{algorithm}

Da $P$ i.A. nicht differenzierbar ist, werden für das Hilfsproblem in Schritt (ii) Verfahren der unrestringierten, nichtdifferenzierbaren Optimierung benötigt. Es stellt sich natürlich die Frage, ob das Verfahren tatsächlich gegen eine Lösung des Ausgangsproblems konvergiert.

\begin{theorem}\emph{(Konvergenzsatz für das Penalty-Verfahren)}
\\ Seien $f$ und $h_j$, $j = 1, \ldots, p$ stetig und $\{ \eta_\idx \}$ streng monoton wachsend mit $\eta_\idx \to \infty$. Die zulässige Menge $\Sigma := \{ x \in \R^n \;|\; h_j (x) = 0,\; j=1, \ldots, p \}$ sei nichtleer, und $\{ x^{[\idx]} \}$ sei eine durch Algorithmus (\ref{algo:2.1.3}) erzeugte Folge (die Existenz der Folge sei vorausgesetzt). Dann gelten die folgenden Aussagen:
\begin{enumerate}[label=(\alph*)]
\item Die Folge der Zielfunktionswerte der Penalty-Funktion $\{ P (x^{[\idx]}; \eta_\idx) \}_{k \in \N}$ ist monoton wachsend.
\item Die Folge der Verletzung der Nebenbedingungen $\{ \| h (x^{[\idx]}) \| \}_{k \in \N}$ ist monoton fallend.
\item Die Folge der Zielfunktionswerte $\{ f (x^{[\idx]}) \}_{k \in \N}$ ist monoton wachsend.
\item Es gilt $\lim_{k \to \infty} h (x^{[\idx]}) = 0$.
\item Jeder Häufungspunkt der Folge $\{ x^{[\idx]} \}_{k \in \N}$ ist eine Lösung des Ausgangsproblems.
\end{enumerate}
\qed
\end{theorem}

\begin{remark}
Da nur die Stetigkeit der auftretenden Funktionen benötigt wird, ist das Verfahren auch auf Problemstellungen mit Ungleichungsnebenbedingungen
\begin{eqnarray*}
g_i (x) \leq 0, && i=1, \ldots, m,
\end{eqnarray*}
anwendbar. Denn diese Nebenbedingungen können äquivalent als stetige Nebenbedingungen 
\begin{eqnarray*}
\max \{ 0,\; g_i (x) \} = 0, && i=1, \ldots, m,
\end{eqnarray*}
geschrieben werden. Die Penaltyfunktion lautet dann
$$
P (x; \eta) = f (x) + \dfrac{\eta}{2} \sum_{i=1}^m (\max \{ 0,\; g_i (x) \} )^2 + \dfrac{\eta}{2} \sum_{j=1}^p (h_j (x))^2 .
$$
\qed
\end{remark}
Ein wesentlicher Nachteil des Penalty-Verfahrens ist die Tatsache, dass die Gewichtungsfaktoren $\eta_\idx$ gegen $\infty$ streben müssen, um Konvergenz zu erhalten. Dies führt dazu, dass die Teilprobleme in (ii) des Algorithmus für großes $\eta_\idx$ sehr schlecht konditioniert sind\footnote{Einige Eigenwerte der Hessematrix $\nabla_{xx}^2 P (x^{[\idx]}; \eta_\idx)$ streben gegen $\infty$ und somit strebt die Spektral-Konditionszahl der Hessematrix gegen unendlich.} und numerisch nur sehr schwer zu lösen sind.

\subsubsection{Schätzung der Lagrange-Multiplikatoren}

Wir untersuchen, wie aus der Folge $\{ x^{[\idx]} \}_{k \in \N}$ eine Folge $\{ \nu^{[\idx]} \}_{k \in \N}$ von Näherungen der Lagrange-Multiplikatoren konstruiert werden kann, so dass $x^{[\idx]}$ und $\nu^{[\idx]}$ gegen einen KKT-Punkt $\x$ und $\hat{\nu}$ des Ausgangsproblems konvergieren.

Hierzu benötigen wir die stetige Differenzierbarkeit der Funktionen $f$ und $h_j$, $j=1, \ldots, p$. Ein KKT-Punkt $(\x, \hat{\nu})$ des Ausgangsproblems erfüllt
$$0 = \nabla f (\x) + \sum_{j=1}^p \hat{\nu}_j \nabla h_j (\x).$$
Da $x^{[\idx]}$ Minimalstelle der Penalty-Funktion mit Gewichtungsparameter $\eta_\idx$ ist, gilt notwendig
$$0 = \nabla_x P (x^{[\idx]}; \eta) = \nabla f (x^{[\idx]}) + \eta_\idx \cdot \sum_{j=1}^p h_j (x^{[\idx]}) \nabla h_j (x^{[\idx]}).$$
Vergleicht man die beiden Ausdrücke, so liegt es nahe,
\begin{equation}
\label{eqn:2.2}
\nu^{[\idx]} = \eta_\idx h_j (x^{[\idx]})
\end{equation}
als Approximation der Lagrange-Multiplikatoren $\hat{\nu}_j$ zu verwenden. 

Es gilt:
\begin{theorem}
Seien $f$ und $h_j$, $j=1, \ldots, p$, stetig differenzierbar und $\{ x^{[\idx]} \}_{\idx \in \N}$ eine durch das Penalty-Verfahren erzeugte Folge mit $x^{[\idx]} \to \x$ für $k \to \infty$. Die Gradienten $\nabla h_j (\x)$, $j=1, \ldots, p$, seien linear unabhängig, und $\{ \nu^{[\idx]} \}_{\idx \in \N}$ sei durch (\ref{eqn:2.2}) gegeben. Dann gelten:
\begin{enumerate}[label=(\alph*)]
\item Die Folge $\{ \nu^{[\idx]} \}_{k \in \N}$ konvergiert gegen einen Vektor $\hat{\nu}$. 
\item $(\x, \hat{\nu})$ ist ein KKT-Punkt des Ausgangsproblems.
\end{enumerate}
\qed
\end{theorem}

\subsubsection{Multiplikator-Penalty-Verfahren}

Multiplikator-Penalty-Verfahren ähneln den Penalty-Verfahren. Allerdings arbeiten sie mit einer exakten und differenzierbaren Penalty-Funktion --- der erweiterten Lagrange-Funktion.

Wir betrachten wieder das gleichungsrestringierte Problem \ref{prob:2.1.2}, d.h.
\begin{equation}
\label{eqn:2.3}
\min_{h (x) = 0} f (x)
\end{equation}
Darin seien die Funktionen $f : \R^n \to \R$ und $h = (h_1, \ldots, h_p)^T : \R^n \to \R^p$ zweimal stetig differenzierbar.

Sei $\x$ lokales Minimum des Problems. Dann ist $\x$ für $\eta > 0$ auch ein lokales Minimum von
$$\min_{h (x) = 0} f (x) + \dfrac{\eta}{2} \| h (x) \|^2$$
Die Lagrange-Funktion für dieses Problem lautet
$$\Lagrangian_a (x, \nu; \eta) := f (x) + \dfrac{\eta}{2} \| h (x) \|^2 + \nu^T h(x)$$
und heißt erweiterte \emph{Lagrange-Funktion (augmented Lagrangian)} oder \emph{Multiplikator-Penalty-Funktion}.

Es zeigt sich, dass der Gewichtungsparameter $\eta$ für $\Lagrangian_a$ nicht gegen $\infty$ streben muss, um ein lokales Minimum des Ausgangsproblems zu erreichen.

\begin{theorem}\label{eqn:2.2.1}
Sei $(\x, \hat{\nu})$ KKT-Punkt von (\ref{eqn:2.3}). Desweiteren sei die hinreichende Bedingung zweiter Ordnung (\ref{eqn:1.6}) erfüllt. Dann existiert ein endliches $\bar{\eta} > 0$, so dass $\x$ für jedes $\eta \geq \bar{\eta}$ ein striktes lokales Minimum von $\Lagrangian_a (\cdot, \hat{\nu}; \eta)$ ist. \qed
\end{theorem}

Auf Grund dieses Hilfssatzes kann man versuchen, das Ausgangsproblem (\ref{eqn:2.3}) indirekt zu lösen, indem die erweiterte Lagrange-Funktion minimiert wird: 
$$\min_{x \in \R^n} \Lagrangian_a (x, \hat{\nu}; \eta)$$
Der Penalty-Parameter $\eta$ muß jetzt, anders als bei den Penalty-Verfahren, nicht mehr gegen $\infty$ streben. Darüber hinaus ist $\Lagrangian_a$ differenzierbar, so dass bekannte Verfahren aus der unrestringierten Optimierung eingesetzt werden können.

\emph{Problem:} Der optimale Lagrange-Multiplikator $\hat{\nu}$ ist unbekannt.

Wir versuchen nun, $\hat{\nu}$ geeignet zu approximieren. Sei $\eta$ hinreichend groß und $x^{[\idx+1]}$ stationärer Punkt des Problems
$$\min_{x \in \R^n} \Lagrangian_a (x, \nu^{[\idx]}; \eta)$$
Dann gilt notwendig
$$0 = \nabla_x \Lagrangian_a (x^{[\idx+1]}, \nu^{[\idx]}; \eta) = \nabla f (x^{[\idx+1]}) + \sum_{j=1}^p (\nu_j^{[\idx]} + \eta \cdot h_j (x^{[\idx+1]}) \nabla h_j (x^{[\idx+1]}).$$
Andererseits gilt in einem KKT-Punkt $(\x, \hat{\nu})$ von (\ref{eqn:2.3}) notwendig
$$0 = \nabla_x \Lagrangian (\x, \hat{\nu}) = \nabla f (\x) + \sum \hat{\nu}_j \nabla h_j (\x).$$
Ein Vergleich beider Ausdrücke liefert die naheliegende Aufdatierungsvorschrift
$$\nu^{[\idx+1]} := \nu^{[\idx]} + \eta \cdot h (x^{[\idx+1]}).$$
Insgesamt entsteht das Multiplier-Penalty-Verfahren:

\begin{algorithm}\label{algo:2.2.2}\emph{(Multiplikator-Penalty-Verfahren)}
\begin{enumerate}[label=(\roman*)]
\item Wähle $x[0] \in \R^n$, $\nu^{[0]} \in \R^p$, $\eta_0 > 0$, $\sigma \in (0,1)$ und setze $k=0$. 
\item Ist $(x^{[\idx]}, \nu^{[\idx]})$ KKT-Punkt von (\ref{eqn:2.3}), {\tt{STOP}}.
\item Bestimme $x^{[\idx+1]}$ als Lösung von
$$\min_{x \in \R^n} \Lagrangian_a (x, \nu^{[\idx]}; \eta_\idx)$$
\item Setze $\nu^{[\idx+1]} := \nu^{[\idx]} + \eta_\idx h (x^{[\idx+1]})$.
\item Ist $\| h (x^{[\idx+1]}) \| \geq \sigma \| h (x^{[\idx]}) \|$, so setze $\eta_{\idx+1} := 10 \eta_\idx$, andernfalls setze $\eta_{\idx+1} := \eta_k$.
\item Setze $\idx := \idx+1$ und gehe zu (ii).
\end{enumerate}
\qed
\end{algorithm}

\subsubsection{Anwendung auf Ungleichungen}

Das Standard-Optimierungsproblem
\begin{equation}
\label{equ:2.4}
\min_{\substack{g (x) \leq 0,\\ h (x) = 0}} f (x)
\end{equation}
ist durch Einführung von Schlupfvariablen $s = (s_1, \ldots, s_m)^T \in \R^m$ äquivalent mit dem gleichungsrestringierten Problem
$$\min_{\substack{(x, s) \in \R^{n \times m} \\ g_i (x) + s_i^2 = 0,\; i=1, \ldots, m\\ h_j (x) = 0,\; j=1, \ldots, p}} f (x)$$
Die erweiterte Lagrange-Funktion hierfür lautet
$$
\bar{\Lagrangian}_a (x, s, \mu, \nu; \eta) 
= f (x) + \dfrac{\eta}{2} \| h (x) \|^2 + \nu^T h (x) + \sum_{i=1}^m \left(\mu_i \left(g_i (x) + s_i^2 \right) + \dfrac{\eta}{2} \left(g_i (x) + s_i^2 \right)^2 \right)
$$
Für festes $x$ kann die Minimierung bzgl. $s$ explizit ausgeführt werden und man erhält
$$\hat{s}_i = \left( \max \left\{ 0, -\left( \dfrac{\mu_i}{\eta} + g_i (x) \right) \right\} \right)^\frac{1}{2} , i=1, \ldots, m.$$
Einsetzen in die erweiterte Lagrange-Funktion liefert
\begin{eqnarray*}
\Lagrangian_a (x, \mu, \nu; \eta) & = f(x) & + \nu^T h (x) + \dfrac{\eta}{2} \| h (x) \|^2 \\
&& + \dfrac{1}{2 \eta} \sum_{i=1}^m \left( ( \max \{ 0, \mu_i + \eta g_i (x) \} )^2 - \mu_i^2 \right) \\
& = f (x) & + \sum_{j=1}^p \left( \nu_j h_j (x) + \dfrac{\eta}{2} h_j (x)^2 \right) \\
&& + \sum_{i=1}^m 
\begin{cases}
\mu_i g_i (x) + \dfrac{\eta}{2} g_i (x)^2, & \text{falls } \mu_i + \eta g_i (x) \geq 0 \\
- \dfrac{\mu_i^2}{2 \eta} & \text{sonst.}
\end{cases}
\end{eqnarray*}
Beachte, dass diese Funktion nur noch stetig differenzierbar ist.

Für die Multiplikatoren ergeben sich die Aufdatierungsformeln 
\begin{eqnarray*}
\mu_i^{[\idx+1]} & := & \max \left\{ 0, \mu^{[\idx]} + \eta \cdot g_i (x^{[\idx+1]}) \right\},\; i=1, \ldots, m \\
\nu^{[\idx+1]} & := & \nu^{[\idx]} + \eta \cdot h (x^{[\idx+1]}),
\end{eqnarray*}

\subsection{SQP-Verfahren}

Die sequentielle quadratische Programmierung (SQP) wird vielfach in der Literatur behandelt. Es existieren diverse Implementierungen. Zunächst diskutieren wir das lokale SQP-Verfahren (mit Schrittweite 1) und erweitern das lokale Verfahren dann durch eine Globalisierungsstrategie, die auf dem Armijo-Verfahren basiert.

\subsubsection{Das lokale SQP-Verfahren}

Zur Motivation des SQP-Verfahrens erinnern wir uns an das Lagrange-Newton-Verfahren. Das Lagrange-Newton-Verfahren eignet sich zur Lösung des gleichungsrestringierten Optimierungsproblems
$$\min_{h (x) = 0} f (x)$$
wobei $f : \R^n \to \R$ und $h : \R^n \to \R^p$ zweimal stetig differenzierbare Funktionen seien und $\Lagrangian (x, \nu) = f (x) + \nu^T h (x)$ die Lagrange-Funktion bezeichnet. Das Lagrange-Newton-Verfahren entsteht durch Anwendung des Newton-Verfahrens auf die KKT-Bedingungen
$$\nabla_x \Lagrangian (x, \nu) = 0 \text{ und } h (x) = 0$$
und lautet wie folgt:
\begin{algorithm}\emph{(Lagrange-Newton-Verfahren)}
\begin{enumerate}[label=(\roman*)]
\item Wähle Startschätzungen $x^{[0]} \in \R^n$ und $\nu^{[0]} \in \R^p$, $\epsilon > 0$ und setze $k = 0$. 
\item Falls $\max \left\{ \| \nabla_x \Lagrangian (x^{[\idx]}, \nu^{[\idx]}) \|, \| h (x^{[\idx]}) \| \right\} \leq \epsilon$, {\tt{STOP}}.
\item Löse das lineare Gleichungssystem
\begin{equation}
\label{eqn:3.1}
\begin{pmatrix}
\nabla_{xx}^2 \Lagrangian (x^{[\idx]}, \nu^{[\idx]}) & h' (x^{[\idx]})^T \\
0 & h' (x^{[\idx]}) 
\end{pmatrix}
\begin{pmatrix}
d \\ v
\end{pmatrix}
= -
\begin{pmatrix}
\nabla_x \Lagrangian (x^{[\idx]}, \nu^{[\idx]}) \\
h (x^{[\idx]}). 
\end{pmatrix}
\end{equation}
und setze
\begin{eqnarray}
\label{eqn:3.2}
x^{[\idx+1]} := x^{[\idx]} + d, &&\nu^{[\idx+1]} := \nu^{[\idx]} + v
\end{eqnarray}
\item Setze $k := k+1$und gehe zu (ii).
\end{enumerate}
\qed
\end{algorithm}
Wir starten zunächst mit einer Beobachtung. Das lineare Gleichungssystem (\ref{eqn:3.1}) in (iii) des Lagrange-Newton-Verfahrens entsteht auch auf andere Art. Wir erinnern uns an das Newton-Verfahren für unrestringierte Optimierungsprobleme. Dort hatten wir das Newtonverfahren auf zwei Arten motiviert: 
\begin{enumerate}
\item Anwendung des Newtonverfahrens auf die notwendigen Bedingung $\nabla f = 0$ (indirekter Ansatz); 
\item lokale Approximation der Zielfunktion durch eine quadratische Funktion (direkter Ansatz).
\end{enumerate}
Beide Ansätze lieferten das gleiche Verfahren.

Zur Abkürzung setzen wir im Folgenden
$$Q_\idx := \nabla_{xx}^2 \Lagrangian (x^{[\idx]}, \nu^{[\idx]}).$$
Wir betrachten nun wieder das gleichungsrestringierte Optimierungsproblem und approximieren es lokal im Punkt $(x^{[\idx]}, \nu^{[\idx]})$ durch das quadratische Optimierungsproblem
$$\min_{\substack{d \in \R^n \\ h (x^{[\idx]}) + h' (x^{[\idx]}) d = 0}} \dfrac{1}{2} d^T Q_\idx d + \nabla f (x^{[\idx]})^T d$$
Die Lagrange-Funktion für das quadratische Optimierungsproblem ist gegeben durch
$$\Lagrangian_{QP} (d, \eta) := \dfrac{1}{2} d^T Q_\idx d + \nabla f (x^{[\idx]})^T d + \eta^T h (x^{[\idx]}) + h' (x^{[\idx]}) d$$
Auswertung der KKT-Bedingungen führt auf das lineare Gleichungssystem
\begin{eqnarray*}
Q_\idx d + \nabla f (x^{[\idx]}) + h' (x^{[\idx]})^T \eta & = & 0 \\
h (x^{[\idx]}) + h' (x^{[\idx]}) d & = & 0
\end{eqnarray*}
bzw.
\begin{equation}
\label{eqn:3.3}
\begin{pmatrix}
Q_\idx & h' (x^{[\idx]})^T \\
h' (x^{[\idx]}) & 0
\end{pmatrix}
\begin{pmatrix}
d \\ \eta
\end{pmatrix}
= -
\begin{pmatrix}
\nabla f (x^{[\idx]}) \\ h (x^{[\idx]}) 
\end{pmatrix}
\end{equation}
Subtraktion von $h' (x^{[\idx]})^T \nu^{[\idx]}$ auf beiden Seiten der ersten Gleichung in (\ref{eqn:3.3}) liefert das lineare Gleichungssystem
\begin{equation}
\label{eqn:3.4}
\begin{pmatrix}
Q_\idx & h' (x^{[\idx]})^T \\
h' (x^{[\idx]}) & 0
\end{pmatrix}
\begin{pmatrix}
d \\ \eta - \nu^{[\idx]}
\end{pmatrix}
= -
\begin{pmatrix}
\nabla_x \Lagrangian (x^{[\idx]}, \nu^{[\idx]}) \\ h (x^{[\idx]})
\end{pmatrix}
\end{equation}
Ein Vergleich von (\ref{eqn:3.4}) mit (\ref{eqn:3.1}) zeigt, dass diese zwei Gleichungssysteme identisch sind, wenn man noch $v := \eta - \nu^{[\idx]}$ definiert. Die neuen Iterierten in (3.2) lassen sich damit wie folgt berechnen:
$$x^{[\idx+1]} = x^{[\idx]} + d, \quad \nu^{[\idx+1]} = \nu^{[\idx]} + v = \eta.$$
\begin{summary}
Für gleichungsrestringierte Optimierungsprobleme ist das Lagrange-Newton-Verfahren identisch mit dem oben hergeleiteten sukzessiven quadratischen Optimierungsverfahren, wenn der Multiplikator $\eta$ des quadratischen Hilfsproblems als neue Approximation für den Multiplikator $\nu$ des Ausgangsproblems verwendet wird. \qed
\end{summary}
Diese Beobachtung motiviert die folgende Erweiterung des quadratischen Hilfsproblems für Standard-Optimierungsprobleme mit Gleichungs- und Ungleichungsrestriktionen:
\begin{problem}\emph{(QP Problem $QP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]}))$}
\label{prob:3.1.2}
\begin{eqnarray*}
\dfrac{1}{2} d^T Q_\idx d + \nabla f (x^{[\idx]})^T d & = & \min_{d \in \R^n} ! \\
g (x^{[\idx]}) + g' (x^{[\idx]}) d & \leq & 0 \\
h (x^{[\idx]}) + h' (x^{[\idx]}) d & = & 0
\end{eqnarray*}
\qed
\end{problem}
Sukzessive quadratische Approximation liefert das lokale SQP Verfahren:
\begin{algorithm}\emph{(Lokales SQP Verfahren)}
\label{algo:3.1.3}
\begin{enumerate}[label=(\roman*)]
\item Wähle Startwerte $(x^{[0]}, \mu^{[0]}, \nu^{[0]}) \in \R^n \times \R^m \times \R^p$ und setze $k = 0$.
\item Falls $(x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$ ein KKT-Punkt des Standard-Optimierungsproblems ist, {\tt{STOP}}.
\item Berechne einen KKT-Punkt $(d^{[\idx]}, \mu^{[\idx+1]}, \nu^{[\idx+1]}) \in \R^n \times \R^m \times \R^p$ des quadratischen Optimierungsproblems $QP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$.
\item Setze $x^{[\idx+1]} := x^{[\idx]} + d^{[\idx]}$, $k := k+1$ und gehe zu (ii).
\end{enumerate}
\qed
\end{algorithm}
\begin{remark}
\begin{itemize}
\item Es ist nicht notwendig, die Indexmenge $\A(\x)$ der aktiven Ungleichungsnebenbedingungen im Voraus zu kennen.
\item Die Iterierten $x^{[\idx]}$ sind in der Regel nicht zulässig, d.h. es gilt i.A. $x^{[\idx]} \notin \Sigma$.
\end{itemize}
\qed
\end{remark}
Die lokale Konvergenz des SQP Verfahrens wird im folgenden Satz formuliert.
\begin{theorem}\emph{(Lokale Konvergenz des SQP-Verfahrens)}
\\ Voraussetzungen:
\begin{enumerate}[label=(\roman*)]
\item $\x$ ist lokales Minimum des Standard-Optimierungsproblems und $\hat{\mu}$ und $\hat{\nu}$ bezeichnen die Lagrange-Multiplikatoren.
\item Die Funktionen $f$, $g_i$, $i=1, \ldots, m$, und $h_j$, $j=1, \ldots, p$, sind zweimal stetig differenzierbar mit Lipschitz-stetigen zweiten Ableitungen.
\item Es gilt die 'Linear Independence Constraint Qualification' (LICQ) in $\x$.
\item Die strikte Komplementaritätsbedingung $\hat{\mu}_i - g_i (\x) \geq 0$ ist für alle $i \in \A (\x)$ erfüllt.
\item Es gilt die hinreichende Bedingung zweiter Ordnung:
$$d^T \nabla_{xx}^2 \Lagrangian (\x, \hat{\mu}, \hat{\nu}) d > 0$$
für alle $0 \not= d \in \R^n$ mit
$$\nabla g_i (\x)^T d = 0,\quad i \in \A (\x),\quad \nabla h_j (\x)^T d = 0,\quad j=1, \ldots, p.$$
\end{enumerate}
Dann existieren Umgebungen $U$ von $(\x, \hat{\mu}, \hat{\nu})$ und $V$ von $(0, \hat{\mu}, \hat{\nu})$, so dass alle quadratischen Optimierungsprobleme $QP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$ für beliebige Startwerte
$$(x^{[0]}, \mu^{[0]}, \nu^{[0]}) \in U$$
in $V$ eine eindeutige lokale Lösung $d^{[\idx]}$ mit eindeutigen Multiplikatoren $\mu^{[\idx+1]}$ und $\nu^{[\idx+1]}$ besitzen. \\
Desweiteren konvergiert die Folge $\left\{ (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]}) \right\}_{k \in \N}$ quadratisch gegen $(\x, \hat{\mu}, \hat{\nu})$. \qed
\end{theorem}
\begin{remark}\emph{(Approximation der Hessematrix)}
\label{rem:3.1.6}
Die Verwendung der exakten Hessematrix $Q_\idx = \nabla_{xx}^2 \Lagrangian (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$ im QP-Problem hat zwei Nachteile:
\begin{itemize}
\item In vielen Anwendungen ist die Hessematrix nicht explizit bekannt. Die numerische Approximation durch finite Differenzen ist sehr aufwendig und ungenau.
\item Die Hessematrix kann indefinit sein. Dies erschwert die Lösung der QP-Hilfsprobleme erheblich. Es ist daher wünschenswert, die Hessematrix durch eine positiv definite Matrix zu ersetzen (siehe dazu die Idee der Quasi-\textsc{Newton}-Verfahren).
\end{itemize}
In der Praxis wird die Hessematrix der Lagrange-Funktion $Q_\idx$ in Iteration $k$ durch eine geeignete Matrix $H_\idx$ ersetzt. \textsc{Powell} [Pow78] schlug vor, die modifizierte BFGS-Update-Formel mit
\begin{equation}
\label{eqn:3.5}
H_{\idx+1} = H_\idx + \dfrac{q^{[\idx]} (q^{[\idx]})^T}{(q^{[\idx]})^T d^{[\idx]}} - \dfrac{H_\idx d^{[\idx]} (d^{[\idx]})^T H_\idx}{(d^{[\idx]})^T H_\idx d^{[\idx]}},
\end{equation}
mit
\begin{eqnarray*}
d^{[\idx]} & = & x^{[\idx+1]} - x^{[\idx]}, \\
q^{[\idx]} & = & \theta_\idx y^{[\idx]} + (1 - \theta_\idx) H_\idx d^{[\idx]}, \\
y^{[\idx]} & = & \nabla_x \Lagrangian (x^{[\idx+1]}, \mu^{[\idx]}, \nu^{[\idx]}) - \nabla_x \Lagrangian (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]}), \\
\theta_\idx & = &
\begin{cases}
1, & \text{falls } (d^{[\idx]})^T y^{[\idx]} \geq 0.2 \cdot (d^{[\idx]})^T H_\idx d^{[\idx]}, \\
\dfrac{0.8 \cdot (d^{[\idx]})^T H_\idx d^{[\idx]}}{(d^{[\idx]})^T H_\idx d^{[\idx]} - (d^{[\idx]})^T y^{[\idx]}}, & \text{sonst}
\end{cases}
\end{eqnarray*}
zu verwenden. Diese Update-Formel garantiert, dass $H_{\idx+1}$ symmetrisch und positiv definit bleibt, wenn $H_\idx$ symmetrisch und positiv definit war. Für $\theta_\idx = 1$ entsteht die BFGS-Formel, welche schon bei den Quasi-\textsc{Newton}-Verfahren verwendet wurde (allerdings musste dort durch Wahl einer geeigneten Schrittweiten-Strategie noch die Bedingung $(d^{[\idx]})^T y^{[\idx]} > 0$ garantiert werden). \\
Wird die modifizierte BFGS-Update-Formel im SQP-Verfahren verwendet, kann immerhin noch superlineare Konvergenz nachgewiesen werden. \qed
\end{remark}

\subsubsection{Globalisierung des SQP-Verfahrens}

Das Konvergenzresultat zeigt, dass das SQP-Verfahren für alle Startwerte, die in einer Umgebung eines lokalen Minimums liegen, konvergent ist. In der Praxis ist diese Umgebung jedoch unbekannt und kann sehr klein sein. Daher ist es notwendig, das SQP-Verfahren zu globalisieren, so dass es (unter geeigneten Bedingungen) für beliebige Startwerte konvergiert. Wie im unrestringierten Fall wird dies durch Einführung einer Schrittweite $\alpha_\idx > 0$ erreicht. Die neue Iterierte ist gegeben durch
$$x^{[\idx+1]} = x^{[\idx]} + \alpha_\idx \cdot d^{[\idx]},$$
wobei $d^{[\idx]}$ wie zuvor ein quadratisches Hilfsproblem löst. Zur Bestimmung der Schrittweite $\alpha_\idx$ wird wieder eine eindimensionale Liniensuche in Richtung $d^{[\idx]}$ durchgeführt. Im Unterschied zur unrestringierten Optimierung tritt jetzt allerdings das folgende Problem auf:
$$\text{Wann ist } x^{[\idx+1]} \text{ 'besser' als } x^{[\idx]} \text{ ?}$$
Im unrestringierten Fall konnte diese Frage leicht durch einen Vergleich der Zielfunktionswerte beantwortet werden: $x^{[\idx+1]}$ ist besser als $x^{[\idx]}$, wenn $f (x^{[\idx+1]}) < f (x^{[\idx]}) gilt.$

Im restringierten Fall ist dies nicht mehr so einfach, da die Iterierten $x^{[\idx]}$ des SQP-Verfahrens i.a. unzulässig sind. Eine Verbesserung kann also sowohl an Hand der Zielfunktionswerte als auch an Hand der Verletzungen der Nebenbedingungen gemessen werden. Dies sind i.A. zwei miteinander konkurrierende Kriterien, da man einen besseren Zielfunktionswert leicht auf Kosten der Zulässigkeit erreichen kann und umgekehrt.

Ein Ansatz, um dieses Dilemma aufzulösen, besteht in der Verwendung von sogenannten Bewertungsfunktionen (engl. merit functions), die im einfachsten Fall Zielfunktion und Verletzung der Nebenbedingungen gewichtet in einer skalar-wertigen Funktion vereinen (siehe Idee der Penalty-Funktion).

Mithilfe der Bewertungsfunktion ist es möglich zu entscheiden, ob die neue Iterierte $x^{[\idx+1]}$ 'besser' ist als die alte Iterierte $x^{[\idx]}$. Dabei ist die neue Iterierte besser als die alte, falls entweder ein hinreichender Abstieg in der Zielfunktion $f$ oder eine weniger starke Verletzung der Nebenbedingungen erreicht wird, wobei sich das jeweils andere Kriterium nicht substantiell verschlechtern darf.

Eine allgemeine Klasse von Bewertungsfunktionen wird durch
\begin{equation}
\label{eqn:3.6}
P_r (x; \eta) := f (x) + \eta \cdot r (x)
\end{equation}
definiert (vgl. (\ref{eqn:2.1})), wobei $\eta > 0$ einen Gewichtungsparameter und $r : \R^n \to [0, \infty)$ eine stetige Funktion mit der Eigenschaft 
$$
r (x)
\begin{cases}
= 0, & \text{falls } x \in \Sigma, \\
> 0, & \text{falls } x \notin \Sigma
\end{cases}
$$
bezeichnen.

\begin{example}\emph{(Bewertungsfunktion)}
Eine typische Bewertungsfunktion für das Standard-Optimierungsproblem, die auf der $1$-Norm basiert, ist die $\ell_1$-Bewertungsfunktion:
$$\ell_1 (x; \eta) := f (x) + \eta \sum \max \{ 0, g_i (x) \} + \sum | h_j (x) | ,\quad \eta > 0.$$
Beachte, dass unzulässige Punkte $x \notin \Sigma$ durch die Terme
$$\sum \max \{ 0, g_i (x) \} + \sum | h_j (x) | > 0$$
bestraft werden. Desweiteren ist $\ell_1$ Lipschitz-stetig (falls $f$, $g_i$ und $h_j$ differenzierbar sind), aber nicht differenzierbar. \\
Allgemeinere Bewertungsfunktionen basieren auf der $q$-Norm:
$$\ell_q (x; \eta) := f (x) + \eta \left( \sum_{i=1}^m (\max \{0, g_i (x) \} )^q + \sum_{j=1}^p | h_j (x) |^q \right)^\frac{1}{q}$$
und
$$\ell_\infty (x; \eta) := f (x) + \eta \cdot \max \{ 0, g_1 (x), \ldots, g_m (x), | h_1 (x) |, \ldots, | h_p (x) | \}$$
\qed
\end{example}
Von besonderem Interesse sind die sogenannten exakten Bewertungsfunktionen, da für diese Bewertungsfunktionen lokale Minima des restringierten Ausgangsproblems auch lokale Minima der unrestringierten Bewertungsfunktion sind und der Gewichtungsparameter $\eta$ dabei endlich gewählt werden kann.

\begin{definition}\emph{(Exakte Bewertungsfunktion)}
Die Bewertungsfunktion $P_r (x; \eta)$ in (\ref{eqn:3.6}) heißt exakt in einem lokalen Minimum $\x$ des Standard-Optimierungsproblems, falls es einen endlichen (!) Parameter $\hat{\eta} > 0$ gibt, so dass $\x$ ein lokales Minimum von $P_r (\cdot ; \eta)$ für alle $\eta \geq \hat{\eta}$ ist. \qed
\end{definition}

Es wäre wünschenswert, eine differenzierbare exakte Bewertungsfunktion zu haben. Dummerweise kann gezeigt werden, dass Bewertungsfunktionen der Form $P_r (x; \eta)$ aus (\ref{eqn:3.6}) in einem lokalen Minimum $\x$ stets nicht differenzierbar sind, falls sie exakt sind und $\nabla f (\x) \not= 0$ gilt (letzteres ist der Normalfall in der restringierten Optimierung).

Der folgende Satz sagt aus, dass die Bewertungsfunktionen $\ell_q$ für $1 \leq q \leq \infty$ exakt sind, wenn eine Regularitätsbedingung gilt.
\begin{theorem}
Sei $\x \in \Sigma$ ein isoliertes lokales Minimum des Standard-Opti\-mie\-rungs\-problems, welches die LICQ erfüllt. Dann ist $\ell_q$ exakt für $1 \leq q \leq \infty$. \qed
\end{theorem}

Im Folgenden beschränken wir uns auf die $\ell_1$-Bewertungsfunktion. Es liegt nun nahe, das restringierte Standard-Optimierungsproblem für hinreichend großes $\eta > 0$ durch das unrestringierte Minimierungsproblem
$$\min_{x \in \R^n} \ell_1 (x; \eta)$$
zu ersetzen. Diese Idee wird im SQP-Verfahren ausgenutzt, um eine Schrittweite $\alpha$ mittels eindimensionaler Liniensuche (siehe Armijo-Verfahren) für die Funktion 
$$\varphi (\alpha) := \ell_1 (x^{[\idx]} + \alpha \cdot d^{[\idx]}; \eta)$$ 
durchzuführen. Wie oben erwähnt, ist die exakte $\ell_1$-Bewertungsfunktion nicht differenzierbar. Allerdings ist sie immerhin noch richtungsdifferenzierbar, d.h. der Grenzwert
$$\ell_1' (x; d; \eta) := \lim_{\alpha \downarrow 0} \dfrac{\ell_1 (x + \alpha \cdot d; \eta) - \ell_1 (x; \eta)}{\alpha}$$
existiert für alle $x \in \R^n$ und alle Richtungen $d \in \R^n$, und man kann zeigen, dass ein KKT-Punkt $(d^{[\idx]}, \mu^{[\idx+1]}, \nu^{[\idx+1]})$ mit $d^{[\idx]} \not= 0$ des QP-Problems $QP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$ die Abschätzung
$$\ell_1' (x^{[\idx]}; d^{[\idx]}; \eta) \leq -(d^{[\idx]})^T Q_\idx d^{[\idx]} < 0$$
erfüllt, falls
\begin{itemize}
\item $Q_\idx$ symmetrisch und positiv definit ist (was bei Verwendung des modifizierten BFGS-Updates $H_\idx$ erfüllt ist) und
\item der Gewichtungsparameter $\eta$ die Bedingung
\begin{equation}
\label{eqn:3.7}
\eta \geq \max \left\{ \mu_1^{[\idx+1]}, \ldots, \mu_m^{[\idx+1]}, | \nu_1^{[\idx+1]} |, \ldots, | \nu_p^{[\idx+1]} | \right\}
\end{equation}
erfüllt. Hierin bezeichnen $\mu_i^{[\idx+1]}$, $i=1, \ldots, m$, und $\nu_j^{[\idx+1]}$, $j=1, \ldots, p$, die Lagrange-Multiplikatoren des QP-Problems.
\end{itemize}

\begin{summary}
Eine Liniensuche mit dem \textsc{Armijo}-Verfahren kann durchgeführt werden, wenn die Hessematrix $Q_\idx$ positiv definit ist, oder alternativ der modifizierte BFGS-Update $H_\idx$ im QP verwendet wird, und wenn der Gewichtungsparameter hinreichend groß gewählt wird, was man durch iteratives Anpassen z.B. gemäß der Formel
\begin{equation}
\label{eqn:3.8}
\eta_{\idx+1} := \max \left\{ \eta_\idx , \max \{ \mu^{[\idx+1]}, \dots, \mu^{[\idx+1]}, | \nu^{[\idx+1]} |, \ldots, | \nu^{[\idx+1]} | \} + \epsilon \right\},
\end{equation}
erreichen kann ($\epsilon \geq 0$ ist ein Parameter). \qed
\end{summary}

Insgesamt erhalten wir das globalisierte SQP-Verfahren:
\begin{algorithm}\emph{(Globalisiertes SQP-Verfahren)}
\begin{enumerate}[label=(\roman*)]
\item Wähle Startwerte $(x^{[0]}, \mu^{[0]}, \nu^{[0]}) \in \R^n \times \R^m \times \R^p$ , $H_0 \in \R^{n \times n}$ symmetrisch und positiv definit, $\beta \in (0, 1)$, $\sigma \in (0, 1)$ und setze $\idx=0$.
\item Falls $(x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$ ein KKT-Punkt des Standard-Optimierungsproblems ist, {\tt{STOP}}.
\item \emph{QP-Hilfsproblem:}
Berechne einen KKT-Punkt $(d^{[\idx]}, \mu^{[\idx+1]}, \nu^{[\idx+1]}) \in \R^n \times \R^m \times \R^p$ des quadratischen Hilfsproblems $QP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$, wobei die Hessematrix $Q_\idx$ durch die modifizierte BFGS-Update-Matrix $H_\idx$ ersetzt ist.
\item Wähle $\eta^{[\idx]}$ hinreichend groß, z.B. gemäß (\ref{eqn:3.8}).
\item \emph{Armijo-Regel:}
Bestimme eine Schrittweite $\alpha_\idx = \max \{ \beta^j \;:\; j=0, 1, 2, \ldots \}$ mit
$$\ell_1 (x^{[\idx]} + \alpha_\idx \cdot d^{[\idx]}; \eta^{[\idx]}) \leq \ell_1 (x^{[\idx]}; \eta^{[\idx]}) + \sigma \cdot \alpha_\idx \cdot \ell_1' (x^{[\idx]}; d^{[\idx]}; \eta^{[\idx]}).$$
\item \emph{Modifizierter BFGS-Update:}
Berechne $H_{k+1}$ gemäß der Update-Formel (\ref{eqn:3.5}).
\item Setze $x^{[\idx+1]} := x^{[\idx]} + \alpha_\idx \cdot d^{[\idx]}$, $\idx := \idx+1$ und gehe zu (ii).
\end{enumerate}
\qed
\end{algorithm}

\begin{remark}
\begin{itemize}
\item \dots
\item Es gibt auch differenzierbare exakte Bewertungsfunktionen, diese sind allerdings nicht von der Gestalt in (\ref{eqn:3.6}). Eine häufig benutzte differenzierbare exakte Bewertungsfunktion für das Standard-Optimierungsproblem ist die \emph{erweiterte Lagrange-Funktion}
\begin{eqnarray*}
\Lagrangian_a (x, \mu, \nu; \eta) & = f (x) & + \nu^T h (x) + \dfrac{\eta}{2} \cdot \| h (x) \|^2 \\
&& + \dfrac{1}{2 \eta} \cdot \sum_{i=1}^m \left(( \max \{ 0, \mu_i + \eta \cdot g_i (x) \} )^2 - \mu_i^2 \right) \\
& = f (x) & + \sum_{j=1}^p \left( \nu_j \cdot h_j (x) + 2 h_j (x)^2 \right) \\
&& + \sum_{i=1}^m
\begin{cases}
\mu_i \cdot g_i (x) + \dfrac{\eta}{2} \cdot g_i (x)^2, & \text{falls } \mu_i + \eta \cdot g_i (x) \geq 0, \\
- \dfrac{\mu_i^2}{2 \eta}, & sonst.
\end{cases}
\end{eqnarray*}
Ein SQP-Verfahren unter Verwendung der erweiterten Lagrange-Funktion wird in Schittkowsi [Sch81, Sch83] diskutiert.
\item In praktischen Anwendungen wird anstatt eines einzelnen Gewichtungsparameters $\eta$ jeder Summand der Strafterme in der Bewertungsfunktion individuell gewichtet, etwa durch $\eta_i$, $i = 1, \ldots, m$ und $\hat{\eta}_j$, $j = 1, \ldots, p$. \textsc{Powell} [Pow78] schlug folgende Update-Formel vor:
\begin{eqnarray*}
\eta_i^{[\idx+1]} & := & \max_{i=1, \ldots, m} \left\{ | \mu_i^{[\idx+1]} |, \dfrac{1}{2} \left( \eta^{[\idx]} + | \mu_i^{[\idx+1]} | \right) \right\}, \\
\hat{\eta}_j^{[\idx+1]} & := & \max_{j=1, \ldots, p} \left\{ | \nu_j^{[\idx+1]} |, \dfrac{1}{2} \left( \hat{\eta}_j^{[\idx]} + | \nu_j^{[\idx+1]} | \right) \right\}
\end{eqnarray*}
Diese Formel hat sich in der Praxis bewährt.
\item \ldots
\end{itemize}
\qed
\end{remark}

\subsubsection{Inkonsistentes QP Problem}

\ldots

\textsc{Powell} schlug vor, die Nebenbedingungen des QP-Problems zu relaxieren, so dass das relaxierte QP-Problem zulässig ist. Das ursprüngliche QP-Problem wird ersetzt durch ein relaxiertes QP-Problem.

\begin{problem}\emph{(Relaxiertes QP-Problem $RQP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$)}
\begin{eqnarray*}
\dfrac{1}{2} d^T H_\idx d + \nabla f (x^{[\idx]})^T d + \dfrac{\eta}{2} \delta^2 & = & \min_{\substack{d \in \R^n \\ \delta \in [0, 1]}} \\
g_i (x^{[\idx]}) (1 - \sigma_i \delta) + \nabla g_i (x^{[\idx]})^T d & \leq & 0, \quad i=1, \ldots, m, \\
h_j (x^{[\idx]})(1-\delta) + \nabla h_j (x^{[\idx]})^T d & = & 0, \quad j=1, \ldots, p.
\end{eqnarray*}
\qed
\end{problem}

Hierin ist
$$
\sigma_i = 
\begin{cases}
0, & \text{falls } g_i (x^{[\idx]}) < 0, \\
1, & \text{sonst,}
\end{cases}
\quad i=1, \ldots, m.
$$
Der Punkt $d = 0$ und $\delta = 1$ ist stets zulässig für $RQP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$. Erfüllt die optimale Lösung $(d, \delta)$ von $RQP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$ die Beziehung $\delta = 0$, dann ist d auch optimal für das ursprüngliche QP-Problem $QP (x^{[\idx]}, \mu^{[\idx]}, \nu^{[\idx]})$. Um tatsächlich $\delta = 0$ zu erreichen, muss der Gewichtungsparameter $\eta$, der auch in der Bewertungsfunktion auftritt, hinreichend groß sein.

\subsubsection{Quadratische Optimierung}

Wir widmen uns nun einem Verfahren zur Lösung des wohl einfachsten nichtlinearen Optimierungsproblems – dem quadratischen Optimierungsproblem. Zunächst beschränken wir uns auf den Fall mit Gleichungsrestriktionen.

\begin{problem}\emph{(Quadratisches Optimierungsproblem mit Gleichungsbeschränkungen)}
Für eine symmetrische Matrix $W \in \R^{n \times n}$, eine Matrix $B \in \R^{p \times n}$ und Vektoren $c \in \R^n$ und $v \in \R^p$ minimiere
$$f (x) := \dfrac{1}{2} x^T W x + c^T x$$
unter der Nebenbedingung
$$h (x) := B x - v = 0.$$
\qed
\end{problem}
Die KKT-Bedingungen in einem Minimum $\x$ mit Lagrange-Multiplikator $\nu \in \R^p$ lauten
\begin{equation}
\label{eqn:3.10}
\begin{pmatrix}
W & B^T  \\ B & 0
\end{pmatrix}
\begin{pmatrix}
\x \\ \nu
\end{pmatrix}
=
\begin{pmatrix}
-c \\ v
\end{pmatrix}
\end{equation}
Beachte, dass hier wieder die sogenannte KKT-Matrix auftritt. Ist $W$ positiv definit auf dem Kern von $B$ und $Rang(B) = p$, so ist die Matrix invertierbar. Ist $W$ positiv semi-definit, so ist $f$ konvex und jede Lösung des Gleichungssystems ist zugleich globale Lösung des quadratischen Optimierungsproblems.

Im Hinblick auf ein später zu diskutierendes iteratives Verfahren formen wir (\ref{eqn:3.10}) um und setzen dazu $\x = x^{[\idy]} + d$, wobei $x^{[\idy]}$ ein beliebiger zulässiger Punkt mit $h (x^{[\idy]}) = 0$ sei.

Dann ist (\ref{eqn:3.10}) äquivalent mit
$$
\begin{pmatrix}
W & B^T  \\ B & 0
\end{pmatrix}
\begin{pmatrix}
x^{[\idy]} + d \\ \nu
\end{pmatrix}
=
\begin{pmatrix}
-c \\ v
\end{pmatrix},
$$
bzw. mit
$$
\begin{pmatrix}
W & B^T  \\ B & 0
\end{pmatrix}
\begin{pmatrix}
d \\ \nu
\end{pmatrix}
=
\begin{pmatrix}
-c \\ v
\end{pmatrix}
-
\begin{pmatrix}
W & B^T  \\ B & 0
\end{pmatrix}
\begin{pmatrix}
\x \\ 0
\end{pmatrix}
=
\begin{pmatrix}
-\nabla f (x^{[\idy]}) \\ 0
\end{pmatrix}.
$$
Diese Betrachtungen zeigen
\begin{theorem}
\label{theo:3.4.2}
Ist $x^{[\idy]} \in \R^n$ zulässig, so erfüllen $x = x^{[\idy]} + d$ und $\nu \in \R^p$ die KKT-Bedingungen des gleichungsbeschränkten quadratischen Optimierungsproblems, wenn $(d, \nu)$ das lineare Gleichungssystem
\begin{equation}
\label{eqn:3.11}
\begin{pmatrix}
W & B^T \\ B & 0
\end{pmatrix}
\begin{pmatrix}
d \\ \nu
\end{pmatrix}
=
\begin{pmatrix}
-\nabla f (x^{[\idy]}) \\ 0
\end{pmatrix}.
\end{equation}
löst. \qed
\end{theorem}
Wir lassen nun auch Ungleichungen zu und betrachten allgemeine quadratische Optimierungsprobleme:
\begin{problem}\emph{(Quadratisches Optimierungsproblem)}
Für eine symmetrische Matrix $W \in \R^{n \times n}$, Vektoren $c \in \R^n$, $a_i \in \R^n$, $i \in \I$, $b_j \in \R^n$, $j \in \J$, und Zahlen $u_i$, $i \in \I$, $v_j \in \R$, $j \in \J$, minimiere
$$f (x) := \dfrac{1}{2} x^T W x + c^T x$$
unter den Nebenbedingungen
\begin{eqnarray*}
g_i (x) := a_i^T x - u_i & \leq & 0,\quad i \in \I \\
h_j (x) := b_j^T x - v_j & = & 0,\quad j \in \J.
\end{eqnarray*}
\qed
\end{problem}
Mit
$$
A := 
\begin{pmatrix}
a_1^T \\ \vdots \\ a_m^T
\end{pmatrix}
,\quad B := 
\begin{pmatrix}
b_1^T \\ \vdots \\ b_p^T
\end{pmatrix}
,\quad v = 
\begin{pmatrix}
v_1 \\ \vdots \\ v_p
\end{pmatrix}
,\quad u = 
\begin{pmatrix}
u_1 \\ \vdots \\ u_p
\end{pmatrix}
$$
lautet das Problem in Matrixschreibweise
\begin{eqnarray*}
\dfrac{1}{2} x^T W x + c^T x & = & \min_{x \in \R^n} ! \\
A x & \leq & u \\ 
B x & = & v
\end{eqnarray*}

Auswertung der KKT-Bedingungen in einem lokalen Minimum $\x$ liefert
\begin{eqnarray*}
\mu_i & \geq & 0,\quad i \in \I, \\
\mu_i \cdot g_i (\x) & = & 0,\quad i \in \I, \\
W \x + c + \sum_{i=1}^m \mu_i \cdot a_i + \sum_{j=1}^p \nu_j \cdot b_j & = & 0, \\
a_i^T \x - u_i & \leq & 0,\quad i \in \I, \\
b_j^T \x - v_j & = & 0,\quad j \in \J.
\end{eqnarray*}
Dieses System von Gleichungen und Ungleichungen lässt sich nicht so einfach lösen wie im gleichungsbeschränkten Fall. Das Problem ist darin begründet, dass die Indexmenge $\A (\x)$ der aktiven Ungleichungsbeschränkungen unbekannt ist. Wäre sie bekannt, so könnten die inaktiven Ungleichungsbeschränkungen weggelassen werden, da sie keinen Einfluss auf das Optimum haben und man erhielte das äquivalente Problem
\begin{equation}
\label{eqn:3.12}
\begin{array}{rcl}
\dfrac{1}{2} x^T W x + c^T x & = & \min ! \\
g_i (x) = a_i^T x - u_i & = & 0,\quad i \in \A (\x), \\
h_j (x) = b_j^T x - v_j & = & 0,\quad j \in \J
\end{array}
\end{equation}
Dieses ist ein quadratisches Optimierungsproblem mit Gleichungsbeschränkungen, dessen Lösung durch Satz \ref{theo:3.4.2} charakterisiert ist.

Die Idee der \emph{Strategie der aktiven Mengen} zur Lösung des allgemeinen quadratischen Optimierungsproblems besteht nun darin, die unbekannte Indexmenge $\A (\x)$ in (\ref{eqn:3.12}) durch eine Schätzung $\A_s \subseteq \I$ zu ersetzen und diese iterativ anzupassen.

Sei $x^{[\idy]}$ der aktuelle Iterationspunkt, $x^{[\idy]}$ sei zulässig und $\A_s^\idy \subseteq \I$ sei die aktuelle Schätzung der aktiven Menge. Löse dann das Hilfsproblem
\begin{problem}
\label{prob:3.4.4}\emph{(Hilfsproblem)}
\begin{eqnarray*}
f (x^{[\idy]} + d) & = & \min_{d \in \R^n} ! \\
a_i^T d & = & 0,\quad i \in \A_s^\idy \\
b_j^T d & = & 0,\quad j \in \J.
\end{eqnarray*}
\qed
\end{problem}

Die Strategie zur Anpassung der Indexmenge $\A_s^\idy$ hängt nun ab von der Lösung $d$ und den zugehörigen Lagrange-Multiplikatoren $\mu_i$, $i \in \A_s^\idy$, und $\nu_j$, $j \in \J$, des Hilfsproblems. Folgende Fälle können eintreten:
\begin{enumerate}[label=(\alph*)]
\item Besitzt das Hilfsproblem die Lösung $d=\Theta$, so liefern die KKT-Bedingungen für das Hilfssproblem
$$\nabla f (x^{[\idy]}) + \sum_{i \in \A_s^\idy} \mu_i \cdot a_i + \sum_{j \in \J} \nu_j \cdot b_j = 0.$$
\begin{enumerate}[label=(\roman*)]
\item Sind alle $\mu_i \geq 0$, $i \in \A_s^k$, so wird $x^{[\idy]}$ als Lösung akzeptiert, da die KKT-Bedingungen für das Ausgangsproblem erfüllt sind, wenn man noch $\mu_i = 0$, $i \in \I \setminus \A_s^k$ setzt.
\item \emph{Deaktivierungsschritt:} \\
Gibt es einen Index $i \in \A_s^\idy$ mit $\mu_i < 0$, so erfüllt $x^{[\idy]}$ die KKT-Bedingungen des Ausgangsproblems nicht, ist also nicht optimal. Andererseits ist $x^{[\idy]}$ Minimum von $f$ unter den Nebenbedingungen $\A_s^\idy \cup \J$ . Daher muss der zulässige Bereich vergrößert werden, d.h. die Indexmenge $\A_s^\idy$ wird verkleinert. Bestimme dazu denjenigen Index $q \in \A_s^\idy$ mit
$$\mu_q = \min_{i \in \A_s^\idy} \mu_i < 0$$
und setze
$$\A_s^{\idy+1} := \A_s^\idy \setminus \{ q \}.$$
\end{enumerate}
\item Besitzt das Hilfsproblem eine Lösung $d \not= \Theta$, so ist $d$ eine Abstiegsrichtung von $f$ im Punkt $x^{[\idy]}$, die die Nebenbedingungen $\A_s^\idy \cup \J$ erfüllt, d.h. es gilt
\begin{equation}
\label{eqn:3.13}
a_i^T d = 0,\; i \in \A_s^\idy,\quad b_j^T d = 0,\; j \in \J.
\end{equation}
\begin{enumerate}[label=(\roman*)]
\item Ist $x^{[\idy]} + d$ zulässig für das Ausgangsproblem, d.h. gilt
$$a_i^T (x^{[\idy]} + d) \leq u_i,\quad i \in \I \setminus \A_s^\idy,$$
so setze
$$x^{[\idy+1]} := x^{[\idy]} + d,\quad \A_s^{\idy+1} := \A_s^\idy.$$
\item \emph{Aktivierungsschritt:} \\
Ist $x^{[\idy]} + d$ unzulässig für das Ausgangsproblem, so bestimme eine möglichst große Schrittweite $\alpha_\idy \geq 0$, so dass $x^{[\idy]} + \alpha_\idy \cdot d$ zulässig bleibt:
$$a_i^T (x^{[\idy]} + \alpha_\idy \cdot d) \leq u_i \quad \forall i \in \I \setminus \A_s^\idy$$
bzw.
\begin{equation}
\label{eqn:3.14}
\alpha_\idy \cdot a_i^T d \leq u_i - a_i^T x^{[\idy]} \quad \forall i \in \I \setminus \A_s^\idy
\end{equation}
Beachte, dass $x^{[\idy]} + \alpha \cdot d$ für alle $\alpha$ zulässig bleibt für die Nebenbedingungen $\A_s^\idy \cup \J$, da $x^{[\idy]}$ zulässig ist und (\ref{eqn:3.13}) gilt.\\
Da $x^{[\idy]}$ zulässig ist und $x^{[\idy]} + \alpha \cdot d$ mit $\alpha = 1$ unzulässig ist, muß es in (\ref{eqn:3.14}) einen Index $i \in \I \setminus \A_s^\idy$ mit $a_i^T d > 0$ geben. Bestimme also
$$
\alpha_\idy := \min \left\{ \dfrac{u_i - a_i^T x^{[\idy]}}{a_i^T d} \;|\; i \in \I \setminus \A_s^\idy,\; a_i^T d > 0 \right\}.
$$
Sei $r \in \I \setminus \A_s^\idy$ ein (nicht notwendig eindeutiger) Index, für den dieses Minimum angenommen wird. Der Fall $\alpha = 0$ kann auftreten, wenn mehrere Nebenbedingungen gleichzeitig aktiv werden (Entartung). \\
Setze
$$x^{[\idy+1]} := x^{[\idy]} + \alpha \cdot d,\quad \A_s^{\idy+1} := \A_s^\idy \cup \{ r \}.$$
\end{enumerate}
\end{enumerate}

Zusammenfassend erhalten wir den folgenden Algorithmus.

\begin{algorithm}\label{algo:3.4.5}\emph{(Strategie der aktiven Menge)}
\begin{enumerate}[label=(\roman*)]
\item Sei $x^{[0]}$ zulässig für das quadratische Optimierungsproblem. Setze $\idy := 0$ und 
$$\A_s^0 := \left\{ i \in \I \;:\; a_i^T x^{[0]} = u_i \right\}.$$
\item \label{algo:3.4.5:ii} Bestimme eine Lösung $(d, \mu_{\A_s^\idy}, \nu)$ des Hilfsproblems durch Lösen des Gleichungssystems
$$
\begin{pmatrix}
W & A_{\A_s^\idy}^T & B^T \\
A_{\A_s^\idy} & 0 & 0 \\
B & 0 & 0
\end{pmatrix}
\begin{pmatrix}
d \\ \mu_{\A_s^\idy} \\ \nu
\end{pmatrix}
=
\begin{pmatrix}
-\nabla f (x^{[\idy]}) \\ 0 \\ 0
\end{pmatrix}
$$
(vgl. (\ref{eqn:3.11})). Hierin sind
$$A_{\A_s^\idy} := (a_i^T)_{i \in \A_s^\idy},\quad \mu_{\A_s^\idy} := (\mu_i)_{i \in \A_s^\idy}.$$
\item Ist $d=\Theta$ und $\mu_{\A_s^\idy} \geq 0$, so setze $\mu_i=0$ für $i \in \I \setminus \A_s^\idy$ und {\tt{STOP}}.
\item Ist $d=\Theta$ und $\mu_q := \min \left\{ \mu_i \;:\; i \in \A_s^\idy \right\} < 0$, so setze
$$\A_s^{\idy+1} := \A_s^\idy \setminus \{ q \}.$$
Setze $\idy := \idy+1$ und gehe zu \ref{algo:3.4.5:ii}.
\item Gilt $a_i^T (x^{[\idy]} + d) \leq u_i$, $i \in \I \setminus \A_s^\idy$, so setze
$$x^{[\idy+1]} := x^{[\idy]} + d,\quad \A_s^{\idy+1} := \A_s^\idy.$$
Setze $\idy := \idy+1$ und gehe zu \ref{algo:3.4.5:ii}.
\item Bestimme $r \in \I \setminus \A_s^\idy$ mit
$$
\alpha_\idy := \dfrac{u_r - a_r^T x^{[\idy]}}{a_r^T d} = \min_{\substack{i \in \I \setminus \A_s^\idy \\ a_i^T d > 0}} \left\{ \dfrac{u_i - a_i^T x^{[\idy]}}{a_i^T d} \right\}
$$
und setze
$$x^{[\idy+1]} := x^{[\idy]} + \alpha_\idy \cdot d,\quad \A_s^{\idy+1} := \A_s^\idy \cup \{ r \}.$$
Setze $\idy := \idy+1$ und gehe zu \ref{algo:3.4.5:ii}.
\end{enumerate}
\qed
\end{algorithm}

\subsection{Aktive-Mengen-Strategie (2)}

\paragraph{Herleitung des Verfahrens}

Wir führen aktive und inaktive Mengen ein. Diese Unterscheidung betrifft die Frage, ob eine Ungleichungs\-nebenbedingung in einem Punkt mit Gleichheit erfüllt wird. Für die Optimallösung $\bar{u}$ von (ROS) ohne gemischte Beschränkung definieren wir
\begin{eqnarray*}
\Omega_+ & = & \left\{ x \in \Omega \;:\; \bar{u} (x) = u_b(x) \right\}, \\
\Omega_- & = & \left\{ x \in \Omega \;:\; \bar{u} (x) = u_a(x) \right\}, \text{ und} \\
\Omega_B & = & \left\{ x \in \Omega \;:\; u_a(x) < \bar{u}(x) < u_b(x) \right\}.
\end{eqnarray*}
Diese und weitere Definitionen sind immer nur bis auf Mengen vom Maß Null eindeutig und auch in diesem Sinne zu verstehen.

Wir gehen bei der Strategie des Algorithmus von Iterierten $(u^{[\idy-1]}, \lambda^{[\idy-1]})$ aus und werten den Ausdruck $u^{[\idy-1]} + \lambda^{[\idy-1]}$ aus. Ist dieser für einen Punkt positiv, so nehmen wir diesen in $\Omega_+^{[\idy]}$ auf. Ist er negativ, so nehmen wir den Punkt in $\Omega_-^{[\idy]}$ auf. Dementsprechend setzen wir die neuen aktiven Mengen gemäß
\begin{eqnarray*}
\Omega_+^{[\idy]} & = & \left\{ x \in \Omega \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) > u_b (x) \right\}, \\
\Omega_-^{[\idy]} & = & \left\{ x \in \Omega \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) < u_a (x) \right\}, 
\end{eqnarray*}
fest. Die übrigen Punkte ergeben
$$\Omega_B^{[\idy]} = \Omega \setminus \left( \Omega_-^{[\idy]} \cup \Omega_+^{[\idy]} \right).$$
Wir erinnern, daß $\bar{\lambda} \geq 0$ auf $\Omega_-$ , $\bar{\lambda} \leq 0$ auf $\Omega_+$ und $\bar{\lambda} = 0$ auf $\Omega_B$ gilt. Die Änderungen der aktiven Mengen stellen die Schlüsselstelle des Algorithmus dar.

Zur Formulierung des konkreten Algorithmus wollen wir diese Ausdrücke noch etwas genauer analysieren. An erster Stelle steht dabei die Feststellung, dass die Iterierten $(u^{[\idy-1]}, \lambda^{[\idy-1]})$ die komplementäre Schlupfbedingung erfüllen.

Die aktiven und inaktiven Mengen stellen eine disjunkte Zerlegung des Gebietes $\Omega$ dar 
$$
\Omega = \Omega_+^{[\idy]} \; \dot\cup \; \Omega_B^{[\idy]} \; \dot\cup \; \Omega_-^{[\idy]} \quad\forall k.
$$
Die Berechnung der Ausdrücke $(u^{[\idy-1]} + \lambda^{[\idy-1]})$ über das Optimalitätssystem beinhaltet insbesondere die Forderungen
\begin{eqnarray*}
x \in \Omega_-^{[\idy-1]} & \Rightarrow & u^{[\idy-1]} (x) = u_a (x), \\
x \in \Omega_B^{[\idy-1]} & \Rightarrow & \lambda^{[\idy-1]} (x) = 0, \\
x \in \Omega_+^{[\idy-1]} & \Rightarrow & u^{[\idy-1]} (x) = u_b (x).
\end{eqnarray*}
Betrachten wir die Bestimmung der aktiven Mengen unter diesen Gesichtspunkten
\begin{eqnarray*}
\Omega_+^{[\idy]} & = & \left\{ x \in \Omega \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) > u_b (x) \right\} \\ \\
& = & \left\{ x \in \Omega_+^{[\idy-1]} \; \dot\cup \; \Omega_B^{[\idy-1]} \; \dot\cup \; \Omega_-^{[\idy-1]} \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) > u_b (x) \right\} \\ \\
& = & \left\{ x \in \Omega_+^{[\idy-1]} \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) > u_b (x) \right\} \\
& \cup & \left\{ x \in \Omega_B^{[\idy-1]} \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) > u_b (x) \right\} \\
& \cup & \left\{ x \in \Omega_-^{[\idy-1]} \;:\; \left( u^{[\idy-1]} + \lambda^{[\idy-1]} \right) (x) > u_b (x) \right\}. 
\end{eqnarray*}
Unter der Annahme, daß von $\Omega_-^{[\idy-1]}$ keine Zugänge für $\Omega_+^{[\idy]}$ zu erwarten sind, ergibt sich
\begin{eqnarray*}
\Omega_+^{[\idy]} & = & \left\{ x \in \Omega_+^{[\idy-1]} \;:\; \lambda^{[\idy-1]}(x) > 0 \right\} \cup \left\{ x \in \Omega_B^{[\idy-1]} \;:\; u^{[\idy-1]} (x) > u_b (x) \right\} \\
& = & \left( \Omega_+^{[\idy-1]} \setminus \left\{ x \in \Omega_+^{[\idy-1]} \;:\; \lambda^{[\idy-1]} (x) \leq 0 \right\} \right) \cup \left\{ x \in \Omega_B^{[\idy-1]} \;:\; u^{[\idy-1]} (x) > u_b (x) \right\}. 
\end{eqnarray*}
Analog gilt:
\begin{eqnarray*}
\Omega_-^{[\idy]} & = & \Omega_-^{[\idy-1]} \setminus \left\{ x \in \Omega_-^{[\idy-1]} \;:\; \lambda^{[\idy-1]} (x) \geq 0 \right\} \cup \left\{ x \in \Omega_B^{[\idy-1]} \;:\; u^{[\idy-1]} (x) < u_a (x) \right\}
\end{eqnarray*}
und damit
\begin{eqnarray*}
\Omega_B^{[\idy]} & = & \Omega \setminus \left( \Omega_+^{[\idy]} \cup \Omega_-^{[\idy]} \right) \\
& = & \Omega \setminus \left( \Omega_+^{[\idy-1]} \cup \Omega_-^{[\idy-1]} \right) \\
&& \setminus \left( \left\{ x \in \Omega_B^{[\idy-1]} \;:\; u^{[\idy-1]} (x) > u_b (x) \right\} \cup \left\{ x \in \Omega_B^{[\idy-1]} \;:\; u^{[\idy-1]} (x) < u_a (x) \right\} \right) \\
&& \cup \left( \left\{ x \in \Omega_+^{[\idy-1]} \;:\; \lambda^{[\idy-1]} (x) \leq 0 \right\} \cup \left\{ x \in \Omega_-^{[\idy-1]} \;:\; \lambda^{[\idy-1]} (x) \geq 0 \right\} \right).
\end{eqnarray*}
Wir bemerken, dass zur Neubestimmung der aktiven und inaktiven Mengen nicht mehr der Ausdruck $(u^{[\idy-1]} + \lambda^{[\idy-1]})$, sondern nur noch $u^{[\idy-1]}$ und $\lambda^{[\idy-1]}$ getrennt ausgewertet werden müssen. Dieses Update-Schema können wir aber auch für die gemischte Beschränkung nutzen.

Dazu sei $\Omega_A$ die Menge der Punkte aus $\Omega$, in denen die gemischte Nebenbedingung aktiv ist und $\Omega_M$ der Rest.
$$\Omega_A^{[\idy]} = \Omega_A^{[\idy-1]} \setminus \left\{ x \in \Omega_A^{[\idy-1]} \;:\; \mu^{[\idy-1]} (x) \leq 0 \right\} \cup \left\{ x \in \Omega_M^{[\idy-1]} \;:\; \left( K u^{[\idy-1]} - c \right) (x) > 0 \right\}$$
und
$$\Omega_M^{[\idy]} = \Omega_M^{[\idy-1]} \setminus \left\{ x \in \Omega_M^{[\idy-1]} \;:\; \left( K u^{[\idy-1]} - c \right) (x) > 0 \right\} \cup \left\{ x \in \Omega_A^{[\idy-1]} : \mu^{[\idy-1]} (x) \leq 0 \right\}$$
Um diese aktiven und inaktiven Mengen anwendbar zu machen, definieren wir über die zugehörigen charakteristischen Funktionen $\chi_-$, $\chi_B$, $\chi_+$ und $\chi_M$, $\chi_A$ die Operatoren
$$X_* : v \to \chi_* \cdot v$$ 
Mit diesen haben die folgenden Ausdrücke den Wert Null:
$$
X_B \lambda (x) = \chi_B (x) \cdot \lambda (x) =
\begin{cases}
0 \;:\; x \notin \Omega_B \Longleftrightarrow \chi_B (x) = 0 \\
0 \;:\; x \in \Omega_B \Longleftrightarrow \lambda (x) = 0
\end{cases}
$$
\begin{eqnarray*}
X_- (u - u_a) (x) = \chi_- (x) \cdot (u - u_a) (x) & = & 
\begin{cases}
0 \;:\; x \notin \Omega_- \Longleftrightarrow \chi_- (x) = 0 \\
0 \;:\; x \in \Omega_- \Longleftrightarrow (u-u_a) (x) = 0
\end{cases} \\
X_+ (u - u_b) (x) = \chi_+ (x) \cdot (u - u_b)(x) & = &
\begin{cases}
0 \;:\; x \notin \Omega_+ \Longleftrightarrow \chi_+ (x) = 0 \\
0 \;:\; x \in \Omega_+ \Longleftrightarrow (u-u_b) (x) = 0
\end{cases}
\end{eqnarray*}
und
\begin{eqnarray*}
X_M \mu (x) = \chi_M (x) \cdot \mu (x) & = &
\begin{cases}
0 \;:\; x \notin \Omega_M \Longleftrightarrow \chi_M (x) = 0 \\
0 \;:\; x \in \Omega_M \Longleftrightarrow \mu (x) = 0
\end{cases} \\
X_A (K u - c) (x) = \chi_A (x) \cdot (K u - c) (x) & = &
\begin{cases}
0 \;:\; x \notin \Omega_A \Longleftrightarrow \chi_A (x) = 0 \\
0 \;:\; x \in \Omega_A \Longleftrightarrow (Ku-c)(x) = 0
\end{cases}
\end{eqnarray*}
Damit formen wir jetzt das System (ROS) in ein Gleichungssystem um
\begin{eqnarray*}
\Theta & = & Q u + K^* X_A \mu + (X_- + X_+) \lambda + q, \\
\Theta & = & X_A (Ku-c) + X_M \mu, \\
\Theta & = & X_- (u-u_a) + X_+ (u-u_b) + X_B \lambda,
\end{eqnarray*}
in anderer Form
$$
\underbrace{
\begin{pmatrix}
Q & K^*X_A & X_- + X_+ \\
X_A K & X_M & 0 \\
X_- + X_+ & 0 & X_B 
\end{pmatrix} 
}_B
\underbrace{
\begin{pmatrix}
u \\ \mu \\ \lambda 
\end{pmatrix} 
}_x
+
\underbrace{
\begin{pmatrix}
q \\ -X_A c \\ -(X_- u_a + X_+ u_b)
\end{pmatrix} 
}_b
= \Theta.
$$
\paragraph{Aktive-Mengen-Methode}
\begin{enumerate}[label=\arabic*.]
\item Wähle als Startwerte $u^{[0]} = \mu^{[0]} = \lambda^{[0]} = \Theta$, und für die Zerlegungsmengen
\begin{eqnarray*}
\Omega_B^{[0]} = \Omega_M^{[0]} = \Omega, \quad \Omega_-^{[0]} = \Omega_+^{[0]} = \Omega_A^{[0]} = \Theta, \\
\Omega_B^{[-1]} = \Omega_M^{[-1]} = \Theta, \quad \Omega_-^{[-1]} = \Omega_+^{[-1]} = \Omega_A^{[-1]} = \Omega,
\end{eqnarray*}
und setze $\idy = 0$.
\item Wenn $\Omega_B^{[\idy-1]} = \Omega_B^{[\idy]}$ und $\Omega_M^{[\idy-1]} = \Omega_M^{[\idy]}$ : {\tt{STOP}}.
\item 
\begin{itemize}
\item Bestimme die Einträge in $B^{[\idy]}$ und $b^{[\idy]}$. 
\item Bestimme Lösung $(u^{[\idy+1]}, \mu^{[\idy+1]}, \lambda^{[\idy+1]})$ von $B^{[\idy]} (u, \mu, \lambda) + b^{[\idy]} = \Theta$. 
\item Berechne das Zerlegungs-Update für die Boxbeschränkung(en)
\begin{eqnarray*}
d_- & = & \left\{ x \in \Omega_B^{[\idy]} \;:\; u^{[\idy+1]} (x) \leq u_a (x) \right\}, \\
d_B^- & = & \left\{ x \in \Omega_-^{[\idy]} \;:\; \lambda^{[\idy+1]} (x) \geq 0 \right\}, \\
d_B^+ & = & \left\{ x \in \Omega_+^{[\idy]} \;:\; \lambda^{[\idy+1]} (x) \leq 0 \right\}, \\
d_+ & = & \left\{ x \in \Omega_B^{[\idy]} \;:\; u^{[\idy+1]} (x) \geq u_b (x) \right\}, \\
\\
\Omega_-^{[\idy+1]} & = & \Omega_-^{[\idy]} \setminus d_B^- \cup d_- , \\
\Omega_B^{[\idy+1]} & = & \Omega_B^{[\idy]} \setminus (d_- \cup d_+) \cup (d_B^- \cup d_B^+), \\
\Omega_+^{[\idy+1]} & = & \Omega_+^{[\idy]} \setminus d_B^+ \cup d_+ , 
\end{eqnarray*}
und für die Mixbeschränkung(en)
\begin{eqnarray*}
d_I & = & \left\{ x \in \Omega_A^{[\idy]} \;:\; \mu^{[\idy+1]} (x) \leq 0 \right\},\\
d_A & = & \left\{ x \in \Omega_M^{[\idy]} \;:\; \left( K u^{[\idy+1]} - c \right) (x) \geq 0 \right\}, \\
\\
\Omega_M^{[\idy+1]} & = & \Omega_M^{[\idy]} \setminus d_A \cup d_I, \\
\Omega_A^{[\idy+1]} & = & \Omega_A^{[\idy]} \setminus d_I \cup d_A.
\end{eqnarray*}
\end{itemize}
\item Setze $k = k+1$ und gehe zu Schritt 2. \qed
\end{enumerate}

\subsection{Active-Set-Methoden (3)}

Active-Set-Methoden sind eine Klasse iterativer Algorithmen zur Lösung von quadratischen Optimierungsproblemen.\footnote{https://de.wikipedia.org/wiki/Active-Set-Methoden}

\subsubsection{Mathematische Problemstellung}

Jedes quadratische Programm kann in eine standardisierte Form überführt werden:
$$
\begin{array}{rcl}
\min_{x \in \R^n} & \dfrac{1}{2} x^T H x + c^T x & = f (x) \\
\text{s.t.} & a_i^T x \geq u_i & \forall i \in \I \\
& b_j^T x = v_j & \forall j \in \J
\end{array}
$$
wobei $n$ die Anzahl der Entscheidungsvariablen ist. In der Ziel(=Kosten-)funktion $f(x)$ entspricht $H$ der Hesse-Matrix, die Mengen $\I$ und $\J$ indizieren die Ungleichheits- und Gleichheitsbedingungen. Oft wird dabei gefordert, dass die Matrix $H$ positiv semidefinit ist, da dann das Optimierungsproblem konvex ist.

\paragraph{Active Set}

Eine Nebenbedingung $i \in \I$ ist \emph{aktiv} an einem Punkt $x$, wenn $a_i^T x = u_i$ gilt.

Das Active Set $\A (x)$ ist die Menge aller aktiven Bedingungen an einem gültigen Punkt $x$:
$$
\A (x) := \left\{ i \in \I \;:\; a_i^T x = u_i \right\} \cup \{ j \in \J \}
$$

\subsubsection{Algorithmus}

Active-Set-Methoden setzen eine initiale gültige Lösung $x^{[0]}$ voraus. Die Algorithmen berechnen dann in jeder Iteration einen gültigen Punkt $x^{[\idy]}$, bis ein Optimum erreicht ist. Dabei wird eine Menge $\A_\idy$ verwaltet, die angibt, welche Nebenbedingungen in der aktuellen Iteration aktiv sein sollen.

\begin{enumerate}[label={\tt{\arabic*}}]
\item {\tt{INPUT}}: gültiger Punkt $x^{[0]}$, $\A_0 \subseteq \A (x^{[0]})$
\item {\tt{for}} ($\idy = 0, 1, \ldots$)
\item \quad \underline{Berechne} eine Suchrichtung $d^{[\idy]}$
\item \quad {\tt{if}} ($d^{[\idy]} == 0$)
\item \quad \quad \underline{Berechne} Lagrange-Multiplikatoren $\mu_i$
\item \quad \quad {\tt{if}} ($\forall i \;:\; \mu_i \geq 0$)
\item \quad \quad \quad {\tt{STOP}} und {\tt{OUTPUT:}} $x^{[\idy]}$
\item \quad \quad {\tt{else}}
\item \quad \quad \quad \underline{Finde} Ungleichheitsbedingung $i \in \A_\idy \cap \I$ mit $\mu_i < 0$
\item \quad \quad \quad \quad $\A_{\idy+1} = \A_\idy \setminus \{i\}$
\item \quad \quad {\tt{endif}}
\item \quad {\tt{else}} $(d^{[\idy]} \not= 0)$
\item \quad \quad \underline{Berechne} Schrittlänge $\alpha_\idy$
\item \quad \quad {\tt{if}} ($\alpha_\idy < 1$)
\item \quad \quad \quad \underline{Finde} Nebenbedingung $i$ die $\alpha_\idy$ beschränkt
\item \quad \quad \quad \quad $\A_{\idy+1} = \A_\idy \cup \{i\}$
\item \quad \quad {\tt{endif}}
\item \quad \quad $x^{[\idy+1]} = x^{[\idy]} + \alpha_\idy \cdot d^{[\idy]}$
\item \quad {\tt{endif}}
\item {\tt{endfor}}
\end{enumerate}

\paragraph{Berechnung der Suchrichtung $d^{[\idy]}$}

Die Nebenbedingungen in $\A_\idy$ definieren einen Unterraum. Wenn $\x$ in der optimalen Lösung der Zielfunktion in diesem Unterraum ist, kann man die Suchrichtung als $d^{[\idy]} = \x - x^{[\idy]}$ definieren. Substituiert man dies in die Zielfunktion, erhält man die Suchrichtung $d^{[\idy]}$ durch Lösen eines quadratischen Subproblems:
$$
\begin{array}{rcl}
\min_{x \in \R^n} & \dfrac{1}{2} (d^{[\idy]})^T H d^{[\idy]} + g_\idy^T d_\idy \\
\text{s.t.} & A^T d^{[\idy]} = 0 & \forall i \in \A_\idy
\end{array}
$$
wobei $g_\idy = H x^{[\idy]} + c$ der Gradient an der aktuellen Lösung ist und die Spalten der Matrix $A$ die Vektoren $a_i,\; i \in \A_\idy$ sind.

\paragraph{Berechnung der Lagrange-Multiplikatoren $\mu_i$}
Falls die Suchrichtung $d^{[\idy]}=0$ ist, ist $x^{[\idy]}$ bereits optimal im aktuellen Unterraum. Man muss dann eine geeignete Ungleichheitsbedingung aus $\A_\idy$ entfernen. Die Lagrange-Multiplikatoren $\mu_i$ erhält man durch Lösen eines linearen Gleichungssystems:
$$\sum _{i \in \A_\idy \cap \I} a_i \mu_i = g^{[\idy]} = H x^{[\idy]} + c$$
Falls alle $\mu_i \geq 0$ sind, erfüllen $x^{[\idy]}$ und $\mu$ die \textsc{Karush-Kuhn-Tucker}-Bedingungen, welche notwendige Kriterien für die Optimalität sind. Wenn zudem die Hesse-Matrix $H$ positiv semi-definit ist, sind diese Bedingungen hinreichend und $x^{[\idy]}$ ist die optimale Lösung des Problems. Entfernt man eine Ungleichheitsbedingung mit negativem Lagrange-Multiplikator aus $\A_\idy$ erhält man in der nächsten Iteration eine Suchrichtung.

\paragraph{Berechnung der Schrittlänge $\alpha_\idy$}

Hat man eine Suchrichtung $d^{[\idy]}$, muss man die maximale Schrittlänge $\alpha_\idy$ berechnen. Eine volle Schrittlänge mit $\alpha_\idy=1$ führt direkt zum Minimum im durch $\A_\idy$ definierten Unterraum. Die Schrittlänge ist jedoch häufig durch eine Nebenbedingung $i \notin \A_\idy$ beschränkt.

Alle Nebenbedingungen in $i \notin \A_\idy$ mit $a_i^T d^{[\idy]} \geq 0$ sind auch am Punkt $x^{[\idy]} + \alpha_\idy \cdot d^{[\idy]}$ für alle $\alpha_\idy \geq 0$ erfüllt, da dann die Ungleichung 
$$a_i^T (x^{[\idy]} + \alpha_\idy \cdot d^{[\idy]}) = a_i^T x^{[\idy]} + \alpha_\idy \cdot a_i^T d^{[\idy]} \geq a_i^T x^{[\idy]} \geq u_i$$ 
gilt. Alle Nebenbedingungen $i \notin \A_\idy$ mit $a_i^T d^{[\idy]} < 0$ werden am neuen Punkt nur dann eingehalten, wenn für diese Nebenbedingungen die Ungleichung 
$$a_i^T x^{[\idy]} + \alpha_\idy \cdot a_i^T d^{[\idy]} \geq u_i$$
gilt. Dies ist äquivalent mit der Bedingung 
$$
\alpha_\idy \leq {\dfrac {u_i - a_i^T x^{[\idy]}}{a_i^T d^{[\idy]}}} \quad \forall i \notin \A_\idy \;
:\; a_i^T d^{[\idy]} < 0
$$
Um so nah wie möglich an das Optimum im aktuellen Unterraum zu kommen, kann man die maximale Schrittlänge durch diese Formel berechnen:
$$
\alpha_\idy = \min \left\{ 1, \min_{i \notin \A_\idy,\; a_i^T d^{[\idy]} < 0}{\dfrac {u_i - a_i^T x^{[\idy]}}{a_i^T d^{[\idy]}}} \right\}
$$
Die Nebenbedingung, die diese Länge beschränkt, wird in die Menge $\A_{\idy+1}$ aufgenommen, da diese Nebenbedingung nun aktiv ist.

\subsection{Verfahren der konjugierten Gradienten}

Das CG-Verfahren (von engl. conjugate gradients) ist eine effiziente numerische Methode zur Lösung von großen linearen Gleichungssystemen der Form $Ax=b$ mit symmetrischer, positiv-definiter Systemmatrix $A$.

Das Verfahren liefert, in exakter Arithmetik, nach spätestens $m$ Schritten die exakte Lösung, wobei $m$ die Größe der quadratischen Matrix $A \in \R^{m \times m}$ ist. Insbesondere ist es aber als iteratives Verfahren interessant, da der Fehler monoton fällt. Das CG-Verfahren kann in die Klasse der Krylow-Unterraum-Verfahren eingeordnet werden.

\begin{algorithm}\label{algo:cg}\emph{(CG-Verfahren)} zur Berechnung einer Lösung von $Ax = b$
\begin{enumerate}[label=(\roman*)]
\item Wähle Startwert $x^{[0]}$, berechne $r^{[0]} = b - A x^{[0]}$, setze $d^{[0]} = r^{[0]}$, $\idz := 0$.
\item \label{algo:cg:ii}Ist $r^{[\idz]} = 0$ (bzw. $\| r^{[\idz]} \|_A < \text{tol}$): {\tt{STOP}}. 
\item Berechne
\begin{itemize}
\item temp. Zwischenwert
\begin{eqnarray*}
z^{[\idz]} & = & A d^{[\idz]},
\end{eqnarray*}
\item Finde von $x^{[\idz]}$ in Richtung $d^{[\idz]}$ den Ort $x^{[\idz+1]}$ des Minimums der Funktion $E(x) := \tfrac{1}{2} \langle A x, x \rangle - \langle b, x \rangle$ und aktualisiere den Gradienten bzw. das Residuum
\begin{eqnarray*}
\alpha_\idz & = & \dfrac{(r^{[\idz]})^T r^{[\idz]}}{(d^{[\idz]})^T z^{[\idz]}}, \\
x^{[\idz+1]} & = & x^{[\idz]} + \alpha_\idz \cdot d^{[\idz]}, \\
r^{[\idz+1]} & = & r^{[\idz]} - \alpha_\idz \cdot z^{[\idz]}, \quad \left( = b - A x^{[\idz+1]} \right)
\end{eqnarray*}
\item Korrigiere die Suchrichtung $d^{[\idz+1]}$ mit Hilfe von $d^{[\idz]}$ und $r^{[\idz+1]}$: 
\begin{eqnarray*}
\beta_\idz & = & \dfrac{(r^{[\idz+1]})^T r^{[\idz+1]}}{(r^{[\idz]})^T r^{[\idz]}} \quad (\textsc{Fletcher-Reeves}), \\
\beta_\idz & = & \dfrac{(r^{[\idz+1]})^T (r^{[\idz+1]} - r^{[\idz]})}{(r^{\idz})^T r^{[\idz]}} \quad (\text{alternative \sc{Polak-Ribière}}), \\
\beta_\idz & = & \dfrac{(r^{[\idz+1]})^T (r^{[\idz+1]} - r^{[\idz]})}{(d^{[\idz]})^T (r^{[\idz+1]} - r^{[\idz]})} \quad (\text{alternative \sc{Hestenes-Stiefel}}), \\ \\
d^{[\idz+1]} & = & r^{[\idz+1]} + \beta_\idz \cdot d^{[\idz]},
\end{eqnarray*}
\end{itemize}
\item Setze $\idz:=\idz+1$ und gehe zu \ref{algo:cg:ii}
\end{enumerate}\qed
\end{algorithm}

\subsection{Methode der kleinsten Quadrate}

Die Methode der kleinsten Quadrate (kurz: MKQ) oder KQ-Methode (englisch: method of least squares oder lediglich least squares, kurz: LS); zur Abgrenzung von daraus abgeleiteten Erweiterungen wie z. B. der \emph{verallgemeinerten Methode der kleinsten Quadrate} oder der \emph{zweistufigen Methode der kleinsten Quadrate} auch mit dem Zusatz 'gewöhnliche' bezeichnet, d. h. gewöhnliche Methode der kleinsten Quadrate (englisch: ordinary least squares, kurz: OLS; veraltet Methode der kleinsten Abweichungsquadratsumme) ist das mathematische Standardverfahren zur Ausgleichungsrechnung.

Dabei wird zu einer Menge von Datenpunkten eine Funktion bestimmt, die möglichst nahe an den Datenpunkten verläuft und somit die Daten bestmöglich zusammenfasst. Die am häufigsten verwendete Funktion ist die Gerade, die dann Ausgleichsgerade genannt wird. Um die Methode anwenden zu können, muss die Funktion mindestens einen Parameter enthalten. Diese Parameter werden dann durch die Methode bestimmt, so dass, wenn die Funktion mit den Datenpunkten verglichen und der Abstand zwischen Funktionswert und Datenpunkt quadriert wird, die Summe dieser quadrierten Abstände möglichst gering wird. Die Abstände werden dann Residuen genannt.

Typischerweise werden mit dieser Methode reale Daten, etwa physikalische oder wirtschaftliche Messwerte, untersucht. Diese Daten beinhalten oft unvermeidbare Messfehler und Schwankungen. Unter der Annahme, dass die gemessenen Werte nahe an den zugrunde liegenden „wahren Werten“ liegen und zwischen den Messwerten ein bestimmter Zusammenhang besteht, kann die Methode verwendet werden, um eine Funktion zu finden, die diesen Zusammenhang der Daten möglichst gut beschreibt. Die Methode kann auch umgekehrt verwendet werden, um verschiedene Funktionen zu testen und dadurch einen unbekannten Zusammenhang in den Daten zu beschreiben.

Messpunkte und deren Abstand von einer nach der Methode der kleinsten Quadrate bestimmten Funktion. Hier wurde eine logistische Funktion als Modellkurve gewählt.

In der Stochastik wird die Methode der kleinsten Quadrate meistens als regressionsanalytische Schätzmethode benutzt, wo sie auch als Kleinste-Quadrate-Schätzung bzw. gewöhnliche Kleinste-Quadrate-Schätzung bezeichnet wird. Da die Kleinste-Quadrate-Schätzung die Residuenquadratsumme minimiert, ist es dasjenige Schätzverfahren, welches das Bestimmtheitsmaß maximiert. Angewandt als Systemidentifikation ist die Methode der kleinsten Quadrate in Verbindung mit Modellversuchen z. B. für Ingenieure ein Ausweg aus der paradoxen Situation, Modellparameter für unbekannte Gesetzmäßigkeiten zu bestimmen.

\subsubsection{Das Verfahren}

\paragraph{Voraussetzungen}

Man betrachtet eine abhängige Größe $y$, die von einer Variablen $x$ oder auch von mehreren Variablen beeinflusst wird. So hängt die Dehnung einer Feder nur von der aufgebrachten Kraft ab, die Profitabilität eines Unternehmens jedoch von mehreren Faktoren wie Umsatz, den verschiedenen Kosten oder dem Eigenkapital. Zur Vereinfachung der Notation wird im Folgenden die Darstellung auf eine Variable $x$ beschränkt. Der Zusammenhang zwischen $y$ und den Variablen wird über eine Modellfunktion $f$, beispielsweise eine Parabel oder eine Exponentialfunktion
$$y (x) = f (x; \alpha_1, \dotsc, \alpha_m),$$
die von $x$ sowie von $m$ Funktionsparametern $\alpha_j$ abhängt, modelliert. Diese Funktion entstammt entweder der Kenntnis des Anwenders oder einer mehr oder weniger aufwendigen Suche nach einem Modell, eventuell müssen dazu verschiedene Modellfunktionen angesetzt und die Ergebnisse verglichen werden. Ein einfacher Fall auf Basis bereits vorhandener Kenntnis ist beispielsweise die Feder, denn hier ist das Hookesche Gesetz und damit eine lineare Funktion mit der Federkonstanten als einzigem Parameter Modellvoraussetzung. In schwierigeren Fällen wie dem des Unternehmens muss der Wahl des Funktionstyps jedoch ein komplexer Modellierungsprozess vorausgehen.

Um Informationen über die Parameter und damit die konkrete Art des Zusammenhangs zu erhalten, werden zu jeweils $n$ gegebenen Werten $x_i$ der unabhängigen Variablen $x$ entsprechende Beobachtungswerte $y_i$ $(i=1, \dotsc, n)$ erhoben. Die Parameter $\alpha_j$ dienen zur Anpassung des gewählten Funktionstyps an diese beobachteten Werte $y_i$. Ziel ist es nun, die Parameter $\alpha_j$ so zu wählen, dass die Modellfunktion die Daten bestmöglich approximiert.

\textsc{Gauß} und \textsc{Legendre} hatten die Idee, Verteilungsannahmen über die Messfehler dieser Beobachtungswerte zu machen. Sie sollten im Durchschnitt Null sein, eine gleichbleibende Varianz haben und von jedem anderen Messfehler stochastisch unabhängig sein. Man verlangt damit, dass in den Messfehlern keinerlei systematische Information mehr steckt, sie also rein zufällig um Null schwanken. Außerdem sollten die Messfehler normalverteilt sein, was zum einen wahrscheinlichkeitstheoretische Vorteile hat und zum anderen garantiert, dass Ausreißer in $y$ so gut wie ausgeschlossen sind.

Um unter diesen Annahmen die Parameter $\alpha_j$ zu bestimmen, ist es im Allgemeinen notwendig, dass deutlich mehr Datenpunkte als Parameter vorliegen, es muss also $n>m$ gelten.

\paragraph{Minimierung der Summe der Fehlerquadrate}

Das Kriterium zur Bestimmung der Approximation sollte so gewählt werden, dass große Abweichungen der Modellfunktion von den Daten stärker gewichtet werden als kleine. Sofern keine Lösung ganz ohne Abweichungen möglich ist, dann ist der Kompromiss mit der insgesamt geringsten Abweichung das beste allgemein gültige Kriterium.

Dazu wird die Summe der Fehlerquadrate, die auch Fehlerquadratsumme (genauer: Residuenquadratsumme) heißt, als die Summe der quadrierten Differenzen zwischen den Werten der Modellkurve $f (x_i)$ und den Daten $y_i$ definiert.

In Formelschreibweise mit den Parametern $\vec\alpha = (\alpha_1, \dotsc, \alpha_m) \in \R^m$ und $$\vec{f} = (f (x_1, \vec{\alpha}), \dotsc, f (x_n, \vec{\alpha})) \in \R^n$$ ergibt sich
$$
\sum_{i=1}^n \left( f (x_i, \vec\alpha) - y_i \right)^2 = \| \vec{f} - \vec{y} \|_2^2.
$$
Es sollen dann diejenigen Parameter $\alpha_j$ ausgewählt werden, bei denen die Summe der quadrierten Anpassungsfehler minimal wird:
$$
\min_{\vec{\alpha}} \| \vec {f} - \vec{y} \|_2^2.
$$
Wie genau dieses Minimierungsproblem gelöst wird, hängt von der Art der Modellfunktion ab.

\paragraph{Zusammenhang mit dem zentralen Grenzwertsatz}

Selbst wenn die Fehlerterme nicht normalverteilt sind, folgt aus dem zentralen Grenzwertsatz oft, dass der Schätzer der bedingten Erwartung $f (x, \alpha) = \hat{E} [Y|x]$ approximativ normalverteilt ist, solange die Stichprobe hinreichend groß ist. Aus diesem Grund ist die Verteilung des Fehlerterms bei großen Stichprobenumfängen oft kein gravierendes Problem in der Regressionsanalyse. Speziell ist es häufig nicht wichtig, ob der Fehlerterm einer Normalverteilung folgt, es sei denn es liegen beispielsweise folgende Punkte vor:
\begin{itemize}
\item die Stichprobengröße ist klein
\item die Verteilung der Fehler ist eine Heavy-tailed-Verteilung, welche zur Erzeugung von Daten führt, welche weit weg von den anderen Daten liegen (Stichproben aus den Heavy tails werden dann oft als Ausreißer interpretiert)
\item Multimodale Fehlerverteilungen
\item große Schiefe der Fehlerverteilung
\end{itemize}

\subsubsection{Lineare Modellfunktion}

Lineare Modellfunktionen sind Linearkombinationen aus beliebigen, im Allgemeinen nicht-linearen Basisfunktionen. Für solche Modellfunktionen lässt sich das Minimierungsproblem auch analytisch über einen Extremwertansatz ohne iterative Annäherungsschritte lösen. Zunächst werden einige einfache Spezialfälle und Beispiele gezeigt.

\paragraph{Spezialfall einer einfachen linearen Ausgleichsgeraden}

\subparagraph{Herleitung und Verfahren}

Eine einfache Modellfunktion mit zwei linearen Parametern stellt das Polynom erster Ordnung
$$f (x) = \alpha_0 + \alpha_1 \cdot x$$
dar. Gesucht werden zu n gegebenen Messwerten $(x_1, y_1), \dotsc , (x_n, y_n)$ die Koeffizienten $\alpha_0$ und $\alpha_1$ der bestangepassten Geraden. Die Abweichungen $r_i$ zwischen der gesuchten Geraden und den jeweiligen Messwerten
$$
\begin{matrix}
r_1 = & \alpha_0 + & \alpha_1 \cdot x_1 - y_1 \\
r_2 = & \alpha_0 + & \alpha_1 \cdot x_2 - y_2 \\
\vdots & \vdots & \vdots \\
r_n = & \alpha_0 + & \alpha_1 \cdot x_n - y_n
\end{matrix}
$$
nennt man Anpassungsfehler oder Residuen. Gesucht sind nun die Koeffizienten $\alpha_0$ und $\alpha_1$ mit der kleinsten Summe der Fehlerquadrate
$$ 
\min_{\alpha_0,\; \alpha_1} \sum_{i=1}^n r_i^2.
$$
Der große Vorteil des Ansatzes mit diesem Quadrat der Fehler wird sichtbar, wenn man diese Minimierung mathematisch durchführt: Die Summenfunktion wird als Funktion der beiden Variablen $\alpha_0$ und $\alpha_1$ aufgefasst (die eingehenden Messwerte sind dabei numerische Konstanten), dann die Ableitung (genauer: partielle Ableitungen) der Funktion nach diesen Variablen (also $\alpha_0$ und $\alpha_1$) gebildet und von dieser Ableitung schließlich die Nullstelle gesucht. Es ergibt sich das lineare Gleichungssystem
$$ 
\begin{aligned}
n \cdot \alpha_0 + \left( \sum_{i=1}^n x_i \right) \alpha_1 & = \sum_{i=1}^n y_i \\
\left( \sum_{i=1}^n x_i \right) \alpha_0 + \left( \sum_{i=1}^n x_i^2 \right) \alpha_1 & = \sum_{i=1}^n x_i y_i
\end{aligned}
$$
mit der Lösung
$$
\alpha_1 = \frac{\sum_{i=1}^n x_i (y_i - \overline{y})}{\sum_{i=1}^n (x_i - \overline{x})^2} = \frac{\sum_{i=1}^n (x_i - \overline{x}) (y_i - \overline{y})}{\sum_{i=1}^n (x_i - \overline{x})^2} = \frac{SP_{xy}}{SQ_x}
\text{ und } \alpha_0 = \overline{y} - \alpha_1 c\overline{x},
$$
wobei $SP_{xy}$ die Summe der Abweichungsprodukte zwischen $x$ und $y$ darstellt, und $SQ_x$ die Summe der Abweichungsquadrate von $x$ darstellt. Dabei ist $\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i$ das arithmetische Mittel der $x$-Werte, $\overline{y}$ entsprechend. Die Lösung für $\alpha_1$ kann mit Hilfe des Verschiebungssatzes auch in nicht-zentrierter Form
$$
\alpha_1 = \frac{\sum_{i=1}^n (x_i \cdot y_i) - n \cdot \overline{x} \cdot \overline{y}}{\left( \sum_{i=1}^n x_i^{2} \right) - n \cdot \overline{x}^2}
$$
angegeben werden. Diese Ergebnisse können auch mit Funktionen einer reellen Variablen, also ohne partielle Ableitungen, hergeleitet werden.

Aus der Lösung von $\alpha _{0}$ wird zudem eine Eigenschaft der linearen Ausgleichsgerade ersichtlich: Die Ausgleichsgerade verläuft stets durch den Punkt $(\overline{x}, \overline{y})$. Das ist hilfreich, falls die Ausgleichsgerade sehr steil oder gar senkrecht verläuft und der Achsenabschnitt dadurch sehr groß wird oder gar nicht berechnet werden kann. In diesem Fall kann dieser Punkt als Stützpunkt einer Vektordarstellung der Ausgleichsgerade verwendet werden.

\paragraph{Spezialfall einer linearen Ausgleichsfunktion mit mehreren Variablen}

Ist die Modellfunktion ein mehrdimensionales Polynom erster Ordnung, besitzt also statt nur einer Variablen $x$ mehrere unabhängige Modellvariablen $x_1, \ldots, x_N$, erhält man eine lineare Funktion der Form
$$
f (x_1, \dotsc, x_N; \alpha_0, \alpha_1, \dotsc, \alpha_N) = \alpha_0 + \alpha_1 x_1 +\dotsb + \alpha_N x_N,
$$
die auf die Residuen
$$
\begin{matrix}
r_1 = & \alpha_0 + \alpha_1 x_{1, 1} + & \dotsb \;\; + \alpha_j x_{j, 1} + & \dotsb \;\; + \alpha_N x_{N, 1} - y_1 \\
r_2 = & \alpha_0 + \alpha_1 x_{1, 2} + & \dotsb \;\; + \alpha_j x_{j, 2} + & \dotsb \;\; + \alpha_N x_{N, 2} - y_2 \\
\vdots & \vdots & \vdots & \vdots \\
r_i = & \alpha_0 + \alpha_1 x_{1, i} + & \dotsb \;\; + \alpha_j x_{j, i} + & \dotsb \;\; + \alpha_N x_{N, i} - y_i \\
\vdots & \vdots & \vdots & \vdots \\ 
r_n = & \alpha_0 + \alpha_1 x_{1, n} + & \dotsb \;\; + \alpha_j x_{j, n} + & \dotsb \;\; + \alpha_N x_{N, n} - y_n
\end{matrix}
$$
führt und über den Minimierungsansatz
$$\min_\alpha \sum_{i=1}^n r_i^2$$
gelöst werden kann.

\paragraph{Der allgemeine lineare Fall}

Im Folgenden soll der allgemeine Fall von beliebigen linearen Modellfunktionen mit beliebiger Dimension gezeigt werden. Zu einer gegebenen Messwertfunktion $$y(x_{1},x_{2},\dots ,x_{N})$$ mit $N$ unabhängigen Variablen sei eine optimal angepasste lineare Modellfunktion
$$
f (x_1, \dots, x_N; \alpha_1, \dots, \alpha_m) = \sum_{j=1}^m \alpha_j \varphi_j (x_1, \dots, x_N)
$$
gesucht, deren quadratische Abweichung dazu minimal sein soll. $x_i$ sind dabei die Funktionskoordinaten, $\alpha_j$ die zu bestimmenden linear eingehenden Parameter und $\varphi_j$ beliebige zur Anpassung an das Problem gewählte linear unabhängige Funktionen.

Bei $n$ gegebenen Messpunkten
$$
(x_{1, 1}, x_{2, 1}, \dots, x_{N, 1}; y_1), (x_{1, 2}, x_{2, 2}, \dots, x_{N, 2}; y_2), \dots, (x_{1, n}, x_{2, n}, \dots, x_{N, n}; y_n)
$$
erhält man die Anpassungsfehler
$$
\begin{matrix}
r_1 = & \alpha_1 \varphi_1 (x_{1, 1}, \dots, x_{N, 1}) \;\; + & \cdots \;\;\; + \alpha_m \varphi_m (x_{1, 1}, \dots, x_{N, 1}) - y_1 \\
\vdots & \vdots & \vdots \\
r_i = & \alpha_1 \varphi_1 (x_{1, i}, \dots, x_{N, i}) \;\; + & \cdots \;\;\; + \alpha_m \varphi_m (x_{1, i}, \dots, x_{N, i}) - y_i \\
\vdots & \vdots & \vdots \\
r_n = & \alpha_1 \varphi_1 (x_{1, n}, \dots, x_{N, n}) \;\; + & \cdots \;\;\; + \alpha_m \varphi_m (x_{1, n}, \dots, x_{N, n}) - y_n
\end{matrix}
$$
oder in Matrixschreibweise
$$r=A \alpha -y,$$
wobei der Vektor $r \in \R^n$ die $r_i$ zusammenfasst, die Matrix $A \in \R^{n \times m}$ die Basisfunktionswerte $A_{ij} := \varphi_j (x_{1, i}, \dots, x_{N, i})$, der Parametervektor $\alpha \in \R^m$ die Parameter $\alpha_j$ und der Vektor $y \in \R^n$ die Beobachtungen $y_i$, wo $n \geq m$.

Der beste Schätzer wird durch die Lösung des Minimierungsproblems bestimmt. Das Minimierungsproblem, das sich mithilfe der euklidischen Norm durch
$$
\min_\alpha \sum _{i=1}^n r_i^2 = \min_\alpha \| f (\alpha)-y \|_2^2 = \min_\alpha \| A \alpha -y \|_2^2
$$
formulieren lässt, kann im regulären Fall (d. h. $A$ hat vollen Spaltenrang, somit ist $A^T A$ regulär und damit invertierbar) mit der Formel
$$\hat\alpha = (A^T A)^{-1} A^T y$$
eindeutig analytisch gelöst werden (siehe nächster Abschnitt). Im generalisierten Fall der gewichteten kleinsten Quadrate muss zudem noch die inverse Kovarianzmatrix $V^{-1}$ berücksichtigt werden
$$\hat\alpha = (A^T V^{-1} A)^{-1} A^T V^{-1} y.$$
Im singulären Fall, wenn $A$ nicht von vollem Rang ist, ist das Normalgleichungssystem nicht eindeutig lösbar, d.h. der Parameter $\alpha$ nicht identifizierbar.

Jedoch ist in vielen praktischen Anwendungen die Modellfunktionen $y (x_1, x_2, \dots, x_N)$ nicht analytisch bekannt, sondern kann nur für verschiedene diskrete Werte $(x_1, x_2, \dots, x_N)$ bestimmt werden. In diesem Fall kann die Modellfunktion mithilfe einer linearen Regression näherungsweise bestimmt werden, und der beste Schätzer wird direkt mit der Gleichung des linearen Template Fits bestimmt:
$$
\hat\alpha = \left( (Y \tilde{M})^{\mathsf{T}} V^{-1} Y \tilde {M} \right)^{-1} (Y \tilde{M})^{\mathsf{T}} V^{-1} (d-Y \bar{m}).
$$
Dabei ist $Y$ die Matrix mit den bekannten Werten der Modellfunktion (Template Matrix) für alle $x$, und der Vektor $d$ bezeichnet die Zufallsvariablen (bspw. eine Messung). Die Matrix $\tilde{M}$ und der Vektor $\tilde{m}$ werden mithilfe der Stützstellen $x$ (zusammengefasst in der Matrix $Y$) berechnet.

\paragraph{Lösung des Minimierungsproblems}

\subparagraph{Herleitung und Verfahren}

Das Minimierungsproblem ergibt sich, wie im allgemeinen linearen Fall gezeigt, als
$$
\min_\alpha \| A \alpha -y \|_2^2 = \min_\alpha (A \alpha -y)^T (A \alpha - y) = \min_\alpha (\alpha^T A^T A \alpha - 2 y^T A \alpha + y^T y).
$$
Dieses Problem ist immer lösbar. Hat die Matrix $A$ vollen Rang, so ist die Lösung sogar eindeutig. Zum Bestimmen des extremalen Punktes ergibt Nullsetzen der partiellen Ableitungen bezüglich der $\alpha_j$,
$$\nabla \| A \alpha -y \|_2^2 = 2 (A \alpha -y)^T A,$$
ein lineares System von Normalgleichungen (auch Gaußsche Normalgleichungen oder Normalengleichungen)
$$A^T A \alpha = A^T y,$$
welches die Lösung des Minimierungsproblems liefert und im Allgemeinen numerisch gelöst werden muss. Hat $A$ vollen Rang und ist $n\geq m$, so ist die Matrix $A^T A$ positiv definit, so dass es sich beim gefundenen Extremum in der Tat um ein Minimum handelt. Damit kann das Lösen des Minimierungsproblems auf das Lösen eines Gleichungssystems reduziert werden. Im einfachen Fall einer Ausgleichsgeraden kann dessen Lösung, wie gezeigt wurde, sogar direkt als einfache Formel angegeben werden.

Alternativ lassen sich die Normalgleichungen in der Darstellung
$$
A^T A \alpha -A^T y = 
\begin{pmatrix}
\left\langle \varphi_1, \varphi_1 \right\rangle & \left\langle \varphi_1, \varphi_2 \right\rangle & \cdots & \left\langle \varphi_1, \varphi_m \right\rangle \\
\vdots & \vdots & \ddots & \vdots \\
\left\langle \varphi_m, \varphi_1 \right\rangle & \left\langle \varphi_m, \varphi_2 \right\rangle & \cdots & \left\langle \varphi_m, \varphi_m \right\rangle
\end{pmatrix}
\begin{pmatrix}
\alpha_1 \\
\vdots \\
\alpha_{m}
\end{pmatrix}
-
\begin{pmatrix}
\left\langle y, \varphi_1 \right\rangle \\
\vdots \\
\left\langle y, \varphi_m \right\rangle \\
\end{pmatrix}
=0.
$$
ausschreiben, wobei $\left\langle \cdot, \cdot \right\rangle$ das Standardskalarprodukt symbolisiert und auch als Integral des Überlappens der Basisfunktionen verstanden werden kann. Die Basisfunktionen $\varphi_i$ sind als Vektoren $\vec{\varphi_i} = (\varphi_i (x_{1, 1}, \dots, x_{N, 1}),\varphi_i (x_{1, 2}, \dots, x_{N, 2}), \ldots, \varphi_i (x_{1, n}, \dots, x_{N, n}))$ zu lesen mit den $n$ diskreten Stützstellen am Ort der Beobachtungen $y = \vec{y} = (y_1, y_2, \ldots, y_n)$.

Ferner lässt sich das Minimierungsproblem mit einer Singulärwertzerlegung gut analysieren. Diese motivierte auch den Ausdruck der Pseudoinversen, einer Verallgemeinerung der normalen Inversen einer Matrix. Diese liefert dann eine Sichtweise auf nichtquadratische lineare Gleichungssysteme, die einen nicht stochastisch, sondern algebraisch motivierten Lösungsbegriff erlaubt.

\subparagraph{Numerische Behandlung der Lösung}

Zur numerischen Lösung des Problems gibt es zwei Wege. Zum einen können die Normalgleichungen
$$A^T A \alpha =A^T y$$
gelöst werden, die eindeutig lösbar sind, falls die Matrix A vollen Rang hat. Ferner hat die Produktsummenmatrix $A^T A$ die Eigenschaft, positiv definit zu sein, ihre Eigenwerte sind also alle positiv. Zusammen mit der Symmetrie von $A^T A$ kann dies beim Einsatz von numerischen Verfahren zur Lösung ausgenutzt werden: beispielsweise mit der Cholesky-Zerlegung oder dem CG-Verfahren. Da beide Methoden von der Kondition der Matrix stark beeinflusst werden, ist dies manchmal keine empfehlenswerte Herangehensweise: Ist schon $A$ schlecht konditioniert, so ist $A^T A$ quadratisch schlecht konditioniert. Dies führt dazu, dass Rundungsfehler so weit verstärkt werden können, dass sie das Ergebnis unbrauchbar machen. Durch Regularisierungsmethoden kann die Kondition allerdings verbessert werden.

Eine Methode ist die sog. Ridge-Regression, die auf Hoerl und Kennard (1970) zurückgeht. Das englische Wort ridge heißt soviel wie Grat, Riff, Rücken. Hier wird anstelle der schlecht konditionierten Matrix $A^T A$ die besser konditionierte Matrix $A^T A + \delta I_m$ benutzt. Dabei ist $I_m$ die $m$-dimensionale Einheitsmatrix. Die Kunst besteht in der geeigneten Wahl von $\delta$. Zu kleine $\delta$ erhöhen die Kondition nur wenig, zu große $\delta$ führen zu verzerrter Anpassung.

Zum anderen liefert das ursprüngliche Minimierungsproblem eine stabilere Alternative, da es bei kleinem Wert des Minimums eine Kondition in der Größenordnung der Kondition von $A$, bei großen Werten des Quadrats der Kondition von $A$ hat. Um die Lösung zu berechnen wird eine QR-Zerlegung verwendet, die mit Householdertransformationen oder Givens-Rotationen erzeugt wird. Grundidee ist, dass orthogonale Transformationen die euklidische Norm eines Vektors nicht verändern. Damit ist
$$\| A \alpha -y \|_2 = \| Q (A \alpha -y) \|_2$$
für jede orthogonale Matrix $Q$. Zur Lösung des Problems kann also eine QR-Zerlegung von $A$ berechnet werden, wobei man die rechte Seite direkt mittransformiert. Dies führt auf eine Form
$$\| R \alpha -Q^T y \|_2$$
mit $R = \binom{\tilde{R}}{0}$, wobei $\tilde{R} \in \R^{m \times m}$ eine rechte obere Dreiecksmatrix ist. Die Lösung des Problems ergibt sich somit durch die Lösung des Gleichungssystems
$$
\tilde{R} 
\begin{pmatrix}
\alpha_1 \\
\vdots \\
\alpha_m
\end{pmatrix}
=
\begin{pmatrix}
(Q^T y)_1 \\
\vdots \\
(Q^T y)_m
\end{pmatrix}
$$
Die Norm des Minimums ergibt sich dann aus den restlichen Komponenten der transformierten rechten Seite $(Q y)_{m+1},\dots ,(Q y)_n$, da die dazugehörigen Gleichungen aufgrund der Nullzeilen in 
$R$ nie erfüllt werden können.

In der statistischen Regressionsanalyse spricht man bei mehreren gegebenen Variablen $x_1, \ldots, x_n$ von multipler linearer Regression. Der gebräuchlichste Ansatz ein multiples lineares Modell zu schätzen ist als die gewöhnliche Kleinste-Quadrate-Schätzung bzw. gewöhnliche Methode der kleinsten Quadrate (englisch ordinary least squares, kurz OLS) bekannt. Im Gegensatz zur gewöhnlichen KQ-Methode wird die verallgemeinerte Methode der kleinsten Quadrate, kurz VMKQ (englisch generalised least squares, kurz GLS) bei einem verallgemeinerten linearen Regressionsmodell verwendet. Bei diesem Modell weichen die Fehlerterme von der Verteilungsannahme wie Unkorreliertheit und/oder Homoskedastizität ab. Dagegen liegen bei multivariater Regression für jede Beobachtung $(i=1, \dots, n)$ $r$ viele $y$-Werte vor, so dass statt eines Vektors eine $n \times r$-Matrix $Y$ vorliegt (siehe Allgemeines lineares Modell). Die linearen Regressionsmodelle sind in der Statistik wahrscheinlichkeitstheoretisch intensiv erforscht worden. Besonders in der Ökonometrie werden beispielsweise komplexe rekursiv definierte lineare Strukturgleichungen analysiert, um volkswirtschaftliche Systeme zu modellieren.

\paragraph{Probleme mit Nebenbedingungen}

Häufig sind Zusatzinformationen an die Parameter bekannt, die durch Nebenbedingungen formuliert werden, die dann in Gleichungs- oder Ungleichungsform vorliegen. Gleichungen tauchen beispielsweise auf, wenn bestimmte Datenpunkte interpoliert werden sollen. Ungleichungen tauchen häufiger auf, in der Regel in der Form von Intervallen für einzelne Parameter. Im Einführungsbeispiel wurde die Federkonstante erwähnt, diese ist immer größer Null und kann für den konkret betrachteten Fall immer nach oben abgeschätzt werden.

Im Gleichungsfall können diese bei einem sinnvoll gestellten Problem genutzt werden, um das ursprüngliche Minimierungsproblem in eines einer niedrigeren Dimension umzuformen, dessen Lösung die Nebenbedingungen automatisch erfüllt.

Schwieriger ist der Ungleichungsfall. Hier ergibt sich bei linearen Ungleichungen das Problem
$$
\min_\alpha \| \vec{f} - \vec {y} \|_2 \text{ mit } l \leq C \alpha \leq u,\; C \in \R^{n \times n},
$$
wobei die Ungleichungen komponentenweise gemeint sind. Dieses Problem ist als konvexes und quadratisches Optimierungsproblem eindeutig lösbar und kann beispielsweise mit Methoden zur Lösung solcher angegangen werden.

Quadratische Ungleichungen ergeben sich beispielsweise bei der Nutzung einer Tychonow-Regularisierung zur Lösung von Integralgleichungen. Die Lösbarkeit ist hier nicht immer gegeben. Die numerische Lösung kann beispielsweise mit speziellen QR-Zerlegungen erfolgen.

\subsubsection{Nichtlineare Modellfunktionen}

\paragraph{Grundgedanke und Verfahren}

Mit dem Aufkommen leistungsfähiger Rechner gewinnt insbesondere die nichtlineare Regression an Bedeutung. Hierbei gehen die Parameter nichtlinear in die Funktion ein. Nichtlineare Modellierung ermöglicht im Prinzip die Anpassung von Daten an jede Gleichung der Form $y = f (\alpha)$. Da diese Gleichungen Kurven definieren, werden die Begriffe nichtlineare Regression und \emph{curve fitting} zumeist synonym gebraucht.

Manche nichtlineare Probleme lassen sich durch geeignete Substitution in lineare überführen und sich dann wie oben lösen. Ein multiplikatives Modell von der Form 
$$y=\alpha_0 \cdot x^{\alpha_1}$$
lässt sich beispielsweise durch Logarithmieren in ein additives System überführen. Dieser Ansatz findet unter anderem in der Wachstumstheorie Anwendung.

Im Allgemeinen ergibt sich bei nichtlinearen Modellfunktionen ein Problem der Form
$$\min_\alpha \| f (\alpha)-y \|_2,$$
mit einer nichtlinearen Funktion f. Partielle Differentiation ergibt dann ein System von Normalgleichungen, das nicht mehr analytisch gelöst werden kann. Eine numerische Lösung kann hier iterativ mit dem Gauß-Newton-Verfahren erfolgen.

Aktuelle Programme arbeiten häufig mit einer Variante, dem Levenberg-Marquardt-Algorithmus. Dabei wird durch eine Regularisierung die Monotonie der Näherungsfolge garantiert. Zudem ist das Verfahren bei größerer Abweichung der Schätzwerte toleranter als die Ursprungsmethode. Beide Verfahren sind mit dem Newton-Verfahren verwandt und konvergieren unter geeigneten Voraussetzungen (der Startpunkt ist genügend nahe beim lokalen Optimum) meist quadratisch, in jedem Schritt verdoppelt sich also die Zahl der korrekten Nachkommastellen.

Wenn die Differentiation auf Grund der Komplexität der Zielfunktion zu aufwendig ist, stehen eine Reihe anderer Verfahren als Ausweichlösung zu Verfügung, die keine Ableitungen benötigen, siehe bei Methoden der lokalen nichtlinearen Optimierung.

\subsubsection{Fehlverhalten bei Nichterfüllung der Voraussetzungen}

Die Methode der kleinsten Quadrate erlaubt es, unter bestimmten Voraussetzungen die wahrscheinlichsten aller Modellparameter zu berechnen. Dazu muss ein korrektes Modell gewählt worden sein, eine ausreichende Menge Messwerte vorliegen und die Abweichungen der Messwerte gegenüber dem Modellsystem müssen eine Normalverteilung bilden. In der Praxis kann die Methode jedoch auch bei Nichterfüllung dieser Voraussetzungen für diverse Zwecke eingesetzt werden. Dennoch sollte beachtet werden, dass die Methode der kleinsten Quadrate unter bestimmten ungünstigen Bedingungen völlig unerwünschte Ergebnisse liefern kann. Beispielsweise sollten keine Ausreißer in den Messwerten vorliegen, da diese das Schätzergebnis verzerren. Außerdem ist Multikollinearität zwischen den zu schätzenden Parametern ungünstig, da diese numerische Probleme verursacht. Im Übrigen können auch Regressoren, die weit von den anderen entfernt liegen, die Ergebnisse der Ausgleichsrechnung stark beeinflussen. Man spricht hier von Werten mit großer Hebelkraft (englisch: High Leverage Value).

\paragraph{Multikollinearität}

Das Phänomen der Multikollinearität entsteht, wenn die Messreihen zweier gegebener Variablen $x_i$ und $x_j$ sehr hoch korreliert sind, also fast linear abhängig sind. Im linearen Fall bedeutet dies, dass die Determinante der Normalgleichungsmatrix $A^T A$ sehr klein und die Norm der Inversen umgekehrt sehr groß ist; die Kondition von $A^T A$ ist also stark beeinträchtigt. Die Normalgleichungen sind dann numerisch schwer zu lösen. Die Lösungswerte können unplausibel groß werden, und bereits kleine Änderungen in den Beobachtungen bewirken große Änderungen in den Schätzwerten.

\paragraph{Ausreißer}

Als Ausreißer sind Datenwerte definiert, die 'nicht in eine Messreihe passen'. Diese Werte beeinflussen die Berechnung der Parameter stark und verfälschen das Ergebnis. Um dies zu vermeiden, müssen die Daten auf fehlerhafte Beobachtungen untersucht werden. Die entdeckten Ausreißer können beispielsweise aus der Messreihe ausgeschieden werden oder es sind alternative ausreißer\-resistente Berechnungsverfahren wie gewichtete Regression oder das Drei-Gruppen-Verfahren anzuwenden.

Im ersten Fall wird nach der ersten Berechnung der Schätzwerte durch statistische Tests geprüft, ob Ausreißer in einzelnen Messwerten vorliegen. Diese Messwerte werden dann ausgeschieden und die Schätzwerte erneut berechnet. Dieses Verfahren eignet sich dann, wenn nur wenige Ausreißer vorliegen.

Bei der gewichteten Regression werden die abhängigen Variablen $y$ in Abhängigkeit von ihren Residuen gewichtet. Ausreißer, d.h. Beobachtungen mit großen Residuen, erhalten ein geringes Gewicht, das je nach Größe des Residuums abgestuft sein kann. Beim Algorithmus nach Mosteller und Tukey (1977), der als 'biweighting' bezeichnet wird, werden unproblematische Werte mit 1 und Ausreißer mit 0 gewichtet, was die Unterdrückung des Ausreißers bedingt. Bei der gewichteten Regression sind in der Regel mehrere Iterationsschritte erforderlich, bis sich die Menge der erkannten Ausreißer nicht mehr ändert.

\paragraph{Heteroskedastische Fehler}

Liegen heteroskedastische Fehler vor, so liefert die Minimierung des Mittelwertes der kleinsten Quadrate keinen effizienten Schätzer des (bedingten) Mittelwertes, obwohl dieser immer noch unverzerrt ist. Die Minimierung der Gausschen Negativen Log-Likelihood kann in diesem Fall eine Alternative sein.

\subsubsection{Verallgemeinerte Kleinste-Quadrate-Modelle}

Weicht man die starken Anforderungen im Verfahren an die Fehlerterme auf, erhält man so genannte verallgemeinerte Kleinste-Quadrate-Ansätze. Wichtige Spezialfälle haben dann wieder eigene Namen, etwa die gewichtete Methode der kleinsten Quadrate (englisch weighted least squares, kurz WLS), bei denen die Fehler zwar weiter als unkorreliert angenommen werden, aber nicht mehr von gleicher Varianz. Dies führt auf ein Problem der Form
$$\| D (A \alpha - y) \|_2,$$
wobei $D$ eine Diagonalmatrix ist. Variieren die Varianzen stark, so haben die entsprechenden Normalgleichungen eine sehr große Kondition, weswegen das Problem direkt gelöst werden sollte.

Nimmt man noch weiter an, dass die Fehler in den Messdaten auch in der Modellfunktion berücksichtigt werden sollten, ergeben sich die \emph{totalen kleinsten Quadrate} in der Form
$$\min_{E, r} \| (E, r) \|_F,\quad (A+E) \alpha = b + r,$$
wobei $E$ der Fehler im Modell und $r$ der Fehler in den Daten ist.

Schließlich gibt es noch die Möglichkeit, keine Normalverteilung zugrunde zu legen. Dies entspricht beispielsweise der Minimierung nicht in der euklidischen Norm, sondern der Summennorm. Solche Modelle sind Themen der Regressionsanalyse.

\chapter{ufPro}

\section{Pending Tasks / ToDos}

\begin{itemize}
\item elevation, superelevation, outer chainage, design speed, \ldots
\item try to implement the angle-value-handling vector-based ($\sin$- and $\cos$-values ), preferred instead of cycling radiant-values. TICK
\item Check the capabilities of coord.system transformations like the epsg.io service.
\end{itemize}

\section{Basics and Preview}

Die hier dargelegten Überlegungen bedienen sich strikt der mathematischen Nomenklatur, welche sich nicht nur punktuell von der vermessungstechnischen oder auch alltäglichen Vorstellung unterscheidet. Gegebenenfalls wird an passender Stelle explizit darauf hingewiesen.

Wohin geht die Reise? Wir wollen die typischen Möglichkeiten des Trassen-basierten Rechnens zusammen stellen, darauf aufbauende Dokumentations\-möglichkeiten andocken (Trassenplan, Weichenhöhenplan, Geschwindigkeits-Wege-Band, et. al.), sowie grafische Komponenten bereit stellen und aktuelle Schnittstellen (BIM-konform) implementieren. 

\subsection{2D-Kurven}

Eine Trasse verstehen wir als stetig glatte Kurve im $\R^2$ (Ebene), bestehend aus Segmenten - wahlweise Gerade, Bogen oder Übergangsbogen (\myIndex{Clothoide}, S-Form\index{S-Form}, Bloss\index{Bloss}, Sinusoide\index{Sinusoide}, Cosinoide\index{Cosinoide} \ldots) --- entsprechend den Darstellungen z.B. in den landXML\index{landXML}-Schemata.

Mit Startpunkt und -richtung, sowie Krümmungsverlauf ist der Kurven- respektive Trassenverlauf festgelegt (Anfangswertproblem). Üblicherweise sind Trassen bogenlängen-parametrisiert, was die Herleitung und Darstellung grundlegender Hilfsmittel (Formeln) stark vereinfacht. Schönes Beispiel: die Elemente des Tangentialfelds (jeder Tangentialvektor entlang der Kurve) haben alle Länge 1, und sind somit eindeutig mit Sinus- und Cosinuswert des zugrundeliegenden Richtungswinkels zu beschreiben.
\begin{equation*}
\dot{c} (s) = 
\begin{pmatrix}
\dot{x} \\ \dot{y}
\end{pmatrix}
(s) = 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
(t (s))
\end{equation*}
Weiterhin ergibt sich unter Hinzunahme des Normalenfeldes ein Zugang zur Krümmung als Faktor zur Verbindung von Normaler und zweiter Ableitung.
\begin{equation*}
\ddot{c} (s) = \dot{t} (s) \cdot
\begin{pmatrix}
-\sin \\ \cos
\end{pmatrix}
(t (s)) = \dot{t} (s) \cdot
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}^\perp
(t (s)) = 
k (s) \cdot N (s)
\end{equation*}
Woraus sich augenscheinlich die Lösbarkeit des oben erwähnten Anfangswertproblems ergibt. \qed

\subsection{Anfangswertproblem}

Sei $$\kappa (\sigma) : [0, 1] \to [0, 1]$$ stetig mit $\kappa (0) = 0$ und $\kappa (1) = 1$. Des Weiteren seien $k_a$, $k_e$ und $L$ bekannt (und passabel!), ebenso $t_a$ und $(x_a, y_a)$. Die \emph{normalisierte Krümmungsfunktion} $\kappa$ skaliert nun mittels $k_a + (k_e - k_a) \cdot \kappa (s / L)$ für jedes $s \in [0, L]$ zu $k (s) : [0, L] \to [k_a, k_e]$, für welches gilt:
\begin{eqnarray*}
k (s) & = & k_a + (k_e - k_a) \cdot \kappa (s / L) \\
\int k (s) \diff s & = & k_a + (k_e - k_a) \cdot \int \kappa (s / L) \diff s \\
& = & k_a + (k_e - k_a) \cdot \int \kappa (\sigma) \cdot L \diff \sigma, \qquad \text{mit } \sigma = \frac{s}{L} \\
\Delta t (s) & = & \int_0^s k (s) \diff s \\
& = & k_a \cdot s + (k_e - k_a) \cdot L \cdot \int_0^\sigma \kappa (\sigma) \diff \sigma \\
\text{ setze } \Delta \theta (\sigma) & := & \int_0^{\sigma} \kappa (\sigma) \diff \sigma, \text{ also} \\
\Delta t (s) & = & k_a \cdot s + (k_e - k_a) \cdot L \cdot \Delta \theta (s / L)
\end{eqnarray*}
Hmm ... Mal sehn wohin das führt ...
\begin{eqnarray*}
\begin{pmatrix}
x \\ y
\end{pmatrix}
(s) & = & 
\begin{pmatrix}
x_a \\ y_a
\end{pmatrix}
+ \int_0^s 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
(t_a + \Delta t (s)) \diff s \\
. & = &  
\begin{pmatrix}
x_a \\ y_a
\end{pmatrix}
+ \int_0^s 
\begin{pmatrix}
\cos t_a \cos \Delta t (s) - \sin t_a \sin \Delta t (s) \\ \sin t_a \cos \Delta t (s) + \cos t_a \sin \Delta t (s)
\end{pmatrix}
\diff s \\ 
. & = & 
\begin{pmatrix}
x_a \\ y_a
\end{pmatrix}
+ \cos t_a \cdot \int_0^s  
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
\Delta t (s) \diff s + \sin t_a \cdot \int_0^s 
\begin{pmatrix}
-\sin \\ \cos
\end{pmatrix}
\Delta t (s) \diff s
\end{eqnarray*}

Zusätzliche Anforderungen an $\kappa$ wie Glattheit auch in Anfang und Ende (mit Klothoide nicht erfüllt!) oder Schiefsymmetrie ergeben Festlegungen in simplifizierter Form, etwa erster oder \emph{nur} zweiter Ableitung, auch auf anderen Definitionsbereichen. Glattheit in Anfang und Ende heisst $\kappa' (0) = \kappa' (1) = 0$, ggf. mehrfach. Womit in polynomialer Form gilt: $\kappa' (\sigma) = (0 - \sigma)^m \cdot (1 - \sigma)^n \cdot \rho (\sigma)$, für Antisymmetrie in $0.5$ zumindest auch $(0.5 - \sigma)^k = 0$ als Teil von $\kappa''$ \ldots

\begin{remark}[Substitutionsregel]
$$\int f (x) \diff x = \int f ( \varphi ( \sigma ) ) \cdot \varphi' ( \sigma ) \diff \sigma$$
\end{remark}
Für $\varphi: \; \sigma \in [0, 1] \to x \in [a, b]$ dann $a+(b-a) \cdot \sigma = x$, also $\varphi' = (b-a)$

\ldots

\subsection{Die Trassenelemente}

Trassen bzw. Achsen als Bezugssystem linienförmiger Infrastrukur bestehen üblicherweise aus einer geordneten Abfolge von Elementen konstanter Krümmung (Gerade, Bogen) und jeweils zwischenliegender (krümmungs-)vermittelnder Elemente, den Übergangsbögen. (Anm.: Jedes Element für sich ist schon eine simple Kurve.)

Im folgenden gibt es einen kurzen Abriss zur expliziten AWP-Lösung für Gerade und Bogen (mit erwartbarem\footnote{oder auch nicht, siehe die vorangestellten Bemerkung hinsichtlich mathematischer Nomenklatur. Beispiel Krümmung (respektive invers Radius): einen Rechtsbogen durchfährt man nach rechts, nur hat dieser aber mathematisch eine negative Krümmung ... Oops!} Ergebnis), anschliessend gleiches für verschiedene Arten Übergangs\-bögen mit einem eigenen umfangreicheren Abschnitt.

\begin{table}[htp]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
& Krümmung $\kappa$ & Richtung $\Delta \tau (s)$ & Easting $Y (s)$ & Northing $X (s)$ \\
&& $= \int_{s_0}^s \kappa (s) \diff s$ & $= \int_{s_0}^s \cos (\Delta \tau (s)) \diff s$ & $= \int_{s_0}^s \sin (\Delta \tau (s)) \diff s$ \\ \hline
Gerade & $0$ & $t = t_0 = const$ & $s \cdot \cos t$ & $s \cdot \sin t$ \\ \hline
Bogen & const & $k \cdot s$ (oBdA $t_0 = 0$) & $\sin (k \cdot s) / k$ & $(1 - \cos (k \cdot s)) / k$ \\ \hline
\end{tabular}
\caption{elementare Berechnung für Geraden und Bögen (mit Startpunkt im Koordinatenursprung)}
\end{center}
\end{table}

\subsubsection{Parametrisierungen}

\begin{itemize}
\item Bogenlängen\-parametrisierung
\item Polarkoordinaten
\item algebraisch / implizite Beschreibung
\item Funktionsgraphen (explizit)
\end{itemize}

\subsubsection{Übergangsbögen}

In den folgenden Betrachtungen beschränken wir uns auf Clothoiden, S-Form, Blossbögen, Cosinoiden und Sinusoiden. Spezialfälle wie 'unvermittelter Krümmungswechsel' (Über\-gangs\-bogen\-länge gleich Null) oder Raritäten (z.B Lemniskate, Radioide, \ldots) bleiben vorerst aussen vor, ebenso wie 'simple' Approximationen (\emph{kubische Parabel} für Clothoiden, \emph{Sine Half-Wavelength Diminishing Tangent Curve} für Cosinoiden).

Ein Übergangsbogen (engl.: transition curve) vermittelt die Krümmungs\-änderung zwischen Segmenten konstanter Krümmung und ist damit einigen weiteren Anforderungen unterworfen (z.B. Geschwindigkeitsrelevanz und Fahrkomfort) - dazu eventuell später.

Zur einfachen Illustration und Herleitung betrachten wir den Fall Segment\-länge gleich 1 ($s \in [0, 1]$) und stetiger (teils auch in den Anschlüssen glatter höherer Ordnung) Änderung der Krümmung von Null ($\kappa (0) = 0$) auf Eins ($\kappa (1) = 1$), nennen es die normalisierte Betrachtung. Die genannten Übergangsbögen unterscheiden sich, wie gleich explizit angegeben in ihrer polynomialen Ordnung, von erstem Grad (Clothoide) bis unendlich (Sinusoide). Im unserem Normalo-Schaufenster $[0, 1] \times [0, 1]$ sind es also Funktionsgraphen, welche beginnend mit schlicht gerade bis mehr und mehr s-förmig die gegenüber liegenden Eckpunkte $(0, 0)$ und $(1, 1)$ verbinden.

Bei der S-Form offensichtlich schon per Definition, so ist sogar bei allen Nicht-Clothoiden, also den Ü-Bögen mit geschwungenem Krümmungsverlauf, gegebenenfalls der halbe Verlauf (1. Schwung, half-wave) bereits von Interesse - Stichwort Übergang zwischen Gegenbögen (werden in der Praxis nicht mehr in 'einem Stück' gefertigt, liegen im Gleisbestand aber vor!)

In \cite{kufver:1997} is given a very helpful overview!

\begin{description}
\item[Clothoid] .

$$
\kappa ( \sigma ) = \sigma
$$

\item[Biquadratic / \textsc{Helmert} curve / S-Form] .

\textsc{Helmert} (1872) discussed a type of transition curve which also is known as the bi-quadratic parabola and in Germany as the \textsc{Schramm} curve (\textsc{Schuhr}, 1985). According to \textsc{Schramm} (1934), the advantage of the \textsc{Helmert} curve is the lower value of the second derivative of cant and corresponding vertical acceleration. The first time these curves were used was in 1934--1935, when more than 300 were built on the Berlin -- Hamburg line (\textsc{Schramm} 1934, 1975), but they are also used in Sweden.
In the \textsc{Helmert} curve, the curvature has the shape of two second-degree parabolas such that the curvature, $k (s)$, and its derivative, $k' (s)$, are continuous functions.

\begin{eqnarray*}
\kappa & : & [0, 0.5] \to [0, 0.5], \\
&& \sigma \mapsto 2 \sigma^2
\end{eqnarray*}

\item[\textsc{Ruch} curve] (Clothoid and two parts of \textsc{Helmert} curve)

This type of transition curve was suggested by \textsc{Ruch} (1903). The purpose with the \textsc{Ruch} curve was to create a smooth ride concerning lateral position of the mass centre of a standard vehicle, rolling and yaw velocity. The transition curve consists of three parts. The curvature in the first part has the shape of a second-degree parabola, the curvature in the second part is a linear function and the curvature in the last part again has the shape of a second-degree parabola. In the \textsc{Ruch} curve, the curvature $k (s)$ and the derivative of curvature $k' (s)$ for the trajectory of the mass centre of a standard vehicle, are continuous functions.

\textsc{Schuhr} (1984) neglected the linear acceleration of the mass centre of the vehicle which follows an angular acceleration, where the instantaneous axis of rotation is located in the track centre line (or one of the rails). In this case, the clothoid and the \textsc{Helmert} curve can be regarded as special cases of the \textsc{Ruch} curve. If the lengths of the first and third parts of the \textsc{Ruch} curve are zero, the curve is identical to a clothoid. If the lengths of the first and third parts are equal and the length of the second part is zero, the curve is identical to a \textsc{Helmert} curve.

The equations given here correspond to the simplifications of \textsc{Schuhr} (1984). If the original \textsc{Ruch} curve is to be calculated, the curvature in the first and third part must be adjusted with constant terms. These terms equal the second derivative of cant multiplied by the height of the mass centre above the rails divided by 1500\ mm. (The two correction terms will create a small reverse curve and will reduce the necessary lateral shift.) \textsc{Schuhr} also assumed that the three parts of the \textsc{Ruch} curve have the same lengths.

\ldots

\item[\textsc{Bloss} curve] .

This type of transition curve was suggested by \textsc{Bloss} (1936). The curvature of the \textsc{Bloss} curve consists of a third-degree parabola. The derivative of curvature, but not the second derivative, is a continuous function at the tangent points. The argumentation for this type of transition curve was that the curvature function involves only one equation (contrary to the \textsc{Helmert} curve) and that the function is simpler than the equation for the cosine curve.

$$
\kappa ( \sigma ) = 3 \sigma^2 - 2 \sigma^3
$$

\item[Sine] .

The sinusoidal transition curve was suggested in 1937 by \textsc{Klein} (\textsc{Schuhr} 1985, \textsc{Weigend} 1975). The curvature function is built up of one period of a sine function so that both its first and second derivatives are continuous functions at the tangent points.

$$\kappa (\sigma) = \sigma - \sin (2 \pi \sigma) / (2 \pi)$$

\item[Cosine] .

The transition curve with the curvature formed as a cosine function was suggested by \textsc{Vojacec} (1868). It has been used in Japan and Spain and on test tracks in Germany (\textsc{Kick} 1969). The curvature consists of a half-period of a cosine function. The derivative of curvature, but not the second derivative, is a continuous function at the tangent points.

$$\kappa (\sigma) = (1 - \cos (\pi \sigma)) / 2$$

\item[Gubar curve] (Clothoid and two parts of Cosine)

\textsc{Gubar} (1990) suggested a transition curve analogous to the \textsc{Ruch} curve, but consisting of a clothoid and two parts of a cosine curve. The background to this suggestion was the following: According to a limit on maximum jerk, the required length of a cosine curve may lead to such a large angle (the difference in direction between the starting point and ending point of the transition curve) that the connected circle must have a negative length. In order to reduce the required length of the transition curve (and hence the angle) the middle part is formed as a clothoid and only the ends of the transition curve have curvature functions where the second derivative is non-zero. (However, it should be noted that the \textsc{Ruch} curve also solves this problem.)

The clothoid and the cosine curve can be regarded as special cases of the \textsc{Gubar} curve. If the lengths of the first and third parts of the \textsc{Gubar} curve are zero, the curve is identical to a clothoid. If the lengths of the first and third parts are equal and the length of the second part is zero, the curve is identical to a cosine curve.

$$.$$

\item[Watorek curve] .

This transition curve was suggested by \textsc{Watorek} (1907). The curvature function is built up by a polynomial so that both its first and second derivatives are continuous functions at the tangent points. The main reason for having a continuous second derivative of curvature was to achieve a continuous second derivative of cant, which gives a smoother lateral ride for the mass centre of the vehicle.

\begin{eqnarray*}
\kappa & : & [0, 1] \to [0, 1], \\
&& \sigma \mapsto 10 \sigma^3 - 15 \sigma^4 + 6 \sigma^5
\end{eqnarray*}

\item[Mieloszyk/Koc] .

\textsc{Mieloszyk} and \textsc{Koc} (1991) suggested a new type of transition curve, with a polynomial curvature function such that both its first and second derivatives are continuous functions at the tangent points. At one of the tangent points, also the third derivative is a continuous function.

$$20 \sigma^3 - 45 \sigma^4 + 36 \sigma^5 - 10 \sigma^6$$

It is not clear which end should have the continuous third derivative of curvature when the transition has non-zero curvature at both ends (for example on reverse curves).

\item[p-curve] .

The p-curve was suggested by \textsc{Broman} (1982). The p-curve has a polynomial curvature function such that the first derivative is a continuous function at the tangent points. The p-curve is derived to solve alignment problems when a transition curve is desired between two points with defined coordinates, directions and curvatures. This problem is mathematically over-determined for conventional types of transition curves.

$$
k (s) = k_0 + \left( 3 (s/L)^2 - 2 (s/L)^3 \right) \cdot (k_1 - k_0) + p_4 s^2 (L - s)^2 + p_5 s^2 \left( \frac{L}{2} - s \right) (L - s)^2
$$

It should be noted that the two first terms correspond to the \textsc{Bloss} curve. The third term is needed to correct for a possible mismatch in direction and the fourth term is needed to correct for a possible mismatch in lateral position. It is not clear why the tangent points must coincide with the fixed points. If these two conditions are relaxed, by allowing the transition curve to start before or at least after the fixed points, but still requiring the alignment chain to pass through the two fixed points, the problem may be solved with the two first terms, the \textsc{Bloss} curve, alone.

With computer programs for automatic optimisation of alignments, a global optimum cannot be guaranteed since the number and types of elements must be specified by the user (\textsc{Hupfeld} 1970). The problem defined by \textsc{Broman} may be solved without the p-curve if a combination of two elements is used.

\item[Wiener Bogen / Vienna curve] .

\begin{remark}\emph{Vienna curves / mass center alignment}
\begin{eqnarray*}
k (s) & = & \frac{k_c}{\Psi_c} \cdot \Psi (s) - h \cdot \frac{d^2 \Psi}{d s^s} \\
k_H (s) & = & k_1 + (k_2 - k_1) \cdot f (\frac{s}{l}) - h \cdot \Delta \Psi \cdot \frac{d^2 f}{d s^2}
\end{eqnarray*}
\end{remark}

\begin{itemize}
\item[(V2)] mit $\sigma := \frac{s}{l} \in [0,\ 1]$:
$$
f ( \sigma ) = \sigma^4 \left( 35 - 84 \sigma + 70 \sigma^2 - 20 \sigma^3 \right)
$$
(!!! Fortschreibung von Bloss, Watorek nach 7. Ordnung)

\item[(V3)] mit $\sigma := \frac{s}{l} \in [0,\ 1]$ und $\tan \frac{Z}{2} = \frac{Z}{2} \approx 4.49340946$:
$$
f ( \sigma ) = \underbrace{ \sigma^2 ( 3 - 2 \sigma ) }_{ \text{Bloss} } + \underbrace{\frac{6}{Z^2} \left( +2 \sigma -1 + \cos \left( Z \sigma \right) - \frac{2}{Z} \sin \left( Z \sigma \right) \right) }_{ \text{!!!} }
$$ 

\item[(V4)] mit $\sigma := \frac{s}{l} \in [0,\ 1]$:
$$
f ( \sigma ) = \frac{1}{4} \left( \frac{1}{12 - \pi^2} \left( \pi^2 \underbrace{ \sigma^2 \left( 2 \sigma -3 \right) }_{\text{Bloss}} + 6 \underbrace{ ( 1 - \cos ( \pi \sigma ) ) }_{ \text{Cosine} } \right) \right) + \frac{3}{4} \underbrace{ \left( \sigma - \frac{1}{2 \pi} \sin ( 2 \pi \sigma ) \right) }_{ \text{Sine} }
$$

\item[(V5)] mit $\sigma := \frac{s}{l} \in [0,\ 1]$:
$$
f ( \sigma ) = \frac{15}{15 - \pi^2} \underbrace{ \left( \sigma -\frac{1}{2 \pi} \sin (2 \pi \sigma) \right) }_{ \text{Sine} } - \frac{\pi^2}{15 - \pi^2} \underbrace{ \sigma^3 ( 6 \sigma^2 - 15 \sigma + 10 ) }_{ \text{Watorek} }
$$

\item[(V6)] mit $\sigma := \frac{s}{l} \in [0,\ 1]$:
$$
f ( \sigma ) = \frac{5}{10 - \pi^2} \underbrace{ ( 1 - \cos (\pi \sigma) ) }_{ \text{Cosine} } - \frac{\pi^2}{2 (10 - \pi^2)} \underbrace{ \sigma^2 ( 2 \sigma^3 - 5 \sigma^2 + 5 ) }_{ \text{!!!} }
$$

\item[(V7)] mit $\sigma := \frac{s}{l} \in [0,\ 1]$:
$$
f ( \sigma ) = \sigma^5 ( 126 - 420 \sigma + 540 \sigma^2 - 315 \sigma^3 + 70 \sigma^4 )
$$
(!!! Fortschreibung von Bloss, Watorek, (V2) nach 9. Ordnung)

\end{itemize}

\item[Klauder curves] .

\begin{itemize}
\item[(pol\_m\_n)] mit $\sigma := \frac{s}{l} \in [-a,\ a]$:
$$
k'' ( \sigma ) = \text{const} (a + \sigma)^m \sigma^n (a - \sigma)^m
$$
By this, you can easily figure out, that: \textsc{Bloss} is pol\_0\_1, and \textsc{Watorek} is pol\_1\_1.

\item[(pol\_2\_1)]

A 5th order polynomial of form (constant) $( a + s )^2 s ( a – s )^2$ That is like (pol\_1\_1) except that at each end the 2nd derivative of the curvature has a zero of order 2 rather than of order 1. This makes the slope of 2nd derivative of curvature zero at each end. Spirals of this form are longer and gentler than spirals based on any of the other forms examined here.

\item[(pol\_2\_5)]

A 9th order polynomial of form (constant) $( a + s )^2 s^5 ( a – s )^2$ like (pol\_2\_1) but with the zero at the midpoint changed from 1st to 5th order to push acceleration of curvature toward the ends of the spiral and thus reduce spiral length for given curve offset.

\item[(pol\_2\_9)]

A 13th order polynomial of form (constant) $( a + s )^2 s^9 ( a – s )^2$ like (pol\_2\_5) but with the zero at the midpoint changed from 5th to 9th order to push acceleration of curvature further toward the ends of the spiral and further reduce spiral length for given curve offset. Further increase of the central zero order would further increase dynamic disturbance at the ends of the spiral. In the limit of large odd central zero order this form would become equivalent to a linear spiral.
\end{itemize}

\item[mentioned in landXML] 

\begin{verbatim}

<xs:simpleType name="spiralType">
<xs:restriction base="xs:string">
<xs:enumeration value="biquadratic"/>
<xs:enumeration value="bloss"/>
<xs:enumeration value="clothoid"/>
<xs:enumeration value="cosine"/>
<xs:enumeration value="cubic"/>
<xs:enumeration value="sinusoid"/>
<xs:enumeration value="revBiquadratic"/>
<xs:enumeration value="revBloss"/>
<xs:enumeration value="revCosine"/>
<xs:enumeration value="revSinusoid"/>
<xs:enumeration value="sineHalfWave"/>
<xs:enumeration value="biquadraticParabola"/>
<xs:enumeration value="cubicParabola"/>
<xs:enumeration value="japaneseCubic"/>
<xs:enumeration value="radioid"/>
<xs:enumeration value="weinerBogen"/>
</xs:restriction>
</xs:simpleType>
\end{verbatim}

\item[Lemniskate]

\begin{remark}\emph{lemniscate}
\begin{eqnarray*}
scale & = & 2 / (3 - \cos(2 \cdot t)) \\
x & = & scale \cdot \cos(t) \\
y & = & scale \cdot  \sin(2 \cdot t) / 2
\end{eqnarray*}
\end{remark}

\end{description}

\ldots

% \newgeometry{landscape}

\begin{landscape}

Werfen wir einen Blick auf die Ableitungen erster Ordnung auf $[0,\ 1]$ \ldots 
\begin{center}
\begin{tabular}[h]{|c|c|c|c|c|}
\hline
& $\tau (\sigma) = \int \kappa (\sigma)$ & $\kappa ( \sigma ) $ & const $\kappa' ( \sigma ) $ & \\ 
\hline \hline
Clothoid && $\sigma$ & 1 & \\ 
\hline
Biquadratic && $2 \sigma^2$ & $\sigma$ & \\ 
\hline
Bloss & $x^3 - x^4/2$ & $3 \sigma^2 - 2 \sigma^3$ & $\sigma (1 - \sigma)$ & \\ 
% \hline
pol\_0\_1 &&&& \\ 
\hline
part of V6 && $2.5 \sigma^2 -2.5 \sigma^4 + \sigma^5$ & $\sigma (1 +\sigma -\sigma^2) (1- \sigma)$ & \\ 
\hline
Watorek && $10 \sigma^3 -15 \sigma^4 +6 \sigma^5$ & $\sigma ^2 (1- \sigma)^2$ & \\ 
% \hline
pol\_1\_1 &&&& \\ 
\hline
MieKoc && $20 \sigma^3 -45 \sigma^4 +36 \sigma^5 -10 \sigma^6$ & $\sigma^2 (1 - \sigma)^3$ & \\ 
\hline
Vienna2 && $35 \sigma^4 -84 \sigma^5 +70 \sigma^6 -20 \sigma^7$ & $\sigma^3 (1 - \sigma)^3$ & \\ 
% \hline
pol\_2\_1 &&&& \\ 
\hline
Vienna7 && $126 \sigma^5 -420 \sigma^6 +540 \sigma^7 -315 \sigma^8 +70 \sigma^9$ & $\sigma^4 (1 - \sigma)^4$ & \\ 
% \hline
pol\_3\_1 &&&& \\ 
\hline
pol\_2\_3 &&&& \\ 
\hline
pol\_4\_1 &&& $\sigma^5 (1- \sigma)^5$ & \\ 
\hline
pol\_2\_5 &&&& \\ \hline
pol\_5\_1 &&& $\sigma^6 (1- \sigma)^6$ & \\ 
\hline
pol\_2\_7 &&&& \\ 
\hline
pol\_6\_1 &&& $\sigma^7 (1- \sigma)^7$ & \\ 
\hline
pol\_2\_9 &&&& \\ 
\hline \hline
Sine && $\sigma - \frac{\sin (2 \pi \sigma)}{2 \pi}$ & $1 - \cos (2 \pi \sigma)$ & \\ 
\hline
Cosine && $\frac{1}{2} (1-\cos (\pi \sigma))$ & $\frac{1}{2} \pi \sin(\pi \sigma)$ & $\frac{1}{2} \pi^2 \cos(\pi \sigma)$ \\ 
\hline
pV3 &&&& \\
\hline
\end{tabular}
\end{center}

\ldots und zweiter Ordnung auf $[-1,\ 1]$:

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
&&& const $\kappa' ( \sigma ) $ & const $\kappa'' ( \sigma ) $ \\ 
\hline \hline
Clothoid &&& $(1+ \sigma)^0 (1- \sigma)^0$ & 0 \\ 
\hline
Biquadratic &&& $(1+ \sigma)^1 (1- \sigma)^0$ & $\sigma^0$ \\ 
\hline
Bloss &&& $(1+ \sigma)^1 (1- \sigma)^1$ & \\ 
%\hline
pol\_0\_1 &&&& $(1+ \sigma)^0 \sigma^1 (1- \sigma)^0$ \\ 
\hline
pV6 &&& $(1+ \sigma) (\sigma^2 -5) (1- \sigma)$ & $(\sqrt{3} + \sigma) \sigma (\sqrt{3} - \sigma)$ \\ 
\hline
Watorek &&& $(1+ \sigma)^2 (1- \sigma)^2$ & \\ 
%\hline
pol\_1\_1 &&&& $(1+ \sigma)^1 \sigma^1 (1- \sigma)^1$ \\ 
\hline
MieKoc &&& $(1+ \sigma)^2 (1- \sigma)^3$ & $(1+ \sigma) (5 \sigma + 1) (1- \sigma)^2$ \\ 
\hline
Vienna2 &&& $(1+ \sigma)^3 (1- \sigma)^3$ & \\ 
% \hline
pol\_2\_1 &&&& $(1+ \sigma)^2 \sigma^1 (1- \sigma)^2$ \\ 
\hline
Vienna7 &&& $(1+ \sigma)^4 (1- \sigma)^4$ & \\ 
% \hline
pol\_3\_1 &&&& $(1+ \sigma)^3 \sigma^1 (1- \sigma)^3$ \\ 
\hline
pol\_2\_3 &&& $(1+ \sigma)^3 (3 \sigma^2 +1) (1- \sigma)^3$ & $(1+ \sigma)^2 \sigma^3 (1- \sigma)^2$ \\ 
\hline
pol\_4\_1 &&& $(1+ \sigma)^5 (1- \sigma)^5$ & $(1+ \sigma)^4 \sigma^1 (1- \sigma)^4$ \\ 
\hline
pol\_2\_5 &&& $(1+ \sigma)^4 ( 6 \sigma^4 + 3 \sigma^2 +1 ) (1- \sigma)^4$ & $(1+ \sigma)^2 \sigma^5 (1- \sigma)^2$ \\ 
\hline
pol\_5\_1 &&&$ (1+ \sigma)^6 (1- \sigma)^6$ & $(1+ \sigma)^5 \sigma^1 (1- \sigma)^5$ \\ 
\hline
pol\_2\_7 &&& $(1+ \sigma)^3 (10 \sigma^6 + 6 \sigma^4 + 3 \sigma^2 +1) (1- \sigma)^3$ & $(1+ \sigma)^2 \sigma^7 (1- \sigma)^2$ \\ 
\hline
pol\_6\_1 &&& $(1+ \sigma)^7 (1- \sigma)^7$ & $(1+ \sigma)^6 \sigma^1 (1- \sigma)^6$ \\ 
\hline
pol\_2\_9 &&& $(1+ \sigma)^3 (15 \sigma^8 +10 \sigma^6 + 6 \sigma^4 + 3 \sigma^2 +1) (1- \sigma)^3$ & $(1+ \sigma)^2 \sigma^9 (1- \sigma)^2$ \\ 
\hline \hline
Sine &&&&\\ 
\hline
Cosine &&&& \\ 
\hline
pV3 &&&& \\
\hline
\end{tabular}
\end{center}

\begin{eqnarray*}
\int (1+ \sigma)^2 \sigma^9 (1- \sigma)^2 d \sigma & = & \int (1- s^2)^2 s^9 ds \\
& = & \int (1 - 2s^2 + s^4) s^9 ds \\
& = & \int (s^9 -2s^{11} +s^{13}) ds \\
& = & \frac{s^{10}}{10} - 2 \frac{s^{12}}{12} + \frac{s^{14}}{14} + const \\ \\
21 s^{10} - 35 s^{12} + 15 s^{14} + const &=& s^{10} (15 s^4 - 35 s^2 +21) -1 \\ \\
15 s^{14} - 35 s^{12} + 21 s^{10} -1 &=& (15 s^{12} -20 s^{10} + s^8 + s^6 + s^4 + s^2 +1) (s^2 -1) \\
&=& (15 s^{10} - 5 s^8 -4 s^6 -3 s^4 -2 s^2 -1) (s^2 -1)^2 \\
&=& (15 s^8 +10 s^6 + 6 s^4 + 3 x^2 +1) (s^2 -1)^3
\end{eqnarray*}

\end{landscape}

\paragraph{lesson learned}

\begin{itemize}
\item wie schon bei den Vienna's ersichtlich, sind Kombinationen der Funktionen miteinander, aber auch mit Null-Funktionen denkbar.
\item die Änderung des Wertebereichs weg von $[0,\ 1]$ auf $[-1,\ 1]$, und besser sogar auf $[a,\ b]$ ist für die Analyse offensichtlich hilfreich! $a$, $b$? Mit $\kappa'' (\sigma) = (a + \sigma)^{m_a} \sigma^n (b - \sigma)^{m_b}$ sind alle polynomialen Fälle von oben redundant erfasst ($a < 0 < b$)
\item direkte Anschlussfrage: Ist Symmetrie $a+b=0$ hilfreich???
\item \textsc{Gubar} und \textsc{Ruch} curve führen uns zum Berlin-Dogma: Ein Übergangsbogen setzt sich aus den drei Teilen halfWave1 - clothoid - halfWave2 zusammen, mit jeweils glatten Übergängen (außer ...). Und: Erster und dritter Teil müssen nicht zwingend gleicher Herkunft sein, sogar der mittlere Wendepunkt ist wie bei Biquadratic verzichtbar. Damit ist jedes Polynom mit mindestens Grad zwei Transition-Atom. Sine und Cosine als $C^\infty$-Polynome bedürfen hier weiterer Betrachtungen.
\item Plus Schwerpunkttrassierung ... falls gewollt.
\end{itemize}

Der letzte Punkt ist recht entspannt - SPT an oder aus. Fertig. Na gut, wir brauchen dazu die Originalfunktion plus zweiter Ableitung - Haben wir ja.

Schauen wir uns die Waves an. Eigentlich ja nur halfWave1, weil halfWave2 sich per Drehung / Verschiebung aus einer halfWave1 ergibt (siehe Biquadratic). Eine passende halfWave1 $f$ hat am Startwert $a$ einen Scheitel- oder Wendepunkt mit $f' (a) = 0$, und mündet stetig wachsend im Endwert $b$ (ohne weitere Anforderungen, wünschenswert dort Wendepunkt)

\ldots

\subsubsection{ADDITIONAL SPIRAL CONCEPTS:}

refer Klauder2012

An important spiral design conceptual advance of a different kind was achieved by the German engineer Donges (\textsc{Donges} 1968). His insight was that the forces needed to rotate a vehicle between its pre- and post-spiral bank angles will be less if the vehicle is rotated not about a longitudinal axis in the plane of the track but rather about a longitudinal axis through its so-called center-of-percussion with respect to a transverse impulse applied by the rails. (The center-of-percussion is above
the center of mass.) To implement Donges’ idea computationally one can choose a track roll axis height above a typical vehicle center of mass height, calculate the coordinates of each point on the path of that roll axis using any of the spiral types from Table 1 (although the last 5 that have second derivative of curvature zero at each end of the spiral may be preferred), and then note that the corresponding track point is shifted laterally by the roll axis height times the sine of the bank angle at the point. Spiral geometry of this type (but using a curvature function not illustrated in Table 1) was studied and successfully tested by the Austrian Railways as reported in
\textsc{Presle} \& \textsc{Hasslinger} (1998).

There is another conceptual advance that is worth noting even though with the small track bank angles that are used in conventional railroads its effects are quite small. That is to begin one’s thinking about a spiral not by thinking of a shape on the ground but rather by thinking about how to rotate a vehicle between its pre- and post-spiral bank angles. The pol\_1\_1, Sine, and pol\_2\_1 entries in Table 1 for track curvature versus distance are gentle functions, and those functions can be chosen to define how the roll angle should vary with distance. Ideally that would be the vehicle roll angle, but since a track designer cannot control vehicle roll angle directly that function can be used as a specification for the track bank angle $R (s)$ as a function of distance. To obtain the corresponding path of the track on the ground one obtains the curvature, $C (s)$, of the path of the vehicle roll axis from the roll $R (s)$ via the balance equation. That equation stipulates that the component of centripetal acceleration in the plane of the track should be provided by the component of gravity in the plane of the track and can be written:
\begin{eqnarray*}
\mathcal{C} (s) \cdot \mathcal{V}^2 \cdot \cos ( \mathcal{R} (s) ) = \mathcal{G} \cdot \sin ( \mathcal{R} (s) )
\end{eqnarray*}
where $\mathcal{V}$ denotes a balancing speed and $\mathcal{G}$ denotes the acceleration of gravity. With the formula for curvature as a function of path length along the spiral established, integrations to obtain the compass bearings and coordinates of successive points along the spiral are done as already outlined.

\ldots

% \centerline{\includegraphics{transitionTypes.png}}

\ldots

\section{alignment data transfer}

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
& \multicolumn{3}{|c|}{ fix } & \multicolumn{3}{|c|}{ zero } & \multicolumn{3}{|c|}{ approx } & \multicolumn{10}{|c|}{ transitions } \\ 
& \rotatebox{-90}{ fixElement } & \rotatebox{-90}{ line } & \rotatebox{-90}{ arc } & \rotatebox{-90}{ Km-Sprung } & \rotatebox{-90}{ kink } & \rotatebox{-90}{ immidiate } & \rotatebox{-90}{ cubParabola } & \rotatebox{-90}{ ??? } & \rotatebox{-90}{ ??? } & \rotatebox{-90}{ clotho } & \rotatebox{-90}{ biquadratic } & \rotatebox{-90}{ bloss } & \rotatebox{-90}{ kauder } & \rotatebox{-90}{ sine } & \rotatebox{-90}{ cose } & \rotatebox{-90}{ ? radioid ? } & \rotatebox{-90}{ viennese } & \rotatebox{-90}{ \ldots } & \rotatebox{-90}{ selfmade } \\ 
\hline
AIMv0 & x & - & - & x & x & x &-&-&-& x & x & x & x & x & x &-& x && x \\ 
\hline
Verm.Esn & - & x & x & x & x & (x) &&&& x & x & x & - & x & x && - && - \\ 
\hline
landXML & - & x & x & (x) & (x) & (x) &&&& x & x & x & - & x & x && - && \\ 
\hline
infraGML & - & x & x & (x) & (x) & (x) &&&& x &&&&&&&&& \\ 
\hline
ifcAlignment & - & x & x & (x) & (x) & (x) &&&& x &&&&&&&&& \\ 
\hline
railML & - & x & x & ? &&& ? &&& x &&&&&&&&& \\ 
\hline
\ldots \\
\hline
\end{tabular}
\end{center}


\ldots

\section{Numerik der genutzten Wertebereiche}

\ldots als da wären: Länge, Krümmung, und Winkel!

\subsection{Längenangaben und darauf aufbauende Werte}

Die 1-dim. Länge wird schlicht als Float32 resp. Float64 behandelt. Höher-dimensionales entsprechend als Vektoren (bzw. arrays) mit Längen-Komponenten.

Eine Erweiterung des damit zugrunde-gelegten Zahlraums $\R$ um $\pm \infty$ und die Kehrseite $\neg \R$ in Hinblick auf orientierte homogene Koordinaten erfolgt vielleicht später.

\subsection{Krümmung}

\ldots und Radius \ldots Letzteres ganz klar eine Länge, ersteres aber nutzbringender ($r=\pm0?$!)

\ldots

\subsection{Winkel}

abendfüllend! Sinn und nochmehr Unsinn der unsäglichen Debatten und Unkenntnis zur Verwendung von Radiant-Werten, Alt-Grad, Neugrad oder sogar time-based-values, Orientierung clock- or counterclockwise, $\tau$ instead of $2 \pi$ etc. et. al. --- mal außen vor gelassen: Um ganz einfach den Perioden-Überlauf und damit verbundene Probleme bei simplen Berechnungen (siehe Mittelwert von -2 gon and +1 gon vs. 398 gon and 1 gon) zu verringern (der Optimist sagt: zu vermeiden), probieren wir die Handhabe per $\sin$/$\cos$-Vektor als Pendant zum mathematischen Radiant-Wert.
\begin{eqnarray*}
\tau \to 
\begin{pmatrix}
\cos \tau \\ \sin \tau
\end{pmatrix}
&, &
\begin{pmatrix}
c \\ s
\end{pmatrix}
\to (s \geq 0) \;?\; + \arccos c \;:\; - \arccos c
\end{eqnarray*}

Standardberechnungen am Winkel:

\begin{center}
\begin{tabular}{|l|c|c|}
\hline
Addition & $\begin{pmatrix}
\cos (\alpha+\beta) \\ \sin (\alpha+\beta)
\end{pmatrix}$ & $\begin{pmatrix}
\cos \alpha \cdot \cos \beta - \sin \alpha \cdot \sin \beta \\ \sin \alpha \cdot \cos \beta + \cos \alpha \cdot \sin \beta
\end{pmatrix}$ \\ 
\hline
Subtraktion & $\begin{pmatrix}
\cos (\alpha-\beta) \\ \sin (\alpha-\beta)
\end{pmatrix}$ & $\begin{pmatrix}
\cos \alpha \cdot \cos \beta + \sin \alpha \cdot \sin \beta \\ \sin \alpha \cdot \cos \beta - \cos \alpha \cdot \sin \beta
\end{pmatrix}$ \\ 
\hline
Halbierung & $\begin{pmatrix}
\cos \tfrac{\alpha}{2} \\ \sin \tfrac{\alpha}{2}
\end{pmatrix}$ & \ldots \\ 
\hline
Vielfachung & $\begin{pmatrix}
\cos (n \cdot \alpha) \\ \sin (n \cdot \alpha)
\end{pmatrix}$ & $\begin{pmatrix}
\sum_{j=0}^{\left\lfloor \frac{n}{2} \right\rfloor} (-1)^j \cdot \binom{n}{2j} \cdot \sin^{2j} \alpha \cdot \cos^{n-2j} \alpha \\
\sum _{j=0}^{\left\lfloor \frac {n-1}{2} \right\rfloor} (-1)^{j} \cdot \binom{n}{2j+1} \cdot \sin^{2j+1} \alpha \cdot \cos^{n-2j-1} \alpha
\end{pmatrix}$ \\ 
\hline
\end{tabular}
\end{center}

\ldots

\section{Notwendige vs. redundante Parametrisierung}

\subsection{AWP-Input}

\begin{itemize}
\item Anfangskoordinaten und -richtung $(x_A, y_A, t_A)$
\item Segmentlängen $L^{(i)}$
\item Anfangs- \& Endkrümmungen $k_A^{(i)}$, $k_E^{(i)}$; \\
Krümmungsverläufe $k^{(i)} (s) : [0, L^{(i)}] \to [k_A^{(i)}, k_E^{(i)}]$
\item Knickwinkel $\delta^{(i)}$
\item Endkoordinaten und -richtung $(x_E, y_E, t_E)$ $\to$ Randwertproblem???
\end{itemize}

\ldots

\subsection{Tangentenschnitte}

DER Vorteil: unabhängig eventueller Berechnungsprobleme bleibt der grobe Trassenverlauf erhalten!

\ldots

\section{Segmentberechnung}

\subsection{a}

\subsection{b}

\section{Trassenfindung}

\subsection{a}

\subsection{b}

\section{Trassenoptimierung}

Standardsituation: es gibt eine (rechnerische) Trasse im betrachteten Bereich, diese trifft aber die Lage-vor-Ort eher gering. Es gibt wohl nicht-akzeptable Gleislagefehler. Der Ad-Hoc-Ansatz: Anpassung der Trassenelemente in Länge und Krümmung, ggf. auch Krümmungsverlauf = TransitionTyp (diesen aber händisch).

Wir betrachten eine Trasse $T = (C_0, \ldots, C_N) : \R \to \R^2$, beginnend mit $(T, T')(0) = (p_A, t_A)$ und endend mit $(T, T') (\sum l_i) = (p_E, t_E)$. Die $C_i$ sind Kurven (alternierend Fixx - Flex - Fixx), mit stetig-(f.ü.)-glatten Übergängen. Die Flex-Segmente 'erben' ihre Krümmungs\-parameter $(k_A, k_E)$ von den sie umgebenden Fixx-Elementen (das macht die Übergänge dann f.ü. glatt 2. Ordnung!). Die praxisrelevanten Nebenbedingungen sind alle stations-unabhängig - ausser eben $T(\sum l_i)$!

Also betrachten wir eigentlich eine Trasse als bogenlängen-parametrisierte Multikurve nicht nur im Eingang $station$, sondern auch abhängig der Längen-, Krümmungs- und / oder Delta-Werte: $T [l_0, ..., l_N, k_0, k_2 \ldots, k_{N-2}, k_N, \delta_1, \ldots, \delta_{N-1}] (s) \to \R^2$ ...

Welche 'praxis-relevanten Nebenbedingungen'? Das sind zum einen fixe Längen-, Krüm\-mungs- und / oder Delta-Werte (z.B. schlicht $=0$), und 'Abstände'. Punkt\-abstände sind Abfallprodukt der System-Transformation - im Verständnis einer Trasse als gekrümmtem Koordinatensystem. Dabei ist die Transformation aus Trassensystem in das Grosskoordinatensystem recht simpel ($T.\texttt{trForm}: (s, q) \mapsto (x, y)$). Die umgekehrte Richtung dagegen, $T.\texttt{umForm}: (x, y) \mapsto (s, q)$, ist die Herausforderung!

Desweiteren sind die Abstandsbedingungen meist oder immer 'Box'-Beschränkungen, d.h. der vorgegebene Sollwert ist eigentlich ein Paar aus lowerBound und upperBound. Das wird vertieft werden müssen. Oder aber sie gehen analog Ausgleichsrechnung via kleinste-Quadrate o.ä. in die Kostenfunktion ein.

Wie 'funktioniert' die Minimierung der Nullfunktion $f(x) \equiv 0$, sprich es gibt nur Restriktionen??? $\to$ das wäre der Fall wenn es gilt die Punktabstände zu minimieren unter den 'üblichen' Trassen-inheränten Restriktionen, und oder aber es sind keine Punkte im Input (weil nur die Trasse wieder scharf gemacht werden soll!)

Was haben wir denn? Die Elementlängen sind \underline{entweder} gleich Null \underline{oder} echt größer, bei den Krümmungen etwas einfacher, \underline{entweder} gleich Null resp. konstant \underline{oder} egal. Und die Deltas wiederum \underline{entweder} Null \underline{oder} egal. In Summe: fixe Werte (Gleichheitsrestriktion) oder beliebig, ausser den Längen --- dort dann echt ungleich.

Für die Anschlusspunktbedingung ganz klar Gleichheitsrestriktion!

Was aber mit den gegebenenfalls boxed Punktbeschränkungen. Für mehr Flexibilität sind diese besser in den Kosten untergebracht --- schlussendlich eine Soße: als Restriktionen werden sie durch die Multiplikatoren ebenso quadriert in die Lagrange-Funktion und deren Minimierung eingebracht, nur dort als muss in der Box. Als kleinste Quadrate in der Original Kostenfunktion auch, aber nicht als muss in der Box. Schaun wa mal!

Nochmal $f (x) \equiv 0$, also keine Abstände, nur Trassenzwänge. Wie schaut das aus?
\begin{eqnarray*}
0 & \to & \min \\
g (x) & \leq & \Theta \\
h (x) & = & \Theta
\end{eqnarray*}

Dann
$$\Lagrangian (x, \mu, \nu) = \mu \cdot g (x) + \nu \cdot h (x) \;\to\; \min$$

\ldots

\subsection{und noch mal}

\begin{eqnarray*}
f (x) & \to & \min \\
g (x) & \leq & \Theta \\
h (x) & = & \Theta
\end{eqnarray*}
mit $f (x) = \sum L_i$; $g$ trägt die $L_i \ge 0$ sowie punktuelle Abstände; und $h$ hält zum Einen die Systemforderung $T (0) - T (\sum L_i) = p_E - p_A$ und $T' (0) - T' (\sum L_i) = t_E - t_A$, und mindestens weitere direkte Bedingen wie $L_j = 0 \quad \forall j \in J$

Netterweise ist die Richtungsforderung recht simpel!

Im weiter unten beschriebenen SQP-Verfahren werden die Linearisierungen der beteiligten Funktionen in $x_k$ benötigt. Die Hesse-Matrix der Lagrange'schen dagegen nicht - sie wird durch eine numerisch günstigere Form ersetzt.

Aktuell betrachten wir $x$ als Vektor $\left( L_1, \ldots, L_{2n+1}; K_1, K_3, K_{2n+1} \right)$, also ohne Knicke. Wie lauten dann die Jacobi's der mindest-nötigen $f$, $g$ und $h$ aus?

$f$: wohl kein Problem!

$g$: nett für die $L_i \ge 0$, blöd für die punktuellen Abstände!!!

$h$: falls alle genutzten Krümmungsfunktionen explizit integrierbar sind, dann ergibt dich $t_E - t_A$ aus der Summe der Richtungsänderungen über alle Elemente, in linearer Abhängigkeit der $x$-Einträge --> nett! Blöd: $p_E - p_A$ braucht wohl die explizite Neu-Integration der "gestörten" Elemente ... Schon das Bestimmen von z.B.
$$
\frac{d}{d L_i} \int_0^{L_i} 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
( \Delta t_i (s) ) ds
$$
scheint etwas tricky! Ableiten einer Integral-Grenze ... Wow! Eine erste Idee wäre die Umschreibung auf die normierten $\tau$- oder sogar $\kappa$-Funktionen. Integralgrenzen sind dann 0 und 1, und $L_i$ sowie $\Delta K$ tauchen 'nur' als Faktoren auf:
$$
\frac{d}{d L_i} A (L_i, \Delta K) \cdot \int_0^1 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
( B (L_i, \Delta K) \cdot \Delta \tau_i ( \sigma ) ) d \sigma
$$

Wenn dann der Operatortausch simpel wäre ...
$$
\int_0^1 \left( \frac{d}{d L_i} \left( A (L_i, \Delta K) \cdot 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
( B (L_i, \Delta K) \cdot \Delta \tau_i ( \sigma ) ) \right) \right) d \sigma
$$
Verstecken wir $\Delta K$ in $A$ und $B$, dann ergibt sich mit Produktregel:
$$
\int_0^1 \left( 
A_K' (L_i) \cdot 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
( B_K (L_i) \cdot \Delta \tau_i ( \sigma ) )
+
A_K (L_i) \cdot
\frac{d}{d L_i} \left(
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
( B_K (L_i) \cdot \Delta \tau_i ( \sigma ) )
\right)
\right) d \sigma
$$
Der erste Summand
$$
A_K' (L_i) \cdot 
\int_0^1 \left( 
\begin{pmatrix}
\cos \\ \sin
\end{pmatrix}
( B_K (L_i) \cdot \Delta \tau_i ( \sigma ) )
\right) d \sigma
$$
scheint noch recht entspannt zu sein. Der zweite
$$
A_K (L_i) \cdot B_K' (L_i) \cdot 
\int_0^1
\begin{pmatrix}
-\sin \\ \cos
\end{pmatrix}
( B_K (L_i) \cdot \Delta \tau_i ( \sigma ) )
\cdot
\Delta \tau_i ( \sigma )
d \sigma
$$
nicht mehr.

\ldots

\subsection{Anwendungsfälle}

\subsubsection{Einrechnen}

Seien eine Gerade (am Anfang) und ein Bogen (am Ende) gegeben, gesucht sind alle Längen inklusive des vermittelnden Übergangsbogen zwischen Gerade und Bogen.

Prinzipiell sind drei Fälle in Ausdruck der Abrückung zu unterscheiden:
\begin{description}
\item[$> 0$:] Der eigentlich interessante Fall mit eindeutiger Lösung!
\item[$= 0$:] Die Länge des Übergangsbogen beträgt Null, es ist also de facto ein Bogenwechsel.
\item[$< 0$:] keine Lösung!
\end{description}

Ersterer: Gerade und Bogen sind mit der nötigen Parametrisierung inklusive Anfangs- respektive Endpunkt und -richtung bekannt, ebenso der Typ des Übergangsbogen (vielleicht durch Wechsel Clothoide nach Bloss \ldots). Weitergehende Zwänge wie anzurechnende Punkte nicht nötig, da überflüssig.

\begin{eqnarray*}
0 & \to & \min_{x = (l_g, l_t, l_b, k_g, d_t, k_b)} ! \\
\text{s.t.} \\
l_g & > & 0 \\ 
l_t & > & 0 \\ 
l_b & > & 0 \\ 
k_g & = & 0 \\ 
d_t & = & 0 \\ 
k_b & = & \text{const} \\
tra.\texttt{trForm} (\sum l_{*}, q=0) & = & (p_E, t_E)
\end{eqnarray*}\footnote{$>$??? Praktisch nehmen wir hier statt dessen $\geq$ und schließen das aktiv-Werden aus \ldots}
Formal
\begin{eqnarray*}
g (x)
& = &
\begin{pmatrix}
g_1 \\ g_2 \\ g_3
\end{pmatrix}
(x)
\end{eqnarray*}
und
\begin{eqnarray*}
h (x)
& = &
\begin{pmatrix}
h_1 \\ h_2 \\ h_3
\end{pmatrix}
(x)
\end{eqnarray*}
mit
\begin{eqnarray*}
g_1 (x) & = & -l_g \\ 
g_2 (x) & = & -l_t \\ 
g_3 (x) & = & -l_b \\ 
h_1 (x) & = & k_g \\ 
h_2 (x) & = & d_t \\ 
h_3 (x) & = & k_b \\ 
H (x) & = & tra.\texttt{trForm}(\sum l_*, q=0) - (p_E, t_E)
\end{eqnarray*}
und
\begin{eqnarray*}
g (x) \leq \Theta, & h (x) = \Theta, & H (x) = \Theta
\end{eqnarray*}
Die Lagrange'sche ergibt sich als 
\begin{eqnarray*}
\Lagrangian (x; \mu, \nu, \Nu) & = & 0 \\
& + & (\mu_1, \mu_2, \mu_3) \cdot g (x) \\
& + & (\nu_1, \nu_2, \nu_3) \cdot h (x) \\
& + & (\Nu_x, \Nu_y, \Nu_t) \cdot H (x)
\end{eqnarray*}
Damit
\begin{eqnarray*}
\nabla_x \Lagrangian & = & \mu \cdot \nabla g + \nu \cdot \nabla h + \Nu \cdot \nabla H \\
\nabla_\mu \Lagrangian & = & g \\
\nabla_\nu \Lagrangian & = & h \\
\nabla_\Nu \Lagrangian & = & H
\end{eqnarray*}

\ldots

first choosing the initial iterate $(x^{[0]}, \mu^{[0]}, \nu^{[0]})$, then calculating $H_0$ instead of $\nabla^2 \Lagrangian (x^{[0]}, \mu^{[0]}, \nu^{[0]})$, and $\nabla \Lagrangian (x^{[0]}, \mu^{[0]}, \nu^{[0]})$. 

Then the $(\text{QP}_\idx)$ subproblem 
$$
\begin{array}{rccccl}
\min \limits_d &&& \nabla f (x^{[\idx]})^T d & + & \tfrac{1}{2} d^T H_\idx d \\
\text {s.t.} & g (x^{[\idx]}) & + & \nabla g (x^{[\idx]})^T d & \leq & 0 \\
& h (x^{[\idx]}) & + & \nabla h (x^{[\idx]})^T d & = & 0.
\end{array}
$$
is built and solved to find the Newton step direction $d^{[\idx]}$ which is used to update the parent problem iterate using $x^{[\idx+1]} = x^{[\idx]} + d^{[\idx]}$. This process is repeated for $\idx=0,1,2,\ldots$ until the parent problem satisfies a convergence test.

\begin{remark}
\begin{eqnarray*}
x & \in & \R^6 \\
\mu & \in & \R^3 \\
\nu & \in & \R^3 \\
\Nu & \in & \R^3 \\
d & \in & \R^{6+3+3+3=15}
\end{eqnarray*}

\end{remark}

Howto solve a problem (QP) like
$$
\begin{array}{rccccl}
& \tfrac{1}{2} d^T W d & + & c^T d & \to & !\min_d \\
\text {s.t.} & A d & - & u & \leq & \Theta \\
& B d & - & v & = & \Theta.
\end{array}
$$
or the \ldots

\ldots

\printbibliography[heading=bibintoc, title={Bibliography}]

\addcontentsline{toc}{chapter}{Index}
\printindex

\end{document} 
